// WATCHOUT 7 User Guide - Content Data
// Auto-generated by build-content.js - DO NOT EDIT DIRECTLY
// Edit the markdown files in /content instead

const wikiContent = {
  "1. Getting Started": {
    "overview": "<h1>GETTING STARTED</h1>\n\n<p>Welcome to <strong>WATCHOUT 7</strong> – the premier multi-display presentation and production system from Dataton. This guide will help you create stunning visual experiences using projectors, LED walls, monitors, and other display technologies.</p>",
    "sections": {
      "Welcome To Watchout 7": "<div class=\"article-metadata\"><span class=\"article-badge\" data-badge=\"Jacquie\">Jacquie</span><span class=\"article-badge\" data-badge=\"JME\">JME</span><span class=\"article-badge\" data-badge=\"Karol\">Karol</span></div><h2>Welcome to WATCHOUT 7</h2>\n\n<p><strong>WATCHOUT 7</strong> is the latest evolution of Dataton's award-winning multi-display production and playback system. Designed for show creators, live event professionals, and system integrators, WATCHOUT empowers you to orchestrate massive-scale visuals across unlimited displays, projectors, and LED walls—all from a single timeline.</p>\n\n<p>Whether you are creating a digital signage installation, a projection mapping spectacle, a live concert background, or a corporate presentation, WATCHOUT provides the tools to compose, manage, and play back high-resolution media with frame-accurate synchronization.</p>\n\n<div class='info-box'><p><strong>New in WATCHOUT 7:</strong> This version introduces a completely new high-performance video engine, <strong>HDR</strong> (High Dynamic Range) support, and a modernized user interface with dark mode, asset management, and collaborative workflows.\n</p></div>\n\n<h3>The Core Concept: One Giant Canvas</h3>\n\n<p>If you are new to multi-display systems, the easiest way to understand WATCHOUT is to think of it as <strong>one giant digital canvas</strong>.</p>\n\n<p>In traditional systems with a ten-screen video wall, you might need ten separate video files and players. WATCHOUT eliminates this complexity.</p>\n\n<p>With WATCHOUT, you place your media on a <strong>Stage</strong>—a continuous workspace representing your entire display area. You can drag a video across all screens or animate an image from one side to the other. The system treats the entire display arrangement as a unified creative space.</p>\n\n<p>Behind the scenes, WATCHOUT handles the processing:</p>\n\n<ul>\n<li><strong>Producer:</strong> You use the <strong>Producer</strong> software to design your show, arrange media on the Timeline, and animate content.</li>\n<li><strong>Display Computers:</strong> These computers connect to your projectors or LED walls and render the content.</li>\n<li><strong>The Playback:</strong> When you run your show, WATCHOUT automatically slices your content in real-time, sending the correct portion to each Display Computer. All computers play in perfect synchronization, creating a seamless image.</li>\n\n</ul>\n<h3>System Architecture</h3>\n\n<p>WATCHOUT uses a distributed client-server architecture designed for reliability and scalability.</p>\n\n<img src=\"../media/system_architecture_diagram.svg\" alt=\"WATCHOUT System Architecture Diagram\" class=\"content-image\">\n\n<ol>\n<li><strong>Production Computer:</strong> Runs the <strong>Producer</strong> software and manages your project files. This is your creative workstation where you organize content using the <strong>Asset Manager</strong>. It sends control commands (Play, Pause, Update) to the network while leaving heavy rendering to the display computers.</li>\n<li><strong>Display Computers:</strong> Run the <strong>Display</strong> software (formerly Watchpoint). These machines handle video decoding, real-time compositing, and rendering. Each Display Computer synchronizes automatically with the Production Computer and can run \"headless\" (without a monitor).</li>\n<li><strong>Network:</strong> Connects your Production and Display computers via standard Ethernet.</li>\n\n</ol>\nThis architecture allows you to scale from a simple two-screen setup to hundreds of outputs without changing your workflow.\n\n<h3>What You Can Create</h3>\n\n<p>WATCHOUT is a blank canvas limited only by your hardware and imagination. Common applications include:</p>\n\n<ul>\n<li><strong>Wide-screen Projection:</strong> Blends multiple projectors to form massive panoramic screens.</li>\n<li><strong>Projection Mapping:</strong> Wraps video content around complex 3D objects or buildings.</li>\n<li><strong>LED Video Walls:</strong> Drives custom-resolution LED processors with pixel-perfect accuracy.</li>\n<li><strong>Digital Signage:</strong> Synchronizes playback across multiple monitors throughout a venue.</li>\n<li><strong>Live Broadcasts:</strong> Provides dynamic backdrops and lower-thirds for broadcast or streaming.</li>\n<li><strong>Interactive Installations:</strong> Triggers content based on external inputs from sensors, buttons, or network commands.</li>\n\n</ul>\nThe system adapts to your creative vision, whether you are designing an intimate gallery experience or a stadium concert.",
      "System Requirements": "<div class=\"article-metadata\"><span class=\"article-badge\" data-badge=\"Miro\">Miro</span><span class=\"article-badge\" data-badge=\"Jacquie\">Jacquie</span><span class=\"article-badge\" data-badge=\"JME\">JME</span><span class=\"article-badge\" data-badge=\"Karol\">Karol</span></div><h2>System Requirements</h2>\n\n<p>WATCHOUT 7 requires a Windows-based computer with modern hardware to deliver optimal performance. The requirements differ between the Producer computer (where you edit shows) and Display computers (which render and output to projectors/screens).</p>\n\n<h3>Producer vs. Display Computer Architecture</h3>\n\n<p>WATCHOUT uses a <strong>client-server architecture</strong> that separates show creation from show playback:</p>\n\n<p><strong>Producer Computer</strong> – This is your creative workstation where you design, edit, and control shows. The Producer software provides the timeline editor, stage view, and all creative tools. You only need <em>one</em> Producer computer per show, and it doesn't need to be connected to any physical outputs—it can preview everything internally. The Producer sends commands and media to Display computers over the network.</p>\n\n<p><strong>Display Computer(s)</strong> – These are dedicated playback machines that render content and drive physical outputs (projectors, LED walls, monitors). Each Display computer runs the WATCHOUT Display software and connects to your actual screens. A single Display computer can drive up to 4-8 outputs depending on the graphics card. For larger installations, you simply add more Display computers—WATCHOUT synchronizes them frame-accurately over the network.</p>\n\n<div class='info-box'><p><strong>Tip:</strong> You can run both Producer and Display on the same computer for small setups or previewing. For production environments, dedicated Display computers ensure reliable, uninterrupted playback.\n</p></div>\n\n<h3>Producer Computer (Editing)</h3>\n\n<table>\n<tr><th>Component</th><th>Minimum</th><th>Recommended</th></tr>\n<tr><td>Operating System</td><td>Windows 10 21H2 (64-bit)</td><td>Windows 11 23H2 or newer (64-bit)</td></tr>\n<tr><td>Processor</td><td>Intel Core i3/i5 or AMD Ryzen 3/5</td><td>Intel Core i7/i9 or AMD Ryzen 7/9</td></tr>\n<tr><td>RAM</td><td>16 GiB DDR4</td><td>32 GiB DDR5 or more</td></tr>\n<tr><td>Graphics</td><td>DirectX 12 compatible GPU with 4 GiB VRAM</td><td>NVIDIA RTX PRO</td></tr>\n<tr><td>Storage</td><td>SSD with 100 GiB free</td><td>NVMe SSD (Gen4) with 1 TiB+ free</td></tr>\n<tr><td>Network</td><td>Gigabit Ethernet</td><td>2.5 Gigabit Ethernet</td></tr>\n</table>\n\n<h3>Display Computer (Playback)</h3>\n\n<table>\n<tr><th>Component</th><th>Minimum</th><th>Recommended</th></tr>\n<tr><td>Operating System</td><td>Windows 10 21H2 (64-bit)</td><td>Windows 11 23H2 or newer (64-bit)</td></tr>\n<tr><td>Processor</td><td>Intel Core i3/i5, AMD Ryzen 3/5, or equivalent Xeon/EPYC</td><td>Intel Core i7/i9, AMD Ryzen 7/9, or equivalent Xeon/EPYC</td></tr>\n<tr><td>RAM</td><td>16 GiB DDR4</td><td>32 GiB DDR5 or more</td></tr>\n<tr><td>Graphics</td><td>NVIDIA GeForce RTX</td><td>NVIDIA RTX PRO</td></tr>\n<tr><td>Storage</td><td>SATA SSD (500+ MiB/s sustained read)</td><td>NVMe SSD (Gen4, 3500+ MiB/s sustained read)</td></tr>\n<tr><td>Network</td><td>Gigabit Ethernet</td><td>2.5 Gigabit Ethernet</td></tr>\n</table>\n\n<div class='info-box'><p><strong>Note on CPU:</strong> The processor is not a critical factor for most WATCHOUT installations. Workstation-class processors like Intel Xeon and AMD EPYC work well, and even an Intel Core i3 provides sufficient performance for basic playback scenarios.\n</p></div>\n\n<div class='warning-box'><p><strong>Note on AMD Graphics:</strong> While AMD GPUs may work, NVIDIA is recommended for full WATCHOUT feature support. AMD graphics cards require additional testing before deployment in production environments.\n</p></div>\n\n<h3>Windows Editions: Consumer vs. WATCHPAX</h3>\n\n<p>When building your own display computer, you'll use standard consumer Windows editions. <strong>Windows 11 Home</strong> or <strong>Windows 11 Pro</strong> are the recommended options for user-built systems.</p>\n\n<table>\n<tr><th>Feature</th><th>Windows 11 Home/Pro</th><th>WATCHPAX</th></tr>\n<tr><td>Operating System</td><td>Standard Windows</td><td>Windows IoT Enterprise LTSC</td></tr>\n<tr><td>Feature updates</td><td>Every 6-12 months</td><td>None (security only)</td></tr>\n<tr><td>Support lifecycle</td><td>24 months</td><td>5-10 years</td></tr>\n<tr><td>Bloatware/Store apps</td><td>Included</td><td>Removed</td></tr>\n<tr><td>WPX Manager Support</td><td>No</td><td>Yes</td></tr>\n<tr><td>Update control</td><td>Limited</td><td>Complete control</td></tr>\n<tr><td>Pre-configured</td><td>No</td><td>Yes, optimized for WATCHOUT</td></tr>\n</table>\n\n<p><strong>Why choose WATCHPAX over a custom-built PC?</strong></p>\n\n<ul>\n<li><strong>No surprise updates</strong> – The LTSC operating system receives security patches only; no feature updates that could change system behavior or require reboots during shows</li>\n<li><strong>Minimal background processes</strong> – No Cortana, Xbox Game Bar, or Store apps consuming resources</li>\n<li><strong>Predictable environment</strong> – The OS stays exactly as configured for years</li>\n<li><strong>Extended support</strong> – Security patches available for 5+ years without major OS upgrades</li>\n<li><strong>Pre-configured</strong> – WATCHPAX units arrive ready for WATCHOUT with optimal settings applied</li>\n\n</ul>\n<strong>Managing updates on consumer Windows:</strong>\n\n<p>If using Windows 11 Home or Pro, plan for regular maintenance windows:</p>\n\n<ul>\n<li>Schedule Windows updates during non-show periods</li>\n<li>Test updates in a staging environment before production systems</li>\n<li>Use the \"Pause updates\" feature in Windows Settings to defer updates during critical show periods</li>\n<li>Maintain no more than 24 months behind current Windows versions to remain in Microsoft's support window</li>\n\n</ul>\n<div class='info-box'><p><strong>Note:</strong> Display computers should be dedicated to WATCHOUT playback. Avoid running other applications during live shows to ensure consistent performance.\n</p></div>\n\n<h3>Windows Updates and Rendering Performance</h3>\n\n<p>Keeping Windows up to date is <strong>critical for optimal WATCHOUT performance</strong>. Newer Windows updates deliver significant improvements to rendering stability and visual output quality:</p>\n\n<h4>DirectX 12 Ultimate Enhancements</h4>\n\n<p>Windows updates continuously improve DirectX 12 capabilities:</p>\n\n<ul>\n<li><strong>Enhanced memory management</strong> – Better VRAM allocation reduces out-of-memory errors with large textures and high-resolution video</li>\n\n<p><li><strong>Improved shader compilation</strong> – Faster loading times and reduced hitching during playback</li></p>\n\n<p><li><strong>Multi-adapter support</strong> – Better handling of systems with multiple GPUs</li></p>\n\n</ul>\n<h4>Multi-Head Output Stability</h4>\n\n<p>For display servers driving multiple outputs, Windows updates are essential:</p>\n\n<ul>\n<li><strong>Improved EDID handling</strong> – Better detection and configuration of connected displays, especially when using EDID emulators or matrix switches</li>\n\n<p><li><strong>Hotplug stability</strong> – Reduced crashes and display resets when cables are connected or disconnected</li></p>\n\n<p><li><strong>Resolution persistence</strong> – Display configurations survive reboots more reliably</li></p>\n\n<p><li><strong>Mosaic/Surround mode fixes</strong> – Critical patches for multi-display spanning configurations</li></p>\n\n</ul>\n<h4>Security and Reliability</h4>\n\n<ul>\n<li><strong>Kernel improvements</strong> – Reduced system crashes and blue screens during extended operation</li>\n\n<p><li><strong>Memory leak fixes</strong> – Essential for 24/7 installations where systems run for weeks without restart</li></p>\n\n<p><li><strong>Timer resolution updates</strong> – More accurate timing for frame-perfect synchronization</li></p>\n\n</ul>\n<div class='warning-box'><p><strong>Recommendation:</strong> Always use the latest stable Windows version and cumulative updates. Test updates in a staging environment before deploying to production show computers.\n</p></div>\n\n<h3>NVIDIA RTX PRO Professional Graphics</h3>\n\n<p>While consumer GeForce cards can run WATCHOUT, <strong>NVIDIA RTX PRO (Quadro and RTX Ada) professional GPUs</strong> are strongly recommended for display computers in production environments. Here's why:</p>\n\n<h4>Key Benefits of NVIDIA RTX PRO</h4>\n\n<table>\n<tr><th>Feature</th><th>NVIDIA RTX PRO</th><th>GeForce RTX</th></tr>\n<tr><td>TCC Mode</td><td>✓ Compute-optimized mode</td><td>✗ Windows display only</td></tr>\n<tr><td>EDID Management</td><td>✓ Controllable via WATCHOUT</td><td>✗ Not supported</td></tr>\n<tr><td>Sync Connector</td><td>✓ Hardware genlock/framelock</td><td>✗ Software sync only</td></tr>\n<tr><td>Driver Certification</td><td>✓ Extended testing cycles</td><td>Game-focused optimization</td></tr>\n<tr><td>Long-term Support</td><td>✓ Enterprise driver branches</td><td>Consumer update cycle</td></tr>\n</table>\n\n<h4>EDID Management</h4>\n\n<p>WATCHOUT can manage EDID (Extended Display Identification Data) directly when using <strong>NVIDIA RTX PRO or Quadro</strong> graphics cards. This allows you to:</p>\n\n<ul>\n<li>Set custom resolutions and refresh rates per output</li>\n<li>Emulate display EDIDs for consistent behavior without physical displays connected</li>\n<li>Configure outputs before connecting actual projectors or screens</li>\n\n</ul>\n<div class='info-box'><p><strong>Note:</strong> EDID management through WATCHOUT is only supported on NVIDIA professional GPUs. Users with AMD or other graphics cards will need to manage EDID settings outside of WATCHOUT using third-party tools or hardware EDID emulators.\n</p></div>\n\n<h4>NVIDIA Sync Board: Framelock and Genlock</h4>\n\n<p>For multi-projector installations requiring <strong>perfect frame synchronization</strong>:</p>\n\n<ul>\n<li><strong>NVIDIA RTX PRO Sync boards</strong> enable hardware-level genlock between multiple GPUs and external sync sources</li>\n<li><strong>Framelock</strong> ensures all outputs across multiple cards/systems swap buffers simultaneously</li>\n<li>Critical for edge-blended panoramas and LED wall installations where frame tearing between panels is visible</li>\n\n</ul>\n<div class='warning-box'><p><strong>Hardware Required:</strong> Framelocking multiple display computers or syncing to an external genlock signal requires an NVIDIA Sync board installed in each display computer. This is a separate hardware add-on for RTX PRO / Quadro cards—it is not possible with consumer GeForce GPUs.\n</p></div>\n\n<h4>Professional Driver Certification</h4>\n\n<p>RTX PRO drivers undergo extensive testing and certification:</p>\n\n<ul>\n<li><strong>Optimal Drivers for Enterprise (ODE)</strong> – Stability-focused drivers with extended testing cycles</li>\n\n<p><li><strong>Longer support lifecycle</strong> – Enterprise customers receive driver updates for extended periods</li></p>\n\n<p><li><strong>Better regression testing</strong> – Less risk of updates breaking existing functionality</li></p>\n\n</ul>\n<h3>Video Capture Requirements</h3>\n\n<p>When using video capture devices with WATCHOUT, ensure your hardware meets these requirements:</p>\n\n<table>\n<tr><th>Requirement</th><th>Description</th></tr>\n<tr><td><strong>Windows Media Foundation</strong></td><td>Capture device must have Windows Media Foundation (WMF) compatible drivers</td></tr>\n<tr><td><strong>Deltacast Cards</strong></td><td>Require GPUDirect support for optimal performance</td></tr>\n</table>\n\n<div class='info-box'><p><strong>GPUDirect:</strong> For Deltacast capture cards, GPUDirect enables direct memory transfer between the capture card and GPU, bypassing system memory for lower latency and reduced CPU overhead.\n</p></div>\n\n<h3>Storage Recommendations</h3>\n\n<p>Video playback performance depends heavily on storage speed. <strong>Sustained read rates</strong> are more important than peak specifications—this is the read speed your SSD can maintain continuously during 24/7 operation without thermal throttling.</p>\n\n<div class='warning-box'><p><strong>Sustained vs. Peak Performance:</strong> SSD manufacturers often advertise peak read speeds, but thermal throttling can reduce actual performance during continuous operation. Ensure your system has adequate cooling for the SSD, and look for drives with good sustained performance ratings. The read rate an SSD can maintain indefinitely may be significantly lower than its maximum specification, depending on the drive model and thermal conditions.\n</p></div>\n\n<h4>Video Codec Storage Requirements</h4>\n\n<table>\n<tr><th>Content Type</th><th>Sustained Read Required</th><th>Recommended Storage</th></tr>\n<tr><td>HAP 1080p60</td><td>~59 MiB/s</td><td>SATA SSD</td></tr>\n<tr><td>HAP 4K60</td><td>~237 MiB/s</td><td>SATA SSD or NVMe</td></tr>\n<tr><td>Notch LC 4K60</td><td>~380 MiB/s</td><td>SATA SSD or NVMe</td></tr>\n<tr><td>HAP 8K60</td><td>~949 MiB/s</td><td>NVMe Gen3 SSD</td></tr>\n<tr><td>4K image sequence (60 fps)</td><td>~1,899 MiB/s</td><td>NVMe Gen4 SSD</td></tr>\n<tr><td>8K image sequence (60 fps)</td><td>~7,594 MiB/s</td><td>NVMe Gen4 RAID array</td></tr>\n</table>\n\n<h4>Asset Disk Space Guidelines</h4>\n\n<p>Plan storage capacity based on your content library. Below are typical file sizes for common media formats:</p>\n\n<table>\n<tr><th>Content</th><th>Duration/Count</th><th>Approximate Size</th></tr>\n<tr><td>HAP 1080p60 video</td><td>1 minute</td><td>~3.5 GiB</td></tr>\n<tr><td>HAP 4K60 video</td><td>1 minute</td><td>~14 GiB</td></tr>\n<tr><td>Notch LC 4K60 video</td><td>1 minute</td><td>~22 GiB</td></tr>\n<tr><td>HAP 8K60 video</td><td>1 minute</td><td>~56 GiB</td></tr>\n<tr><td>4K image sequence (60 fps)</td><td>1 minute</td><td>~111 GiB</td></tr>\n<tr><td>8K image sequence (60 fps)</td><td>1 minute</td><td>~446 GiB</td></tr>\n</table>\n\n<div class='info-box'><p><strong>Note:</strong> Images are stored as RAW/uncompressed for optimal playback performance. ProRes and other compressed video formats are automatically optimized to Notch LC by default.\n</p></div>\n\n<div class='info-box'><p><strong>Tip:</strong> For shows with large media libraries, calculate total storage needs including headroom for revisions and additional content. A 1 TB NVMe SSD is suitable for most productions; consider 2 TB or more for 4K/8K heavy projects.\n</p></div>\n\n<h3>Network Requirements</h3>\n\n<table>\n<tr><th>Component</th><th>Minimum</th><th>Recommended</th></tr>\n<tr><td>Speed</td><td>1 Gbps</td><td>2.5 Gbps</td></tr>\n</table>\n| Switch | Managed Gigabit switch | Enterprise-grade with IGMP snooping |ßß\n<table>\n<tr><th>Topology</th><th>Star (all on same subnet)</th><th>Dedicated VLAN for WATCHOUT</th></tr>\n</table>\n\n<div class='info-box'><p><strong>Why 2.5 Gbps?</strong> Most modern motherboards include 2.5 Gigabit Ethernet as standard, providing a significant improvement over 1 Gbps without the cost and complexity of 10 Gbps infrastructure. This is the same networking standard used in WATCHPAX display servers.\n</p></div>\n\n<div class='info-box'><p><strong>What is IGMP Snooping?</strong> Internet Group Management Protocol (IGMP) snooping is a switch feature that optimizes multicast traffic. Without it, multicast packets (used by WATCHOUT for synchronization and NDI video) flood all switch ports, wasting bandwidth. With IGMP snooping enabled, the switch intelligently forwards multicast traffic only to devices that need it—reducing network congestion and improving overall performance, especially in systems with multiple display servers or NDI sources.\n</p></div>\n\n<h4>NDI Stream Bandwidth Requirements</h4>\n\n<p>NDI (Network Device Interface) is commonly used for video input in WATCHOUT. Here are the typical bandwidth requirements:</p>\n\n<table>\n<tr><th>Resolution</th><th>Frame Rate</th><th>Bandwidth (approx.)</th></tr>\n<tr><td>1920×1080</td><td>60 fps</td><td>~125 Mbps</td></tr>\n<tr><td>3840×2160 (4K)</td><td>60 fps</td><td>~250 Mbps</td></tr>\n<tr><td>7680×4320 (8K)</td><td>60 fps</td><td>~500 Mbps</td></tr>\n</table>\n\n<div class='info-box'><p><strong>Note:</strong> Multiple simultaneous NDI streams may require 2.5 Gbps or faster networking depending on total throughput.\n</p></div>\n\n<h4>File Transfer Time Comparison</h4>\n\n<p>Network speed dramatically affects how quickly you can deploy media to display servers. The table below shows approximate transfer times for common file sizes:</p>\n\n<table>\n<tr><th>File Size</th><th>1 Gbps (~119 MiB/s)</th><th>2.5 Gbps (~298 MiB/s)</th><th>10 Gbps (~1.2 GiB/s)</th></tr>\n<tr><td>1 GiB</td><td>~9 seconds</td><td>~4 seconds</td><td>~1 second</td></tr>\n<tr><td>100 GiB</td><td>~15 minutes</td><td>~6 minutes</td><td>~90 seconds</td></tr>\n<tr><td>1 TiB</td><td>~2.5 hours</td><td>~60 minutes</td><td>~15 minutes</td></tr>\n</table>\n\n<div class='info-box'><p><strong>Note:</strong> Actual transfer speeds depend on disk I/O, network congestion, and switch quality. The values above assume modern SSDs and a well-configured network with minimal overhead.\n</p></div>\n\n<p>For productions with large media libraries or frequent content updates, faster networking pays for itself quickly in reduced setup and rehearsal time. Consider higher-speed networking especially for:</p>\n\n<ul>\n<li><strong>4K/8K video content</strong> – Single uncompressed 4K frames can exceed 30 MB</li>\n<li><strong>Image sequences</strong> – Thousands of files that benefit from sustained throughput</li>\n<li><strong>Multi-server deployments</strong> – Simultaneous transfers to multiple display computers</li>\n<li><strong>Live event environments</strong> – Last-minute content changes require rapid deployment</li>\n\n</ul>",
      "Installing Watchout": "<div class=\"article-metadata\"><span class=\"article-badge\" data-badge=\"Miro\">Miro</span><span class=\"article-badge\" data-badge=\"Jacquie\">Jacquie</span><span class=\"article-badge\" data-badge=\"JME\">JME</span><span class=\"article-badge\" data-badge=\"Karol\">Karol</span></div><h2>Installing WATCHOUT</h2>\n\n<p>Setting up WATCHOUT represents the first step toward creating your show. The installation process is straightforward, but ensuring your system is prepared correctly is key to a stable performance environment.</p>\n\n<h3>Getting the Installer</h3>\n\n<ol>\n<li>Visit the official Dataton website at <strong>dataton.com/downloads</strong>.</li>\n<li>Navigate to the <strong>WATCHOUT 7</strong> section.</li>\n<li>Download the latest release installer.</li>\n\n</ol>\n<h3>Installation Process</h3>\n\n<h4>1. Run as Administrator</h4>\n\n<p>Right-click the downloaded installer file and select <strong>Run as administrator</strong>. This ensures the installer has the necessary permissions to register components and modify system settings.</p>\n\n<h4>2. Select Components</h4>\n\n<p>During installation, you will be prompted to select components. Ensure valid options are selected for your needs.</p>\n\n<img src=\"../media/watchout-setup.png\" alt=\"WATCHOUT Setup - Choose Components\" class=\"content-image\">\n\n<h4>3. Drivers and Prerequisites</h4>\n\n<p>The installer checks for and installs several critical system dependencies. It is essential to allow these installations to complete:</p>\n\n<ul>\n<li><strong>CodeMeter Runtime:</strong> This is the background service that manages your Dataton license keys. It ensures your software is properly authorized and handles network licensing if applicable.</li>\n<li><strong>Microsoft WebView2:</strong> Required for certain parts of the user interface (such as the Asset Manager and Help system) that are built on modern web technologies.</li>\n<li><strong>Vulkan Runtime:</strong> A modern, high-performance graphics API. WATCHOUT 7 uses Vulkan for its rendering engine to achieve lower overhead and efficient GPU resource management.</li>\n\n</ul>\n<h4>4. Restart</h4>\n\n<p>After the installation completes, <strong>restart your computer</strong>. This is mandatory to ensure all system drivers and network services are correctly initialized.</p>\n\n<h3>Post-Installation Checklist</h3>\n\n<ul>\n<li><strong>Windows Settings:</strong> Set \"Power & sleep\" settings to <strong>Never</strong> for both screen and sleep.</li>\n<li><strong>Notifications:</strong> Turn off \"Focus assist\" and Windows notifications to prevent interruptions.</li>\n<li><strong>User Account:</strong> It is recommended to run WATCHOUT under a Standard User account with auto-login enabled for Display computers, not Administrator, to prevent accidental system changes during a show.</li>\n\n</ul>",
      "Launching The Application": "<div class=\"article-metadata\"><span class=\"article-badge\" data-badge=\"Jacquie\">Jacquie</span><span class=\"article-badge\" data-badge=\"JME\">JME</span><span class=\"article-badge\" data-badge=\"Karol\">Karol</span></div><h2>Launching the Application</h2>\n\n<p>Once WATCHOUT is installed, you are ready to launch the software. How you launch it depends on whether you are working on the Production Computer (designing) or a Display Computer (playback).</p>\n\n<h3>On the Production Computer</h3>\n\n<p>Launch <strong>WATCHOUT Producer</strong> from the desktop shortcut or Start Menu.</p>\n\n<h4>The Welcome Screen</h4>\nUpon first launch, you are greeted by the Welcome Screen, which serves as your project hub:\n\n<ul>\n<li><strong>New:</strong> Creates a blank canvas for a new show.</li>\n<li><strong>Open:</strong> Browse your file system for an existing <code>.watch</code> show file.</li>\n<li><strong>Open show from Director:</strong> Connect to a Director on your network to open its currently running show.</li>\n<li><strong>Learn:</strong> Opens the WATCHOUT 7 User's Guide in your web browser.</li>\n<li><strong>Recent Shows:</strong> A list of your most recently accessed show files for quick entry (displayed on the right side of the Welcome Screen).</li>\n\n</ul>\n<h4>Layout Presets</h4>\nWATCHOUT 7 allows you to save and load custom layout presets. You can save up to 9 layout presets and quickly switch between them using keyboard shortcuts or the Window menu. Use <strong>Reset Layout</strong> from the Window menu to return to the default layout.\n\n<h3>On Display Computers</h3>\n\n<p>On your media servers, launch the <strong>WATCHOUT Manager</strong> to start playback services.</p>\n\n<ol>\n<li>Look for the <strong>WATCHOUT Manager</strong> shortcut on the desktop.</li>\n<li>Launch the application.</li>\n<li>A splash screen will appear on connected displays, indicating the system is ready and listening for commands from a Director.</li>\n<li><strong>Important:</strong> The WATCHOUT Manager must be running <em>before</em> you try to connect from the Production computer.</li>\n\n</ol>\nThe WATCHOUT Manager coordinates multiple background services including the Director, Runner, and Visual Renderer components that work together to deliver synchronized playback.\n\n<h4>Configuring Auto-Launch</h4>\n\n<p>For permanent installations, it is critical that WATCHOUT starts automatically when the computer boots. This ensures the system recovers automatically after a power cycle.</p>\n\n<p><strong>Using Windows Task Scheduler (Recommended):</strong></p>\n\n<ol>\n<li><strong>Open Task Scheduler:</strong></li>\n</ol>\n<ul>\n<li>Press <code>Windows Key</code>, type <strong>Task Scheduler</strong>, and press <strong>Enter</strong>.</li>\n<li>Alternatively, press <code>Windows Key + R</code>, type <code>taskschd.msc</code>, and press <strong>Enter</strong>.</li>\n\n</ul>\n<ol>\n<li><strong>Import the Task File:</strong></li>\n</ol>\n<ul>\n<li>In the right-hand <strong>Actions</strong> panel, click <strong>Import Task...</strong>.</li>\n<li>Navigate to your WATCHOUT installation directory (e.g., <code>C:\\WATCHOUT7\\</code>).</li>\n<li>Select the file <code>wo-autostart.xml</code> and click <strong>Open</strong>.</li>\n\n</ul>\n<ol>\n<li><strong>Review Task Settings:</strong></li>\n</ol>\n<ul>\n<li>A dialog will appear showing the task configuration.</li>\n<li>On the <strong>General</strong> tab, ensure <strong>Run with highest privileges</strong> is checked.</li>\n<li>On the <strong>Triggers</strong> tab, verify the trigger is set to <strong>At log on</strong>.</li>\n<li>On the <strong>Actions</strong> tab, confirm the action points to <code>C:\\WATCHOUT7\\process-manager.exe</code> (adjust if you installed elsewhere).</li>\n\n</ul>\n<ol>\n<li><strong>Save the Task:</strong></li>\n</ol>\n<ul>\n<li>Click <strong>OK</strong> to create the scheduled task.</li>\n<li>If prompted for credentials, enter your Windows username and password.</li>\n\n</ul>\n<ol>\n<li><strong>Verify:</strong> Restart the computer to confirm that WATCHOUT Manager launches automatically upon login.</li>\n\n</ol>\n<div class='info-box'><p><strong>Managing the Task:</strong> To edit or delete the task later, open Task Scheduler and look for the task named <strong>WATCHOUT manager</strong> under <em>Task Scheduler Library > WATCHOUT</em>.\n</p></div>\n\n<div class='info-box'><p><strong>Auto-Login:</strong> Ensure your Windows user account is configured to log in automatically without a password prompt. This can be configured using the <code>netplwiz</code> Windows utility.\n</p></div>\n\n<h3>Troubleshooting Launch Issues</h3>\n\n<p>If the application fails to launch:</p>\n\n<ul>\n<li><strong>License Error:</strong> Check that your License Key is plugged in and the light is on. Open CodeMeter Control Center to verify it is detected.</li>\n<li><strong>GPU Driver Error:</strong> Ensure your GPU drivers are up to date. WATCHOUT uses OpenGL for rendering.</li>\n<li><strong>Firewall Prompt:</strong> If Windows asks to allow the application access to the network, check <strong>both</strong> \"Private\" and \"Public\" networks and click <strong>Allow Access</strong>.</li>\n\n</ul>",
      "Network Configuration": "<div class=\"article-metadata\"><span class=\"article-badge\" data-badge=\"Anton\">Anton</span><span class=\"article-badge\" data-badge=\"Jacquie\">Jacquie</span><span class=\"article-badge\" data-badge=\"JME\">JME</span><span class=\"article-badge\" data-badge=\"Karol\">Karol</span></div><h2>Network Configuration</h2>\n\n<p>Establishing a robust and properly configured network is critical for WATCHOUT 7. The system relies on the network not just for file transfer, but for frame-accurate synchronization (UDP) and system control (TCP).</p>\n\n<h3>General Recommendations</h3>\n\n<ul>\n<li><strong>Dedicated Network:</strong> The WATCHOUT network should be a closed, dedicated local area network (LAN). Do <strong>not</strong> connect it to the internet or a general office network alongside your show data.</li>\n<li><strong>Wired Connections:</strong> Always use wired Ethernet connections (Cat5e, Cat6, or fiber). Wi-Fi is not supported for show synchronization due to latency and packet loss.</li>\n<li><strong>Quality Components:</strong> Invest in reliable, professional-grade networking equipment. Consumer-grade hardware may introduce latency spikes or dropped packets under sustained load.</li>\n\n</ul>\n<h3>Recommended Network Hardware</h3>\n\n<p>Choosing the right hardware ensures stable, low-latency communication between your Production and Display computers.</p>\n\n<h4>Network Switches</h4>\n\n<p>For most WATCHOUT installations, a quality unmanaged gigabit switch is sufficient. However, for larger or more demanding setups, consider managed switches that offer greater control.</p>\n\n<table>\n<tr><th>Type</th><th>Use Case</th><th>Recommended Models</th></tr>\n<tr><td><strong>Unmanaged Gigabit</strong></td><td>Small to medium shows<br>(2-8 displays)</td><td>Netgear GS108, TP-Link TL-SG108,<br>Cisco CBS110</td></tr>\n<tr><td><strong>Managed Gigabit</strong></td><td>Medium to large shows,<br>VLANs, QoS</td><td>Cisco CBS250, Netgear GS310TP,<br>Ubiquiti UniFi Switch</td></tr>\n<tr><td><strong>10GbE</strong></td><td>High bandwidth<br>(NDI, 4K+, many outputs)</td><td>Netgear XS508M, MikroTik CRS305,<br>Ubiquiti UniFi 10G</td></tr>\n</table>\n\n<div class='warning-box'><p><strong>Disable Power Saving Features:</strong> If using managed switches, disable \"Green Ethernet,\" \"Energy Efficient Ethernet\" (EEE), and any auto-sleep modes. These features can interrupt synchronization and cause stuttering.\n</p></div>\n\n<h4>Network Interface Cards (NICs)</h4>\n\n<p>Built-in motherboard NICs (Intel I211, I225, Realtek RTL8125) are typically adequate. For demanding workflows (10GbE, NDI sources), consider dedicated add-in cards:</p>\n\n<ul>\n<li><strong>Intel X550-T2:</strong> Dual-port 10GbE, excellent driver support.</li>\n<li><strong>Mellanox ConnectX-3:</strong> High performance, often used in broadcast environments.</li>\n<li><strong>ASUS XG-C100C:</strong> Cost-effective 10GbE option for smaller budgets.</li>\n\n</ul>\n<h4>Cabling</h4>\n\n<ul>\n<li><strong>Cat5e:</strong> Suitable for Gigabit Ethernet up to 100 meters.</li>\n<li><strong>Cat6/Cat6a:</strong> Recommended for 10GbE or runs approaching 100 meters with better shielding.</li>\n<li><strong>Fiber Optic (SFP/SFP+):</strong> Essential for long-distance runs (over 100 meters) or electrically noisy environments (near LED walls, dimmers, etc.).</li>\n\n</ul>\n<h3>IP Addressing</h3>\n\n<p>WATCHOUT computers must be on the same subnet to discover each other. We recommend using static IP addresses to ensure consistent connectivity.</p>\n\n<h4>Recommended Scheme</h4>\n\n<ul>\n<li><strong>Subnet Mask:</strong> <code>255.255.255.0</code> (Class C)</li>\n<li><strong>Production Computer:</strong> <code>192.168.1.10</code></li>\n<li><strong>Display Computers:</strong> <code>192.168.1.11</code>, <code>192.168.1.12</code>, etc.</li>\n\n</ul>\n<div class='warning-box'><p><strong>Avoid DHCP:</strong> While WATCHOUT can technically work with auto-assigned IPs (DHCP), it is strongly discouraged for live environments. IPs can change upon reboot, potentially breaking your mapping and control links.\n</p></div>\n\n<h3>Windows Firewall</h3>\n\n<p>WATCHOUT 7 requires specific network ports to operate. Upon installation, the installer typically adds the necessary rules to the Windows Defender Firewall.</p>\n\n<p>If you need to manage ports manually:</p>\n\n<ul>\n<li><strong>TCP Port 3040:</strong> Main communication.</li>\n<li><strong>UDP Port 3040:</strong> Synchronization.</li>\n<li><strong>Asset Management:</strong> Various ports are used for the new Asset Manager syncing; ensure the <code>Dataton.Watchout.exe</code> and <code>Dataton.Watchout.Display.exe</code> applications are fully allowed through the firewall for both Private and Public profile types.</li>\n\n</ul>\n<h3>Advanced: Jumbo Frames</h3>\n\n<p>For 10GbE networks or systems pushing very high bandwidth video data (especially NDI or uncompressed streams), enabling <strong>Jumbo Frames</strong> (usually 9000 MTU) on all network cards and switches can improve performance. Ensure every device in the chain supports and is configured for the same MTU size.</p>\n\n<div class='info-box'><p><strong>Testing Tip:</strong> After changing MTU settings, use <code>ping -f -l 8972 <target_ip></code> from a command prompt to verify jumbo frames are working end-to-end. If the ping fails, a device in the chain isn't configured correctly.\n</p></div>",
      "Quick Start Tutorial": "<div class=\"article-metadata\"><span class=\"article-badge\" data-badge=\"Jacquie\">Jacquie</span><span class=\"article-badge\" data-badge=\"JME\">JME</span><span class=\"article-badge\" data-badge=\"Karol\">Karol</span></div><h2>Quick Start Tutorial</h2>\n\n<p>Follow these steps to create your first simple presentation in WATCHOUT 7.</p>\n\n<h3>Step 1: Create a New Show</h3>\n\n<ol>\n<li>Launch <strong>WATCHOUT Producer</strong> from the desktop shortcut.</li>\n<li>From the <strong>Welcome Screen</strong>, click <strong>New Show</strong>.</li>\n<li>Choose a location and name for your show file (e.g., \"MyFirstShow.watch\").</li>\n<li>Click <strong>Save</strong>. Your new show opens with an empty Stage and Timeline.</li>\n\n</ol>\n<h3>Step 2: Add a Display</h3>\n\n<div class=\"video-placeholder\">Video Placeholder</div>\n\n<p>In WATCHOUT 7, displays are added directly on the Stage canvas.</p>\n\n<ol>\n<li>Click on an empty area of the <strong>Stage</strong> window to make sure it's active.</li>\n<li>Go to the <strong>Stage</strong> menu and select <strong>Add Display</strong>, or right-click on the Stage and choose <strong>Add Display</strong>.</li>\n<li>A new display rectangle appears. It is automatically selected.</li>\n<li>In the <strong>Properties</strong> panel on the right, configure the display:</li>\n</ol>\n<ul>\n<li><strong>Name:</strong> Give it a descriptive name (e.g., \"Main Screen\").</li>\n<li><strong>Resolution:</strong> Set width and height to match your physical output (e.g., <code>1920</code> x <code>1080</code>).</li>\n<li><strong>Alias:</strong> Enter a name or address to identify the output (this is used when routing to physical devices).</li>\n</ul>\n<ol>\n<li>Position the display on the Stage by dragging it to your desired location.</li>\n\n</ol>\n<h3>Step 3: Import Media</h3>\n\n<video src=\"../media/add_media.mp4?t=1770830222408\" class=\"content-video\" autoplay muted loop playsinline title=\"Adding media to the Asset Manager\"></video>\n\n<p>WATCHOUT 7 uses the <strong>Asset Manager</strong> to handle all media.</p>\n\n<ol>\n<li>Open the <strong>Assets</strong> window by going to <strong>Window > Assets</strong> or pressing <code>Ctrl+4</code>.</li>\n<li>Use <strong>File > New Media File</strong> to add media, or drag files directly from Windows Explorer into the Assets window.</li>\n<li>Select your image or video files and click <strong>Open</strong>.</li>\n<li>The files are now listed in the Assets window and are ready to be used.</li>\n\n</ol>\n<h3>Step 4: Place Media on the Timeline</h3>\n\n<video src=\"../media/add_to_timeline.mp4?t=1770830222409\" class=\"content-video\" autoplay muted loop playsinline title=\"Placing media on the Timeline\"></video>\n\n<ol>\n<li>In the <strong>Assets</strong> window, select the media you want to use.</li>\n<li>Drag the media from the Assets window directly onto the <strong>Timeline</strong> window.</li>\n<li>This creates a new <strong>Media Cue</strong> on a layer.</li>\n<li>Drag the cue left or right to adjust its start time, or drag its edges to change its duration.</li>\n\n</ol>\n<h3>Step 5: Position on Stage</h3>\n\n<video src=\"../media/playhead.mp4?t=1770830222410\" class=\"content-video\" autoplay muted loop playsinline title=\"Moving the Playhead\"></video>\n\n<ol>\n<li>Move the <strong>Playhead</strong> (the red vertical line on the Timeline) so it is positioned over your cue.</li>\n<li>Your media will now be visible in the <strong>Stage</strong> window.</li>\n<li>Click and drag the media directly on the Stage to position it within your display area.</li>\n<li>Use the handles to resize or rotate the media as needed.</li>\n\n</ol>\n<h3>Step 6: Set Up a Display Node</h3>\n\n<div class=\"video-placeholder\">Video Placeholder</div>\n\n<p>Before you can see your content on a physical screen, you need to configure a <strong>Display Node</strong> — the computer that will render and output the visuals.</p>\n\n<ol>\n<li>On your Display Computer, launch the <strong>WATCHOUT Manager</strong> from the desktop shortcut.</li>\n<li>The splash screen will appear on connected displays, showing the WATCHOUT logo while waiting for a connection.</li>\n<li>Back on your Producer computer, open the <strong>Network</strong> window by going to <strong>Window > Network</strong> or pressing <code>Ctrl+5</code>.</li>\n<li>Your Display Computer should appear in the list as a node with available services. If it doesn't:</li>\n</ol>\n<ul>\n<li>Ensure both computers are on the same network subnet.</li>\n<li>Check that Windows Firewall allows WATCHOUT through (both Private and Public networks).</li>\n</ul>\n<ol>\n<li>In the <strong>Stage</strong> window, select your display rectangle.</li>\n<li>In the <strong>Properties</strong> panel, configure the <strong>Route</strong> to specify which device and output channel to use.</li>\n<li>Connect to a <strong>Director</strong> by clicking <strong>Connect</strong> in the Welcome Screen or using <strong>File > Connect</strong>. The Director coordinates playback across all your nodes.</li>\n\n</ol>\n<h3>Step 7: Run the Show</h3>\n\n<div class=\"video-placeholder\">Video Placeholder</div>\n\n<ol>\n<li>Press the <strong>Spacebar</strong> or click the <strong>Play</strong> button to start playback.</li>\n<li>The Timeline will play forward from the current position of the Playhead.</li>\n<li>Watch your physical screen—the content will be perfectly synchronized.</li>\n\n</ol>\n<div class='info-box'><p><strong>Tip:</strong> Use <strong>Ctrl+Home</strong> to jump to the beginning of the timeline before pressing play.\n</p></div>"
    }
  },
  "2. The Interface": {
    "overview": "<h1>THE INTERFACE</h1>\n\n<p>WATCHOUT 7 features a modern, flexible interface designed for efficient show production. Learn how to navigate and customize your workspace for maximum productivity.</p>",
    "sections": {
      "Main Window Overview": "<h2>Main Window Overview</h2>\n\n<p>The WATCHOUT 7 <strong>Producer</strong> interface presents a modern, flexible workspace designed for efficient show creation and management. The application uses a windowed design where each component operates in its own resizable, repositionable window, allowing you to customize your workspace to match your project requirements and personal preferences.</p>\n\n<h3>Window Architecture</h3>\n\n<p>WATCHOUT 7 employs a <strong>multi-document interface</strong> where all primary functions exist as separate windows within the main application frame:</p>\n\n<ul>\n<li><strong>Stage</strong> – Your visual canvas showing all displays and content positioning</li>\n<li><strong>Timeline</strong> – Where you arrange and time cues for your show</li>\n<li><strong>Assets</strong> – Your media library for managing project files</li>\n<li><strong>Properties</strong> – Context-sensitive settings for selected items</li>\n<li><strong>Network</strong> – Device discovery and connection management</li>\n\n</ul>\nEach window can be:\n\n<ul>\n<li><strong>Moved</strong> – Drag the title bar to reposition</li>\n<li><strong>Resized</strong> – Drag corners or edges to adjust dimensions</li>\n<li><strong>Closed</strong> – Click the × button in the title bar</li>\n<li><strong>Docked</strong> – Hold <code>Ctrl</code> and double-click the title bar to dock to an edge</li>\n\n</ul>\n<h3>Menu Bar</h3>\n\n<p>The <strong>Menu Bar</strong> provides access to all application commands organized in logical groups:</p>\n\n<table>\n<tr><th>Menu</th><th>Purpose</th></tr>\n<tr><td><strong>File</strong></td><td>Create, open, save, and export shows</td></tr>\n<tr><td><strong>Edit</strong></td><td>Undo, redo, cut, copy, paste, and selection commands</td></tr>\n<tr><td><strong>Stage</strong></td><td>Display and projector management, view controls</td></tr>\n<tr><td><strong>Media</strong></td><td>Add and manage media files</td></tr>\n<tr><td><strong>Timeline</strong></td><td>Layer, cue, and playback controls</td></tr>\n<tr><td><strong>Tween</strong></td><td>Animation property toggles</td></tr>\n<tr><td><strong>Window</strong></td><td>Workspace layout and window visibility</td></tr>\n<tr><td><strong>Help</strong></td><td>Documentation, licenses, and about information</td></tr>\n</table>\n\n<h3>Keyboard Accelerators</h3>\n\n<p>Most menu commands have associated keyboard shortcuts displayed alongside the command name. Common accelerators follow standard conventions:</p>\n\n<ul>\n<li><code>Ctrl+N</code> – New show</li>\n<li><code>Ctrl+O</code> – Open show</li>\n<li><code>Ctrl+S</code> – Save show</li>\n<li><code>Ctrl+Z</code> – Undo</li>\n<li><code>Ctrl+Shift+Z</code> – Redo</li>\n<li><code>Spacebar</code> – Toggle playback</li>\n\n</ul>\n<h3>Theme Support</h3>\n\n<p>WATCHOUT 7 supports both <strong>dark</strong> and <strong>light</strong> visual themes. Toggle between themes via <strong>Window → Light Theme</strong> or through preferences. The dark theme reduces eye strain in low-light production environments, while the light theme may be preferred in brighter working conditions.</p>\n\n<h3>Director Connection Status</h3>\n\n<p>The interface displays real-time connection status to the <strong>Director</strong> service. When connected, windows requiring Director communication (such as Timeline and Assets) show full functionality. When disconnected, these windows display an offline indicator with the message \"Director offline\" and a cloud-off icon.</p>\n\n<h3>Window Focus</h3>\n\n<p>The currently active window displays with enhanced visual prominence—a brighter border and stronger shadow in dark mode. Only the focused window receives keyboard input, and clicking any window brings it to the front and transfers focus.</p>",
      "The Stage Window": "<h2>The Stage Window</h2>\n\n<p>The <strong>Stage</strong> is your visual canvas—a representation of all your displays and how content appears on them. It provides a unified view of your entire display arrangement, allowing you to position and manipulate content directly.</p>\n\n<h3>Stage Modes</h3>\n\n<p>The Stage window operates in three distinct modes, accessible via the topbar button or the <strong>Stage</strong> menu:</p>\n\n<table>\n<tr><th>Mode</th><th>Description</th></tr>\n<tr><td><strong>Default (Front View)</strong></td><td>Standard 2D editing view for positioning and arranging content</td></tr>\n<tr><td><strong>FPS Camera</strong></td><td>First-person navigation for 3D environments with WASD-style controls</td></tr>\n<tr><td><strong>Projector View</strong></td><td>View the Stage from a selected projector's perspective for calibration</td></tr>\n</table>\n\n<h3>Navigation Controls</h3>\n\n<h4>Pan</h4>\n\n<p>Move your view around the Stage:</p>\n\n<ul>\n<li><strong>Mouse</strong> – Hold <code>Ctrl+Alt</code> and drag</li>\n<li><strong>Button</strong> – Click the pan button (hand icon) in the top-right toolbar and drag</li>\n\n</ul>\n<h4>Zoom / Scale</h4>\n\n<p>Adjust your view magnification:</p>\n\n<ul>\n<li><strong>Mouse Wheel</strong> – <code>Ctrl+Mouse Wheel</code> to zoom in/out</li>\n<li><strong>Button</strong> – Click the magnify button and drag vertically</li>\n<li><strong>Menu</strong> – <strong>Stage → Scale</strong> with preset levels (1:16, 1:8, 1:4, 1:2, 1:1)</li>\n\n</ul>\nThe current scale ratio displays in the title bar when in Front View mode.\n\n<h4>Orbit (3D Views)</h4>\n\n<p>When not in Front View:</p>\n\n<ul>\n<li><strong>Button</strong> – Click the orbit button (rotate icon) and drag to rotate the camera around the Stage</li>\n\n</ul>\n<h4>Camera Velocity</h4>\n\n<p>In 3D modes, adjust movement speed using the velocity slider (running figure icon).</p>\n\n<h3>View Commands</h3>\n\n<table>\n<tr><th>Shortcut</th><th>Command</th><th>Description</th></tr>\n<tr><td><code>Ctrl+Shift+D</code></td><td>Frame All Displays</td><td>Zoom to fit all displays in the viewport</td></tr>\n<tr><td><code>Ctrl+Shift+O</code></td><td>Scroll to Origin</td><td>Center the view on coordinates (0, 0)</td></tr>\n<tr><td><code>Ctrl+Shift+S</code></td><td>Frame Selected</td><td>Zoom to fit selected displays</td></tr>\n</table>\n\n<h3>Working with Content</h3>\n\n<h4>Selection</h4>\n\n<ul>\n<li><strong>Single Click</strong> – Select a cue or display</li>\n<li><strong>Shift+Click</strong> – Add to selection</li>\n<li><strong>Ctrl+Click</strong> – Toggle selection</li>\n<li><strong>Marquee</strong> – Click and drag on empty space to create a selection rectangle</li>\n\n</ul>\n<h4>Transformation</h4>\n\n<p>Selected cues can be manipulated directly on the Stage:</p>\n\n<ul>\n<li><strong>Move</strong> – Drag selected items to reposition</li>\n<li><strong>Resize</strong> – Drag corner or edge handles</li>\n<li><strong>Rotate</strong> – Use rotation handles when available</li>\n<li><strong>Nudge</strong> – Arrow keys move selection by 1 pixel; <code>Shift+Arrow</code> moves by 10 pixels</li>\n\n</ul>\n<h4>Drag and Drop</h4>\n\n<p>Drag media from the <strong>Assets</strong> window directly onto the Stage to create cues at the drop location.</p>\n\n<h3>Display Labels</h3>\n\n<p>When enabled, display names appear centered on each display rectangle, making it easy to identify outputs in complex multi-display configurations.</p>\n\n<h3>Projector Mode</h3>\n\n<p>When viewing from a projector's perspective, additional controls appear for calibration:</p>\n\n<ul>\n<li><strong>View Mode</strong> – Preview content as the projector sees it</li>\n<li><strong>Calibration Mode</strong> – Adjust 2D or 3D calibration points</li>\n<li><strong>Calibration Actions</strong> – Add, move, or remove calibration points</li>\n<li><strong>Snap Toggle</strong> – Enable snapping to geometry</li>\n<li><strong>Link Toggle</strong> – Link calibration points across projectors</li>\n<li><strong>Accuracy Display</strong> – Shows current calibration accuracy percentage</li>\n\n</ul>\n<h3>Composition View</h3>\n\n<p>When editing a <strong>Composition</strong> cue, the Stage displays the composition's internal canvas rather than the main Stage, indicated by a border around the viewport and a gantt chart icon in the title bar.</p>",
      "The Timeline Window": "<h2>The Timeline Window</h2>\n\n<p>The <strong>Timeline</strong> is where you orchestrate your show—arranging media and controlling precisely when things happen. It provides a horizontal time-based view of your content, organized in layers.</p>\n\n<h3>Timeline Structure</h3>\n\n<p>The Timeline window is divided into several key areas:</p>\n\n<h4>Header Area</h4>\n\n<ul>\n<li><strong>Timecode Display</strong> – Shows the current playback position in hours:minutes:seconds:frames format. Click to jump to a specific time.</li>\n<li><strong>Sync Indicator</strong> – Displays synchronization status with the Director</li>\n<li><strong>Cue Status Line</strong> – Shows information about selected cues</li>\n<li><strong>Countdown Display</strong> – Indicates time remaining until the next pause cue</li>\n\n</ul>\n<h4>Layer Headers</h4>\n\n<p>The left column displays layer names. Each layer is a horizontal track for organizing content:</p>\n\n<ul>\n<li><strong>Layer Name</strong> – Custom name or default \"Layer N\" numbering</li>\n<li><strong>Key and Fill Mode</strong> – Icon indicates if a layer uses luma or alpha keying</li>\n<li><strong>Selection Highlight</strong> – Active layer appears with elevated background</li>\n\n</ul>\nLayers are ordered with higher numbers appearing on top in the Stage view.\n\n<h4>Time Ruler</h4>\n\n<p>The horizontal ruler at the top of the cue area shows time in your configured format. Features include:</p>\n\n<ul>\n<li><strong>Time Markings</strong> – Major and minor divisions based on zoom level</li>\n<li><strong>Play Cursor Indicator</strong> – Triangle marker showing current time</li>\n<li><strong>Click to Jump</strong> – Click in the ruler to move the play cursor (when \"Click Jumps to Time\" is enabled)</li>\n\n</ul>\n<h4>Cue Area</h4>\n\n<p>The main workspace where cues are displayed:</p>\n\n<ul>\n<li><strong>Tracks</strong> – Horizontal lanes corresponding to layers</li>\n<li><strong>Cues</strong> – Colored rectangles representing media and control cues</li>\n<li><strong>Play Cursor</strong> – Vertical red line showing current playback position</li>\n<li><strong>Overlap Indicators</strong> – Cues that overlap in time on the same layer show warning styling</li>\n\n</ul>\n<h4>Tween Curves Panel</h4>\n\n<p>When a media cue is selected, the lower panel displays animation curves showing how properties change over time.</p>\n\n<h4>Minimap</h4>\n\n<p>The bottom bar shows a compressed overview of your entire timeline, with:</p>\n\n<ul>\n<li><strong>Visible Range Indicator</strong> – Shows which portion of the timeline is currently displayed</li>\n<li><strong>Pan Control</strong> – Drag to scroll horizontally</li>\n<li><strong>Play Position</strong> – Small indicator of current playback time</li>\n<li><strong>Cue Overview</strong> – Tiny representations of all cues</li>\n\n</ul>\n<h3>Playback Controls</h3>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Spacebar</code></td><td>Toggle play/pause</td></tr>\n<tr><td><code>Numpad 0</code></td><td>Start playback</td></tr>\n<tr><td><code>Escape</code></td><td>Pause</td></tr>\n<tr><td><code>Home</code></td><td>Jump to beginning</td></tr>\n<tr><td><code>End</code></td><td>Jump to end</td></tr>\n<tr><td><code>Numpad +</code></td><td>Zoom in</td></tr>\n<tr><td><code>Numpad -</code></td><td>Zoom out</td></tr>\n</table>\n\n<h3>Working with Layers</h3>\n\n<table>\n<tr><th>Action</th><th>Method</th></tr>\n<tr><td>Add Layer</td><td><strong>Timeline → Append Layer</strong> or <code>Ctrl+I</code></td></tr>\n<tr><td>Insert Layer</td><td><strong>Timeline → Insert Layer</strong></td></tr>\n<tr><td>Delete Layer</td><td><strong>Timeline → Delete Layer</strong></td></tr>\n<tr><td>Select Layer</td><td>Click the layer header</td></tr>\n<tr><td>Rename Layer</td><td>Double-click layer header to open Properties</td></tr>\n</table>\n\n<h3>Working with Cues</h3>\n\n<h4>Adding Cues</h4>\n\n<ul>\n<li><strong>Drag and Drop</strong> – Drag media from Assets onto the Timeline</li>\n<li><strong>Menu</strong> – Use <strong>Timeline → Add</strong> submenu for control cues</li>\n\n</ul>\n<h4>Selecting Cues</h4>\n\n<ul>\n<li><strong>Click</strong> – Select a single cue</li>\n<li><strong>Shift+Click</strong> – Add to selection</li>\n<li><strong>Ctrl+Click</strong> – Toggle selection</li>\n<li><strong>Marquee</strong> – Drag on empty track space to select multiple cues</li>\n\n</ul>\n<h4>Editing Cues</h4>\n\n<ul>\n<li><strong>Move</strong> – Drag cues left/right to change timing; drag up/down to change layers</li>\n<li><strong>Resize Start</strong> – Drag the left edge to adjust in-point</li>\n<li><strong>Resize End</strong> – Drag the right edge to adjust duration</li>\n<li><strong>Trim to Time</strong> – Use <strong>Timeline → Trim Start</strong> or <strong>Trim End</strong> to cut at play cursor</li>\n<li><strong>Double-click</strong> – Open Properties panel for detailed editing</li>\n\n</ul>\n<h4>Cue Context Menu</h4>\n\n<p>Right-click a cue for common actions:</p>\n\n<ul>\n<li>Cut, Copy, Paste, Delete</li>\n<li>Group / Ungroup cues</li>\n<li>Add tweens</li>\n<li>Fade In, Fade Out, Cross Fade</li>\n\n</ul>\n<h3>Snapping</h3>\n\n<p>When <strong>Edit → Snap</strong> is enabled, cues snap to:</p>\n\n<ul>\n<li>Other cue edges</li>\n<li>The play cursor</li>\n<li>Time ruler divisions</li>\n\n</ul>\nA highlight appears when snapping occurs.\n\n<h3>Timeline Identification</h3>\n\n<p>When multiple timelines exist, the window title displays the timeline name and ID number (e.g., \"Main #1\").</p>",
      "The Cue List Window": "<h2>The Cue List Window</h2>\n\n<p>The <strong>Cue List</strong> window provides a flat, tabular view of all cues across every timeline in your show. While the Timeline window displays cues graphically along a time axis within a single timeline, the Cue List presents them as sortable, filterable rows in a table — making it ideal for auditing, searching, and managing cues across the entire production.</p>\n\n<p>The Cue List is especially valuable in large shows where cues are spread across many timelines. It lets you quickly locate specific cues by name, type, or media source without switching between timelines.</p>\n\n<h3>Opening the Cue List</h3>\n\n<p>Open the Cue List window from <strong>Window → Cues</strong>. The window operates alongside the Timeline and Stage windows — selecting a cue in the Cue List also selects it in the Timeline and updates the Properties panel, and vice versa.</p>\n\n<h3>Column Layout</h3>\n\n<p>The Cue List displays cues in a table with the following columns. Not all columns are visible by default — you can choose which to show or hide.</p>\n\n<ul>\n<li><strong>Timeline</strong> — the name of the timeline containing the cue. A lock icon appears next to the name indicating the cue's lock state. If the cue belongs to a Blind Edit timeline, an eye-off icon appears to identify it.</li>\n<li><strong>Image</strong> — a thumbnail preview of the cue's media asset, when applicable.</li>\n<li><strong>Name</strong> — the cue's name. Cues with errors (such as missing assets) display their name in a warning color.</li>\n<li><strong>Type</strong> — the cue kind, such as Media, Control, Output, Variable, or Marker. For media cues, the source type is shown in parentheses (e.g., \"Media (Asset)\", \"Media (Capture)\", \"Media (Composition)\").</li>\n<li><strong>Tier</strong> — the stage tier(s) the cue is assigned to. Hidden by default.</li>\n<li><strong>Start</strong> — the cue's start time in the timeline, displayed in timecode format.</li>\n<li><strong>Duration</strong> — the cue's duration. Hidden by default.</li>\n<li><strong>Countdown</strong> — for marker cues, shows a live countdown to the cue's position relative to the current playback time.</li>\n<li><strong>Cue Set</strong> — shows the cue set (group) name and current variant, if the cue belongs to a cue set. Hidden by default.</li>\n\n</ul>\n<h3>Choosing Visible Columns</h3>\n\n<p>Click the <strong>column chooser</strong> button in the top-right corner of the window to open a menu listing all available columns. Toggle columns on or off by clicking their names. The column chooser also includes a <strong>Reset Columns</strong> option to restore the default column visibility and ordering.</p>\n\n<p>Columns can be reordered by dragging their headers in the table. Column widths are adjustable by dragging the borders between column headers.</p>\n\n<h3>Sorting</h3>\n\n<p>Click any sortable column header to cycle through three states:</p>\n\n<ol>\n<li><strong>Ascending</strong> — rows sorted A→Z or earliest→latest. The table switches to a flat view (no tree grouping).</li>\n<li><strong>Descending</strong> — rows sorted Z→A or latest→earliest.</li>\n<li><strong>No sort</strong> — returns to the default ordering (by timeline, then start time).</li>\n\n</ol>\nYou can sort by multiple columns simultaneously. The first column you click is the primary sort key; additional columns serve as tiebreakers. The sort indicator on each column header shows the current direction.\n\n<h3>Filtering</h3>\n\n<p>The Cue List includes a powerful filter panel for narrowing down the displayed cues. Click the <strong>filter icon</strong> in the toolbar to expand the filter panel, or press <code>Ctrl+F</code>.</p>\n\n<p>The filter panel offers several filter dimensions that work together — only cues matching all active filters are shown:</p>\n\n<h4>Text Search</h4>\n\n<p>The <strong>Cue Name</strong> field filters by name. Type a search term and the list updates in real time (with a short debounce for performance). Clear the field to remove the text filter.</p>\n\n<h4>Include by Cue Kind</h4>\n\n<p>Toggle which cue kinds are included in the list:</p>\n\n<ul>\n<li><strong>Control</strong> — playback control cues (go, pause, stop, etc.)</li>\n<li><strong>Output</strong> — output-level cues</li>\n<li><strong>Variable</strong> — variable/input cues</li>\n<li><strong>Marker</strong> — comment/marker cues used for notes and countdown triggers</li>\n\n</ul>\nMedia cues are controlled separately through the media source filter below.\n\n<h4>Media Source Filter</h4>\n\n<p>The <strong>Media</strong> multi-select dropdown controls which types of media cues are shown:</p>\n\n<ul>\n<li><strong>Assets</strong> — cues referencing media assets (images, video, audio)</li>\n<li><strong>Virtual Displays</strong> — cues sourcing from virtual displays</li>\n<li><strong>Compositions</strong> — cues referencing compositions</li>\n<li><strong>Captures</strong> — cues sourcing from NDI/capture inputs</li>\n\n</ul>\n<h4>Cue Sets and Tiers</h4>\n\n<p>Additional multi-select dropdowns let you filter by:</p>\n\n<ul>\n<li><strong>Cue Sets</strong> — show only cues belonging to specific cue set groups</li>\n<li><strong>Tier</strong> — show only cues assigned to specific stage tiers (this filter appears only when stage tiers are defined)</li>\n\n</ul>\n<h4>Follow Selected</h4>\n\n<p>The <strong>Follow Selected</strong> toggles synchronize the Cue List with selections made in other windows:</p>\n\n<ul>\n<li><strong>Assets</strong> — when enabled, the list shows only cues that use the currently selected asset(s) in the Assets window</li>\n<li><strong>Timelines</strong> — limits the list to cues in the currently selected timeline(s)</li>\n<li><strong>Captures</strong> — limits to cues using the selected capture source(s)</li>\n<li><strong>Virtual Displays</strong> — limits to cues using the selected virtual display(s)</li>\n<li><strong>Active Timeline</strong> — limits to cues in the currently active (focused) timeline</li>\n\n</ul>\nThese follow filters are additive — enabling multiple follow options shows cues matching any of them.\n\n<h4>Selected Cues Only</h4>\n\n<p>The <strong>Selected Cues Only</strong> toggle restricts the list to display only cues that are currently selected. This is useful when you have a multi-selection and want to inspect or operate on just those cues.</p>\n\n<h3>Filter Presets</h3>\n\n<p>You can save filter configurations as named presets for quick recall:</p>\n\n<ul>\n<li><strong>Save</strong> — click the save/plus button to create a new preset with the current filter settings. You'll be prompted to enter a name.</li>\n<li><strong>Load</strong> — select a preset from the <strong>Preset</strong> dropdown to apply its saved filter configuration.</li>\n<li><strong>Update</strong> — if you've modified a loaded preset, click the save button to update it with the current settings.</li>\n<li><strong>Delete</strong> — click the delete button to remove the currently selected preset.</li>\n<li><strong>Restore</strong> — if you've changed the filter after loading a preset, click the restore button to revert to the preset's saved settings.</li>\n\n</ul>\nThe toolbar displays the active preset name when one is loaded. If the filter has been modified from the preset, the indicator shows \"No Preset\" to reflect the unsaved state.\n\n<h3>Selecting Cues</h3>\n\n<p>Cue selection in the Cue List is synchronized with the rest of the application through a shared global cue selection:</p>\n\n<ul>\n<li><strong>Click</strong> a row to select a single cue</li>\n<li><strong>Shift+Click</strong> to extend the selection to a range</li>\n<li><strong>Ctrl+Click</strong> to toggle individual cues in and out of the selection</li>\n<li><strong>Ctrl+A</strong> selects all visible cues in the list</li>\n\n</ul>\nSelecting a cue in the Cue List highlights it in the Timeline window and loads its properties in the Properties panel. Conversely, selecting a cue in the Timeline updates the Cue List selection.\n\n<p><strong>Double-clicking</strong> a cue row activates the corresponding Timeline window and scrolls to that cue's position, making it easy to jump from the list view to the graphical timeline context. Hold <code>Alt</code> while double-clicking to also jump the play cursor to the cue's start time.</p>\n\n<h3>Locking and Unlocking Cues</h3>\n\n<p>Each row in the Cue List displays a lock icon to the left of the timeline name:</p>\n\n<ul>\n<li><strong>Unlocked</strong> (open lock icon) — click to lock the cue, preventing accidental edits</li>\n<li><strong>Locked</strong> (closed lock icon) — click to unlock the cue and allow editing</li>\n<li><strong>Locked upstream</strong> (dimmed lock icon) — the cue is locked because its parent timeline is locked. This cannot be toggled from the cue level; unlock the timeline instead.</li>\n\n</ul>\nWhen multiple cues are selected, clicking the lock/unlock icon on any selected cue applies the action to all selected cues simultaneously.\n\n<h3>Blind Edit Indicator</h3>\n\n<p>Cues belonging to a Blind Edit timeline are visually distinguished with a special highlight style and an eye-off icon in the Timeline column. Blind Edit mode allows you to make changes to a timeline that is currently playing without those changes taking effect until you apply them. The Cue List makes it easy to identify which cues are in this state.</p>\n\n<h3>Context Menu</h3>\n\n<p>Right-click a cue (or the table background) to access context menu actions:</p>\n\n<ul>\n<li><strong>Cut / Copy / Paste / Delete</strong> — standard clipboard operations for cues</li>\n<li><strong>Open Composition</strong> — for composition cues, opens the composition's internal timeline for editing in a new window</li>\n<li><strong>Lock / Unlock</strong> — toggle the lock state of selected cues</li>\n\n</ul>\n<h3>Drag and Drop</h3>\n\n<p>The Cue List supports drag-and-drop interactions:</p>\n\n<ul>\n<li><strong>Drag assets</strong> from the Assets window onto a cue row to replace that cue's media source</li>\n<li><strong>Drag assets</strong> onto the table background to apply the media to all selected cues</li>\n<li><strong>Drag devices</strong> (virtual displays, captures) onto cues to assign them as media sources</li>\n\n</ul>\nWhen dropping media onto a selection that includes cues both inside and outside the visible list, a dialog asks whether you want to update only the cues in the list, only the target cue, or all selected cues.\n\n<div class='info-box'><p>Use the Cue List's filter presets to set up common views for different stages of production — for example, a \"Media Only\" preset for content review, a \"Markers\" preset for show calling, and an \"All Cues\" preset for full auditing.\n</p></div>",
      "The Assets Window": "<h2>The Assets Window</h2>\n\n<p>The <strong>Assets</strong> window is your media library—the central repository for all images, videos, audio files, and other resources available for use in your show. It connects to the <strong>Asset Manager</strong> service to provide organization, search, and status tracking for your project media.</p>\n\n<h3>Asset Manager Connection</h3>\n\n<p>The Assets window requires connection to an <strong>Asset Manager</strong> service to function. Connection status displays in the window:</p>\n\n<ul>\n<li><strong>Connected</strong> – Full functionality available</li>\n<li><strong>Offline</strong> – Window shows \"Asset Manager offline\" with cloud-off icon</li>\n\n</ul>\nConfigure the Asset Manager host via <strong>Network → Use Asset Manager</strong>.\n\n<h3>Interface Layout</h3>\n\n<p>The Assets window displays your media in a hierarchical tree table:</p>\n\n<table>\n<tr><th>Column</th><th>Description</th></tr>\n<tr><td><strong>Name</strong></td><td>File name with icon indicating asset type</td></tr>\n<tr><td><strong>Status</strong></td><td>Optimization and transfer state</td></tr>\n<tr><td><strong>Duration</strong></td><td>Length for video and audio files</td></tr>\n<tr><td><strong>Resolution</strong></td><td>Width × Height for image and video files</td></tr>\n<tr><td><strong>Format</strong></td><td>File type and codec information</td></tr>\n</table>\n\n<h3>Adding Media</h3>\n\n<h4>Drag and Drop</h4>\n\n<p>Drag files directly from Windows Explorer into the Assets window.</p>\n\n<h4>Menu Commands</h4>\n\n<ul>\n<li><strong>Media → Add Media File</strong> – Browse and select individual files</li>\n<li><strong>Media → Add Image Sequence</strong> – Select a folder containing numbered image sequences</li>\n\n</ul>\n<h4>Supported Formats</h4>\n\n<p>WATCHOUT 7 supports a wide variety of media types:</p>\n\n<ul>\n<li><strong>Images</strong> – PNG, JPEG, TIFF, BMP, WebP, EXR, PSD</li>\n<li><strong>Video</strong> – MP4, MOV, AVI, MKV, HAP, ProRes, H.264, H.265/HEVC</li>\n<li><strong>Audio</strong> – WAV, MP3, AAC, FLAC, OGG</li>\n<li><strong>Other</strong> – SVG, PDF, image sequences</li>\n\n</ul>\n<h3>Search and Filtering</h3>\n\n<h4>Search Bar</h4>\n\n<p>Click the magnifying glass icon or press <code>Ctrl+F</code> to reveal the search panel:</p>\n\n<ul>\n<li><strong>Text Search</strong> – Find assets by name</li>\n<li><strong>Type Filter</strong> – Filter by media type (images, video, audio, etc.)</li>\n<li><strong>Status Filters</strong> – Show only new assets or assets being prepared</li>\n\n</ul>\nPress <code>Escape</code> to close the search panel and reset filters.\n\n<h4>Filter Options</h4>\n\n<table>\n<tr><th>Filter</th><th>Description</th></tr>\n<tr><td><strong>Only New</strong></td><td>Show assets recently added</td></tr>\n<tr><td><strong>Preparing</strong></td><td>Show assets currently being optimized</td></tr>\n</table>\n\n<h3>Organization</h3>\n\n<h4>Folders</h4>\n\n<p>Create folders to organize your assets:</p>\n\n<ul>\n<li>Right-click and select <strong>Add Folder</strong></li>\n<li>Use <strong>Media → Add Folder</strong></li>\n\n</ul>\nDrag assets into folders to group related media.\n\n<h4>Folder Navigation</h4>\n\n<ul>\n<li><strong>Expand</strong> – Click the arrow or double-click the folder</li>\n<li><strong>Collapse</strong> – Click the arrow or use <strong>Media → Collapse All Folders</strong></li>\n<li><strong>Expand All</strong> – <strong>Media → Expand All Folders</strong></li>\n\n</ul>\n<h3>Asset Status</h3>\n\n<p>Each asset displays a status indicator showing its readiness:</p>\n\n<table>\n<tr><th>Status</th><th>Meaning</th></tr>\n<tr><td><strong>New</strong></td><td>Recently added, not yet processed</td></tr>\n<tr><td><strong>Preparing</strong></td><td>Being optimized for playback</td></tr>\n<tr><td><strong>Ready</strong></td><td>Optimized and available for use</td></tr>\n<tr><td><strong>Transferring</strong></td><td>Being sent to display servers</td></tr>\n<tr><td><strong>Online</strong></td><td>Available on all assigned display servers</td></tr>\n<tr><td><strong>Error</strong></td><td>Problem with file or optimization</td></tr>\n</table>\n\n<h3>Using Assets</h3>\n\n<h4>Add to Timeline</h4>\n\n<p>Drag an asset from the Assets window onto:</p>\n\n<ul>\n<li><strong>Timeline</strong> – Creates a cue at the drop position</li>\n<li><strong>Stage</strong> – Creates a cue at the visual drop location</li>\n<li><strong>Existing Cue</strong> – Replaces the cue's media source</li>\n\n</ul>\n<h4>Find Associated Cues</h4>\n\n<p>Right-click an asset and select <strong>Find Cues</strong> to locate all cues using that asset.</p>\n\n<h3>Asset Properties</h3>\n\n<p>Select an asset and view its properties in the <strong>Properties</strong> panel:</p>\n\n<ul>\n<li><strong>File Path</strong> – Location of the source file</li>\n<li><strong>Resolution</strong> – Native width and height</li>\n<li><strong>Duration</strong> – Length for time-based media</li>\n<li><strong>Frame Rate</strong> – For video files</li>\n<li><strong>Codec</strong> – Encoding information</li>\n<li><strong>Color Space</strong> – HDR and color profile information</li>\n\n</ul>\n<h3>Context Menu</h3>\n\n<p>Right-click assets to access common operations:</p>\n\n<ul>\n<li><strong>Add to Timeline</strong> – Create a cue using this asset</li>\n<li><strong>Reveal in Explorer</strong> – Open the containing folder</li>\n<li><strong>Delete</strong> – Remove from the asset library</li>\n<li><strong>Properties</strong> – Open detailed properties</li>\n\n</ul>",
      "The Properties Panel": "<h2>The Properties Panel</h2>\n\n<p>The <strong>Properties</strong> panel is a context-sensitive inspector that displays settings for whatever is currently selected—displays, cues, layers, tweens, assets, or application preferences.</p>\n\n<h3>Dynamic Content</h3>\n\n<p>The Properties panel automatically adapts to show relevant settings based on your current selection:</p>\n\n<table>\n<tr><th>Selection</th><th>Properties Shown</th></tr>\n<tr><td><strong>No selection</strong></td><td>Application Preferences</td></tr>\n<tr><td><strong>Cue</strong></td><td>Cue properties (position, timing, effects)</td></tr>\n<tr><td><strong>Layer</strong></td><td>Layer settings (name, key and fill options)</td></tr>\n<tr><td><strong>Tween</strong></td><td>Tween curve properties</td></tr>\n<tr><td><strong>Tween Point</strong></td><td>Individual keyframe values</td></tr>\n<tr><td><strong>Asset</strong></td><td>Media file information</td></tr>\n<tr><td><strong>Display</strong></td><td>Display configuration</td></tr>\n<tr><td><strong>Device</strong></td><td>Network device settings</td></tr>\n<tr><td><strong>Stage (background)</strong></td><td>Stage display settings</td></tr>\n</table>\n\n<h3>Accessing Properties</h3>\n\n<ul>\n<li><strong>Automatic</strong> – Select any item and its properties appear</li>\n<li><strong>Double-click</strong> – Double-click items in Stage or Timeline to focus the Properties panel</li>\n<li><strong>Keyboard</strong> – Press <code>Enter</code> with selection to shift focus to Properties</li>\n<li><strong>Menu</strong> – <strong>Window → Properties</strong> or <code>Ctrl+P</code></li>\n\n</ul>\n<h3>Property Categories</h3>\n\n<p>Properties are organized into collapsible categories for easier navigation. Each category can be expanded or collapsed by clicking its header.</p>\n\n<h4>Cue Properties</h4>\n\n<p>When a media cue is selected:</p>\n\n<ul>\n<li><strong>Transform</strong></li>\n<li>Position (X, Y, Z)</li>\n<li>Scale (Width, Height, or unified)</li>\n<li>Rotation (Roll, Pitch, Yaw)</li>\n<li>Anchor Point</li>\n\n<p><li><strong>Appearance</strong></li> <li>Opacity</li> <li>Crop (Top, Bottom, Left, Right)</li> <li>Blur</li></p>\n\n<p><li><strong>Color</strong></li> <li>Brightness</li> <li>Contrast</li> <li>Gamma</li> <li>Hue</li> <li>Saturation</li> <li>Invert</li> <li>RGB Offset and Gain</li></p>\n\n<p><li><strong>Timing</strong></li> <li>Start Time</li> <li>Duration</li> <li>In Point (media offset)</li> <li>Play Rate</li></p>\n\n<p><li><strong>Audio</strong></li> <li>Volume</li> <li>Pan</li> <li>Mute</li></p>\n\n</ul>\n<h4>Layer Properties</h4>\n\n<p>When a layer is selected:</p>\n\n<ul>\n<li><strong>Name</strong> – Custom layer identifier</li>\n<li><strong>Key and Fill</strong> – Enable external keying mode</li>\n<li>Mode: Luma, Alpha, Luma Inverted, Alpha Inverted</li>\n<li>Associated fill layer selection</li>\n\n</ul>\n<h4>Timeline Properties</h4>\n\n<p>When a timeline is selected (via layer):</p>\n\n<ul>\n<li><strong>Timeline Name</strong></li>\n<li><strong>Duration</strong></li>\n<li><strong>Frame Rate</strong></li>\n\n</ul>\n<h4>Asset Properties</h4>\n\n<p>When an asset is selected:</p>\n\n<ul>\n<li><strong>File Information</strong> – Path, size, format</li>\n<li><strong>Media Specifications</strong> – Resolution, duration, codec</li>\n<li><strong>Optimization</strong> – Target format settings</li>\n\n</ul>\n<h4>Display Properties</h4>\n\n<p>When a display is selected on the Stage:</p>\n\n<ul>\n<li><strong>Name</strong> – Display identifier</li>\n<li><strong>Resolution</strong> – Output dimensions</li>\n<li><strong>Position</strong> – Location on the Stage canvas</li>\n<li><strong>Rotation</strong> – Display orientation</li>\n<li><strong>Host Assignment</strong> – Which display server renders this output</li>\n<li><strong>Edge Blending</strong> – Overlap and blend settings</li>\n<li><strong>Masking</strong> – Output mask configuration</li>\n\n</ul>\n<h3>Input Fields</h3>\n\n<p>Property values can be edited using various input types:</p>\n\n<ul>\n<li><strong>Text Fields</strong> – Type values directly; press <code>Enter</code> to confirm</li>\n<li><strong>Number Fields</strong> – Type or use increment buttons; drag to scrub values</li>\n<li><strong>Sliders</strong> – Drag for continuous adjustment</li>\n<li><strong>Color Pickers</strong> – Click the swatch to open the color selector</li>\n<li><strong>Dropdowns</strong> – Click to select from available options</li>\n<li><strong>Toggles</strong> – Click to enable/disable boolean settings</li>\n\n</ul>\n<h3>Scroll Position Memory</h3>\n\n<p>The Properties panel remembers scroll position for each property page type, so switching between different selections maintains your viewing position within similar content.</p>\n\n<h3>Focus Behavior</h3>\n\n<p>When the Properties panel receives focus:</p>\n\n<ul>\n<li>Tab navigation cycles through editable fields</li>\n<li>Press <code>Enter</code> to return focus to the previous window</li>\n<li>Changes apply immediately when values are modified</li>\n\n</ul>",
      "The Network Window": "<h2>The Network Window</h2>\n\n<p>The <strong>Network</strong> window shows all WATCHOUT devices on your network and their status. It provides centralized management of display servers, directors, asset managers, and other network services.</p>\n\n<h3>Device Discovery</h3>\n\n<p>WATCHOUT uses <strong>automatic discovery</strong> to find devices on your local network. All WATCHOUT 7 services running on the same subnet automatically appear in the Network window without manual configuration.</p>\n\n<p>The device list refreshes periodically (every few seconds) to reflect current status.</p>\n\n<h3>Device Table</h3>\n\n<p>The Network window displays devices in a table with the following columns:</p>\n\n<table>\n<tr><th>Column</th><th>Description</th></tr>\n<tr><td><strong>Name</strong></td><td>Device hostname or identifier</td></tr>\n<tr><td><strong>Services</strong></td><td>Icons indicating available services (Director, Display, Asset Manager)</td></tr>\n<tr><td><strong>Address</strong></td><td>IP address of the device</td></tr>\n<tr><td><strong>Version</strong></td><td>WATCHOUT software version (shown in toolbar)</td></tr>\n</table>\n\n<h3>Device Status</h3>\n\n<p>Devices show visual status indicators:</p>\n\n<ul>\n<li><strong>Online</strong> – Device is connected and responsive</li>\n<li><strong>Active in Show</strong> – Device is assigned to the current show</li>\n<li><strong>Offline</strong> – Device is not responding</li>\n\n</ul>\nThe text styling changes based on status:\n\n<ul>\n<li>Normal text – Online and ready</li>\n<li>Dimmed text – Offline or unavailable</li>\n\n</ul>\n<h3>Service Icons</h3>\n\n<p>Each device displays icons for its available services:</p>\n\n<table>\n<tr><th>Icon</th><th>Service</th><th>Description</th></tr>\n<tr><td>Director</td><td>Playback control and synchronization master</td></tr>\n<tr><td>Display</td><td>Video rendering and output</td></tr>\n<tr><td>Asset Manager</td><td>Media file management and optimization</td></tr>\n<tr><td>Audio</td><td>Audio output device</td></tr>\n<tr><td>Capture</td><td>Video input/capture device</td></tr>\n</table>\n\n<h3>Filtering Devices</h3>\n\n<p>Use the filter dropdown to narrow the device list:</p>\n\n<table>\n<tr><th>Filter</th><th>Shows</th></tr>\n<tr><td><strong>All</strong></td><td>Every discovered device</td></tr>\n<tr><td><strong>Active in Show</strong></td><td>Only devices currently assigned to the show</td></tr>\n<tr><td><strong>Referred by Show</strong></td><td>Devices referenced in show configuration</td></tr>\n</table>\n\n<h3>Context Menu Actions</h3>\n\n<p>Right-click a device or use the window menu button to access:</p>\n\n<h4>Device Management</h4>\n\n<ul>\n<li><strong>Add Display</strong> – Create a new display output on this device</li>\n<li><strong>Add 3D Projector</strong> – Add a 3D mapping projector</li>\n<li><strong>Add Audio Device</strong> – Configure audio output</li>\n<li><strong>Add Capture</strong> – Set up video input</li>\n\n</ul>\n<h4>Director Configuration</h4>\n\n<ul>\n<li><strong>Use as Director</strong> – Set the selected device as the show's Director</li>\n<li><strong>Clear Show from Director</strong> – Remove show data from the Director</li>\n\n</ul>\n<h4>Asset Manager Configuration</h4>\n\n<ul>\n<li><strong>Use as Asset Manager</strong> – Set the selected device for asset management</li>\n<li><strong>Close Asset Manager</strong> – Disconnect from current Asset Manager</li>\n\n</ul>\n<h4>Monitoring</h4>\n\n<ul>\n<li><strong>Performance</strong> – Open hardware performance monitor for the device</li>\n\n</ul>\n<h3>Multi-Show Indication</h3>\n\n<p>When a device is serving multiple shows simultaneously, a special indicator appears. This helps identify shared resources in multi-show environments.</p>\n\n<h3>Properties</h3>\n\n<p>Select a device and view detailed information in the <strong>Properties</strong> panel:</p>\n\n<ul>\n<li><strong>Device Name</strong> – Hostname and identifier</li>\n<li><strong>IP Address</strong> – Network address</li>\n<li><strong>Services</strong> – List of available services</li>\n<li><strong>Version</strong> – Software version information</li>\n<li><strong>Status</strong> – Connection and activity state</li>\n\n</ul>\n<h3>Assigning Displays</h3>\n\n<p>To assign a display to a device:</p>\n\n<ol>\n<li>Create a display on the Stage</li>\n<li>Open the display's Properties</li>\n<li>Select the target device from the <strong>Host</strong> dropdown</li>\n\n</ol>\nOr right-click the device in the Network window and choose <strong>Add Display</strong>.\n\n<h3>Refresh</h3>\n\n<p>Click the refresh button to manually update the device list. This triggers an immediate network scan for WATCHOUT devices.</p>",
      "The Nodes Window": "<h2>The Nodes Window</h2>\n\n<p>The <strong>Nodes</strong> window (also known as the Devices & Network window) provides a unified view of your show's output devices and the WATCHOUT nodes available on your network. It consists of two panes that work together to help you configure and monitor your display system.</p>\n\n<h3>Window Layout</h3>\n\n<p>The Nodes window is split into two resizable panes:</p>\n\n<table>\n<tr><th>Pane</th><th>Purpose</th></tr>\n<tr><td><strong>Devices</strong> (left)</td><td>Output devices assigned to your show</td></tr>\n<tr><td><strong>Network</strong> (right)</td><td>WATCHOUT nodes discovered on the network</td></tr>\n</table>\n\n<p>Drag the splitter between panes to adjust their relative sizes.</p>\n\n---\n\n<h2>Devices Pane</h2>\n\n<p>The <strong>Devices</strong> pane lists all output devices configured in your show, including displays, audio devices, and capture sources.</p>\n\n<h3>Device Table</h3>\n\n<table>\n<tr><th>Column</th><th>Description</th></tr>\n<tr><td><strong>Name</strong></td><td>Device name with type icon and optional warning indicators</td></tr>\n<tr><td><strong>Host</strong></td><td>The network node hosting this device, or \"Virtual\" for virtual displays</td></tr>\n</table>\n\n<h3>Device Types</h3>\n\n<p>Each device displays an icon indicating its type:</p>\n\n<table>\n<tr><th>Icon</th><th>Type</th><th>Description</th></tr>\n<tr><td>Monitor</td><td>Display</td><td>Physical video output</td></tr>\n<tr><td>Monitor (shimmer)</td><td>Virtual Display</td><td>Software-rendered output for compositions</td></tr>\n<tr><td>Volume</td><td>Audio</td><td>Audio output device</td></tr>\n<tr><td>Cast</td><td>Capture</td><td>Video input source</td></tr>\n</table>\n\n<h3>Filtering Devices</h3>\n\n<p>Use the dropdown filter to narrow the device list:</p>\n\n<table>\n<tr><th>Filter</th><th>Shows</th></tr>\n<tr><td><strong>All</strong></td><td>Every device in the show</td></tr>\n<tr><td><strong>Display</strong></td><td>Physical display outputs only</td></tr>\n<tr><td><strong>Virtual</strong></td><td>Virtual displays only</td></tr>\n<tr><td><strong>Capture</strong></td><td>Video capture sources</td></tr>\n<tr><td><strong>Audio</strong></td><td>Audio output devices</td></tr>\n</table>\n\n<h3>Device Status Indicators</h3>\n\n<p>Devices may display warning icons for issues such as:</p>\n\n<ul>\n<li>Missing host assignment</li>\n<li>Offline host</li>\n<li>Configuration errors</li>\n<li>Resolution mismatches</li>\n\n</ul>\nHover over warning icons to see details.\n\n<h3>Color Coding</h3>\n\n<p>Display devices show a colored left border matching their assigned color, making it easy to identify displays across the Stage and Devices views.</p>\n\n<h3>Host Grouping</h3>\n\n<p>When sorted by Host, devices on the same node display a connecting bracket in the left margin, visually grouping outputs by their rendering machine.</p>\n\n<h3>Context Menu Actions</h3>\n\n<p>Right-click devices to access:</p>\n\n<ul>\n<li><strong>Enable/Disable Device</strong> – Toggle device output</li>\n<li><strong>Edit Warp</strong> – Open warp correction editor</li>\n<li><strong>Edit Mask</strong> – Open mask editor</li>\n<li><strong>Cut/Copy/Paste/Delete</strong> – Standard editing operations</li>\n<li><strong>Add Capture</strong> – Create a new capture source</li>\n<li><strong>Add Virtual Display</strong> – Create a new virtual display</li>\n\n</ul>\n<h3>Adding Devices</h3>\n\n<p>Create new devices using:</p>\n\n<ul>\n<li><strong>Right-click menu</strong> in the Devices pane</li>\n<li><strong>Stage menu → Add Display/Projector</strong></li>\n<li><strong>Right-click a node</strong> in the Network pane</li>\n\n</ul>\n<h3>Editing Devices</h3>\n\n<ul>\n<li><strong>Double-click</strong> a device to open its properties</li>\n<li><strong>Drag</strong> devices to reorder (when enabled)</li>\n<li>Select multiple devices with <code>Shift+Click</code> or <code>Ctrl+Click</code></li>\n\n</ul>\n---\n\n<h2>Network Pane</h2>\n\n<p>The <strong>Network</strong> pane displays all WATCHOUT nodes discovered on your local network. For detailed information, see [The Network Window](06-the-network-window.md).</p>\n\n<h3>Quick Overview</h3>\n\n<p>The Network pane shows:</p>\n\n<ul>\n<li><strong>Node name</strong> – Hostname or identifier</li>\n<li><strong>Services</strong> – Available WATCHOUT services (Director, Runner, Asset Manager)</li>\n<li><strong>Address</strong> – IP address</li>\n\n</ul>\n<h3>Assigning Devices to Nodes</h3>\n\n<ol>\n<li>Select a node in the Network pane</li>\n<li>Right-click and choose <strong>Add Display</strong> or <strong>Add Audio Device</strong></li>\n<li>The new device is automatically assigned to that node</li>\n\n</ol>\n<h3>Monitoring Node Status</h3>\n\n<p>Nodes display real-time status:</p>\n\n<ul>\n<li>Normal text – Online and responsive</li>\n<li>Dimmed text – Offline or not responding recently</li>\n\n</ul>\n---\n\n<h2>Workflow Tips</h2>\n\n<h3>Efficient Device Management</h3>\n\n<ol>\n<li><strong>Filter by type</strong> when working with many devices</li>\n<li><strong>Sort by Host</strong> to see device groupings per node</li>\n<li><strong>Use color coding</strong> to match devices between Stage and Devices views</li>\n\n</ol>\n<h3>Multi-Selection</h3>\n\n<p>Select multiple devices to:</p>\n\n<ul>\n<li>Enable or disable as a group</li>\n<li>Move to a different host</li>\n<li>Delete in bulk</li>\n\n</ul>\n<h3>Drag and Drop</h3>\n\n<p>Drag devices from the Devices pane to the Stage to reposition displays visually.</p>",
      "Customizing Your Workspace": "<h2>Customizing Your Workspace</h2>\n\n<p>WATCHOUT 7's interface is fully customizable to match your workflow. The flexible window system allows you to arrange, resize, and organize your workspace exactly as you prefer.</p>\n\n<h3>Window Management</h3>\n\n<h4>Moving Windows</h4>\n\n<p>Drag any window by its title bar to reposition it within the application. Windows can be placed anywhere on screen and can overlap freely.</p>\n\n<h4>Resizing Windows</h4>\n\n<p>Drag the edges or corners of any window to resize:</p>\n\n<ul>\n<li><strong>Edges</strong> – Resize in one direction</li>\n<li><strong>Corners</strong> – Resize in both directions simultaneously</li>\n\n</ul>\nWindows maintain a minimum size to ensure controls remain usable.\n\n<h4>Closing Windows</h4>\n\n<p>Click the × button in any window's title bar, or right-click the title bar and select <strong>Close</strong>.</p>\n\n<h4>Reopening Windows</h4>\n\n<p>Closed windows can be reopened via the <strong>Window</strong> menu:</p>\n\n<ul>\n<li><strong>Window → Stage</strong></li>\n<li><strong>Window → Timeline</strong></li>\n<li><strong>Window → Assets</strong></li>\n<li><strong>Window → Properties</strong></li>\n<li><strong>Window → Network</strong></li>\n<li><strong>Window → Variables</strong> (for show variables/inputs)</li>\n\n</ul>\n<h3>Window Docking</h3>\n\n<p>Windows can be <strong>docked</strong> to the edges of the application:</p>\n\n<ol>\n<li>Hold <code>Ctrl</code> and double-click a window's title bar</li>\n<li>The window docks to the nearest edge</li>\n\n</ol>\nDocked windows:\n\n<ul>\n<li>Stretch to fill the edge</li>\n<li>Don't overlap other content</li>\n<li>Stay at their docked position when the application resizes</li>\n\n</ul>\nTo undock, hold <code>Ctrl</code> and double-click the title bar again.\n\n<h3>Layout Presets</h3>\n\n<p>Save and recall up to 9 custom workspace layouts:</p>\n\n<h4>Saving Presets</h4>\n\n<ul>\n<li><code>Ctrl+Shift+1</code> through <code>Ctrl+Shift+9</code> – Save current layout to preset 1-9</li>\n\n</ul>\n<h4>Loading Presets</h4>\n\n<ul>\n<li><code>Ctrl+1</code> through <code>Ctrl+9</code> – Load layout preset 1-9</li>\n\n</ul>\nPresets remember:\n\n<ul>\n<li>Window positions</li>\n<li>Window sizes</li>\n<li>Which windows are open</li>\n<li>Docking states</li>\n\n</ul>\n<h3>Layout Files</h3>\n\n<p>For sharing layouts between projects or team members:</p>\n\n<h4>Save Layout to File</h4>\n\n<ul>\n<li><strong>Window → Save Layout</strong> – Export current workspace to a <code>.layout.json</code> file</li>\n\n</ul>\n<h4>Load Layout from File</h4>\n\n<ul>\n<li><strong>Window → Load Layout</strong> – Import a workspace from file</li>\n\n</ul>\n<h3>Reset Layout</h3>\n\n<p>To restore the default workspace arrangement:</p>\n\n<ul>\n<li><strong>Window → Reset Layout</strong></li>\n\n</ul>\nThis returns all windows to their original positions and sizes.\n\n<h3>Window Navigation</h3>\n\n<h4>Cycling Windows</h4>\n\n<p>Navigate between windows using keyboard shortcuts:</p>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Ctrl+Tab</code></td><td>Activate next window</td></tr>\n<tr><td><code>Ctrl+Shift+Tab</code></td><td>Activate previous window</td></tr>\n<tr><td><code>Ctrl+\\</code><code></td><td>Next window of same type</td></tr>\n<tr><td></code>Ctrl+Shift+\\`<code></td><td>Previous window of same type</td></tr>\n</table>\n\n<h4>Direct Window Access</h4>\n\n<p>Jump directly to specific windows:</p>\n\n<ul>\n<li><strong>Stage</strong> – Click in background or use <strong>Window → Stage</strong></li>\n<li><strong>Timeline</strong> – <strong>Window → Timelines</strong></li>\n<li><strong>Assets</strong> – <strong>Window → Assets</strong></li>\n<li><strong>Properties</strong> – <strong>Window → Properties</strong> or </code>Ctrl+P`</li>\n<li><strong>Network</strong> – <strong>Window → Network</strong></li>\n\n</ul>\n<h3>Theme Selection</h3>\n\n<p>Toggle between visual themes via <strong>Window → Light Theme</strong>:</p>\n\n<ul>\n<li><strong>Dark Theme</strong> – Reduced brightness for low-light environments</li>\n<li><strong>Light Theme</strong> – Higher contrast for bright environments</li>\n\n</ul>\nYour theme preference persists across sessions.\n\n<h3>Multiple Timeline Windows</h3>\n\n<p>WATCHOUT supports multiple Timeline windows open simultaneously, useful when working with multiple timelines in your show. Each Timeline window operates independently and can display a different timeline.</p>\n\n<h3>Window Focus Indicators</h3>\n\n<p>The active (focused) window displays:</p>\n\n<ul>\n<li>Brighter title bar text</li>\n<li>Enhanced border color</li>\n<li>Stronger drop shadow</li>\n\n</ul>\nThis visual hierarchy helps identify which window receives keyboard input.\n\n<h3>Transparent Stage</h3>\n\n<p>The Stage window can display a transparent background when configured, allowing the operating system desktop or other applications to show through. This is useful for:</p>\n\n<ul>\n<li>Calibration reference</li>\n<li>Matching on-screen content with physical elements</li>\n<li>Presentation previews</li>\n\n</ul>"
    }
  },
  "3. Working with Shows": {
    "overview": "<h1>WORKING WITH SHOWS</h1>\n\n<p>A WATCHOUT show (.watch file) contains all your display configurations, media references, timeline data, and settings. Learn how to create, manage, and organize your shows effectively.</p>",
    "sections": {
      "Creating a New Show": "<h2>Creating a New Show</h2>\n\n<p>Every WATCHOUT project begins with creating a show. A show is the container for all your displays, timelines, cues, and media references—essentially your entire production wrapped into a single document that can be saved, shared, and deployed across your network.</p>\n\n<p>When you create a new show, WATCHOUT prepares a fresh workspace with an empty Stage canvas and at least one Timeline ready for programming. No displays are defined yet, no media has been imported, and the stage coordinates default to a neutral origin point. This blank slate approach means you have complete control over how your production takes shape from the very beginning.</p>\n\n<h3>Starting a New Show</h3>\n\n<p>You can create a new show in two ways. From the <strong>Welcome Screen</strong> that appears when you first launch Producer, click <strong>New Show</strong> to begin immediately. Alternatively, if you're already working in the application, choose <strong>File → New</strong> from the menu bar.</p>\n\n<p>If you have unsaved changes in a currently open show, WATCHOUT will ask whether you want to save your work before proceeding. This safeguard ensures you never accidentally lose edits by starting fresh.</p>\n\n<h3>What a New Show Contains</h3>\n\n<p>A freshly created show includes the fundamental structures you need to begin production work. The <strong>Stage</strong> window displays an empty canvas where you'll eventually position displays and arrange visual content. A default <strong>Timeline</strong> is created so you can start adding cues right away. The show also inherits default settings for frame rate, timing resolution, and network routing that you can adjust later through Show Properties.</p>\n\n<p>At this point, nothing is connected—no display servers, no Director, no Asset Manager. The show exists purely as a local document on your Producer workstation until you choose to connect it to network resources.</p>\n\n<h3>Organizing Your Project Files</h3>\n\n<p>Consider where you'll store your show file before you begin programming. Keeping your show file alongside its associated media assets in a dedicated project folder simplifies collaboration and makes packaging the show for transport much easier. A typical structure might place the show file in a project root folder with subfolders for video assets, images, and audio.</p>\n\n<p>When multiple team members work on the same production, consistent folder conventions prevent confusion about which version of the show is current and where media files should be located.</p>\n\n<h3>Network Considerations</h3>\n\n<p>If you create a show while already connected to network nodes, WATCHOUT remains aware of the Director's state. Should you attempt to deploy your new show to a Director that's already running a different production, you'll receive a warning about overriding the existing show. This protection helps prevent accidental interruptions to live systems.</p>",
      "Opening Existing Shows": "<h2>Opening Existing Shows</h2>\n\n<p>Most of your time in WATCHOUT will be spent working on shows that already exist—whether you created them yourself in an earlier session or received them from a colleague. The application provides several ways to return to previous work, each suited to different situations.</p>\n\n<h3>Opening from Disk</h3>\n\n<p>The most common method is opening a show file directly from your computer's storage. Choose <strong>File → Open</strong> or press <code>Ctrl+O</code> to browse for a show file. WATCHOUT's file dialog filters for its native show format, making it easy to locate the correct file among other project assets.</p>\n\n<p>For shows you've worked on recently, <strong>File → Open Recent</strong> provides quick access without navigating through folders. Producer remembers your recent show history, so returning to yesterday's work typically requires just two clicks.</p>\n\n<h3>Opening from a Director</h3>\n\n<p>Sometimes the show you want to work on isn't stored locally—it's already running on a Director node elsewhere on the network. In these situations, use <strong>File → Open Show from Director</strong> to connect directly to the running production.</p>\n\n<p>This approach proves valuable when you need to take over programming responsibilities on an existing system. Rather than transferring files and risking version mismatches, you connect straight to the live show data. The same method works well when verifying show state before a performance or when handing off between operators during a multi-day event.</p>\n\n<p>The Welcome Screen also offers connection options for Director-hosted shows, letting you choose between starting fresh locally or joining an existing network session.</p>\n\n<h3>Protecting Unsaved Work</h3>\n\n<p>WATCHOUT guards against accidental data loss when switching between shows. If your current show contains unsaved changes and you attempt to open a different one, the application pauses to ask what you'd like to do. You can save your current work, proceed without saving (abandoning recent edits), or cancel the operation entirely and remain in your current show.</p>\n\n<p>This protection applies regardless of how you're opening the new show—whether from disk, from a Director, or via the recent files list.</p>\n\n<h3>Director Override Warnings</h3>\n\n<p>When opening a show from a Director that's already running a different production, WATCHOUT displays a prominent warning. Proceeding with the operation will replace the currently running show with the one you're opening, which could interrupt playback or affect displays that are actively showing content.</p>\n\n<p>In rehearsal environments this is typically acceptable, but during live performances such an override could be disruptive. The warning ensures you always make this choice deliberately rather than accidentally.</p>",
      "Saving Your Work": "<h2>Saving Your Work</h2>\n\n<p>Regular saving is fundamental to any production workflow. WATCHOUT provides several save options to accommodate different scenarios—from quick incremental saves during programming to deliberate version snapshots before major changes.</p>\n\n<h3>The Save Command</h3>\n\n<p>The primary save command, accessible via <strong>File → Save</strong> or <code>Ctrl+S</code>, writes your current changes to the show file you're working in. If you're editing a show that's never been saved, this command prompts you to choose a location and filename.</p>\n\n<p>Use this frequently throughout your programming session. Timeline edits, display configurations, property adjustments—all of these modifications live only in memory until you save. A power interruption or application crash would lose unsaved work, so developing a habit of regular saves protects your progress.</p>\n\n<h3>Save As</h3>\n\n<p><strong>File → Save As</strong> (or <code>Ctrl+Shift+S</code>) lets you write the current show to a new file with a different name or location. After saving, your working context switches to this new file—subsequent saves will update the new location rather than the original.</p>\n\n<p>This command is useful when you want to branch your work. Perhaps you're about to make experimental changes and want to preserve a known-good version first. By saving as a new file, you create a checkpoint you can return to if the experiment doesn't work out.</p>\n\n<h3>Save Copy</h3>\n\n<p><strong>File → Save Copy</strong> creates a duplicate of your show without changing which file you're actively working in. The copy is written to a location you specify, but your current show file remains the active target for future saves.</p>\n\n<p>Think of this as creating a snapshot for archival purposes. You might save a copy before a major rehearsal to preserve that day's version, then continue editing without interruption. The copy serves as a recoverable milestone while your workflow continues unbroken.</p>\n\n<h3>Understanding the Differences</h3>\n\n<p>The distinction between these three commands matters in practice. <strong>Save</strong> updates your current file. <strong>Save As</strong> creates a new file and switches your context to it. <strong>Save Copy</strong> creates a new file but leaves your context unchanged.</p>\n\n<p>Knowing which to use prevents confusion about which file contains your latest work. When collaborating with others or managing multiple versions of a production, clear understanding of your save behavior keeps everyone synchronized.</p>",
      "Show Properties": "<h2>Show Properties</h2>\n\n<p>Every show carries a set of properties that define how it behaves globally—settings that affect all timelines, all displays, and all network interactions. These properties establish the fundamental parameters under which your entire production operates.</p>\n\n<h3>Accessing Show Properties</h3>\n\n<p>Show properties are accessible through the <strong>Properties</strong> panel when no specific element is selected. Alternatively, you can access them via the <strong>Show > Show Properties</strong> menu option. The properties panel displays all configurable settings organized into logical sections.</p>\n\n---\n\n<h2>General Properties</h2>\n\n<h3>Frame Rate</h3>\n\n<p>The <strong>Frame Rate</strong> determines the temporal resolution for all timeline operations throughout your show. This setting affects how precisely you can position cues in time and how smoothly animations play back.</p>\n\n<p><strong>Available Presets:</strong> <ul> <li><strong>23.98 FPS</strong> – Standard film rate (24000/1001)</li> <li><strong>24 FPS</strong> – Film rate</li> <li><strong>25 FPS</strong> – PAL/SECAM broadcast standard</li> <li><strong>29.97 FPS</strong> – NTSC broadcast standard (30000/1001)</li> <li><strong>30 FPS</strong> – Standard video rate</li> <li><strong>48 FPS</strong> – High frame rate film</li> <li><strong>50 FPS</strong> – PAL high frame rate</li> <li><strong>59.94 FPS</strong> – NTSC high frame rate (60000/1001)</li> <li><strong>60 FPS</strong> – High frame rate video</li> <li><strong>120 FPS</strong> – Ultra high frame rate</li> <li><strong>Custom</strong> – Specify any frame rate using numerator and denominator values</li></p>\n\n</ul>\nWhen selecting <strong>Custom</strong>, you can specify the exact numerator and denominator. The denominator options are <strong>1</strong> (for integer frame rates) or <strong>1.001</strong> (for NTSC-compatible fractional rates).\n\n<p>> <strong>Note:</strong> Frame rate changes affect how timeline positions are calculated. Changing this setting mid-production may shift the timing of existing cues.</p>\n\n<h3>Eye Point</h3>\n\n<p>The <strong>Eye Point</strong> defines the default viewer position in 3D space, used for perspective calculations across displays. This setting consists of three coordinates:</p>\n\n<ul>\n<li><strong>X</strong> – Horizontal position of the viewer</li>\n<li><strong>Y</strong> – Vertical position (height) of the viewer  </li>\n<li><strong>Z</strong> – Distance from the stage/display plane</li>\n\n</ul>\nThe eye point is particularly important for:\n<ul>\n<li>3D projection mapping scenarios</li>\n<li>Multi-display perspective corrections</li>\n<li>Virtual camera positioning</li>\n\n</ul>\n<h3>Auto Update Assets</h3>\n\n<p>When enabled, the <strong>Auto Update Assets</strong> option automatically refreshes media files when changes are detected on the Asset Manager. This is useful during content development when source files are being actively modified.</p>\n\n<table>\n<tr><th>State</th><th>Behavior</th></tr>\n<tr><td><strong>Enabled</strong></td><td>WATCHOUT monitors source files and updates cues when files change</td></tr>\n<tr><td><strong>Disabled</strong></td><td>Assets remain static until manually refreshed</td></tr>\n</table>\n\n<p>> <strong>Caution:</strong> Enable this setting during content development, but consider disabling it for live shows to prevent unexpected visual changes.</p>\n\n<h3>SDI Genlock</h3>\n\n<p>The <strong>SDI Genlock</strong> option enables hardware synchronization for outputs using SDI (Serial Digital Interface) connections. When enabled, WATCHOUT locks video output timing to an external reference signal.</p>\n\n<table>\n<tr><th>State</th><th>Use Case</th></tr>\n<tr><td><strong>Enabled</strong></td><td>Synchronized multi-display setups with SDI infrastructure</td></tr>\n<tr><td><strong>Disabled</strong></td><td>Standard software-timed output</td></tr>\n</table>\n\n<p>Genlock ensures frame-accurate synchronization across multiple displays, eliminating tearing or timing drift. This requires compatible SDI hardware with genlock input capability.</p>\n\n<h3>Default Anchor Position</h3>\n\n<p>The <strong>Default Anchor Position</strong> determines the reference point for newly created media cues. When you add a media cue to a timeline, this anchor point defines which part of the media aligns with the specified position.</p>\n\n<p><strong>Available Options:</strong></p>\n\n<table>\n<tr><th>Position</th><th>Description</th></tr>\n<tr><td><strong>Top Left</strong></td><td>Upper-left corner as reference</td></tr>\n<tr><td><strong>Top</strong></td><td>Center of top edge</td></tr>\n<tr><td><strong>Top Right</strong></td><td>Upper-right corner</td></tr>\n<tr><td><strong>Left</strong></td><td>Center of left edge</td></tr>\n<tr><td><strong>Center</strong></td><td>Center of the media (default)</td></tr>\n<tr><td><strong>Right</strong></td><td>Center of right edge</td></tr>\n<tr><td><strong>Bottom Left</strong></td><td>Lower-left corner</td></tr>\n<tr><td><strong>Bottom</strong></td><td>Center of bottom edge</td></tr>\n<tr><td><strong>Bottom Right</strong></td><td>Lower-right corner</td></tr>\n</table>\n\n<p>The anchor position is represented visually using a 3×3 grid selector in the Properties panel.</p>\n\n---\n\n<h2>Sync Groups</h2>\n\n<p><strong>Sync Groups</strong> coordinate playback timing across multiple display servers. By grouping nodes together, you ensure their timelines run in lockstep, which is essential for seamless multi-display presentations.</p>\n\n<h3>Managing Sync Groups</h3>\n\n<p>To create a new sync group: <ol> <li>Click <strong>Add Sync Group</strong></li> <li>Enter a name for the group</li> <li>Add member nodes by typing or selecting from available devices</li></p>\n\n</ol>\nEach sync group displays its member nodes, which can be added or removed using the multi-select chip interface. Nodes are identified by their host reference names as they appear on the network.\n\n<h3>When to Use Sync Groups</h3>\n\n<ul>\n<li><strong>Multi-server installations</strong> – When content spans multiple playback machines</li>\n<li><strong>Edge-blended displays</strong> – Where precise frame alignment prevents visible seams</li>\n<li><strong>Redundant systems</strong> – To keep backup servers synchronized with primary units</li>\n\n</ul>\n> <strong>Note:</strong> Nodes must be network-accessible to participate in sync group coordination. Verify network connectivity before adding nodes to sync groups.\n\n---\n\n<h2>Host Configuration</h2>\n\n<p>Host settings define the network infrastructure supporting your show. These properties are typically configured during initial setup and bind the show to specific servers.</p>\n\n<h3>Director</h3>\n\n<p>The <strong>Director</strong> host coordinates overall show playback. This is the central server that: <ul> <li>Manages timeline execution</li> <li>Coordinates commands across all nodes</li> <li>Maintains master timing for the production</li></p>\n\n</ul>\nThe Director hostname appears in the menu bar during active connections.\n\n<h3>Asset Manager</h3>\n\n<p>The <strong>Asset Manager</strong> host stores and distributes media files to display nodes. This server: <ul> <li>Maintains the central asset library</li> <li>Handles file distribution to playback nodes</li> <li>Manages asset versioning and updates</li></p>\n\n</ul>\nThe Asset Manager connection status enables or disables asset-related operations throughout the application.\n\n<h3>Time Server</h3>\n\n<p>The optional <strong>Time Server</strong> provides network time synchronization for the show. This ensures all nodes reference the same clock source for coordinated playback.</p>\n\n<h3>Log Server</h3>\n\n<p>The optional <strong>Log Server</strong> receives logging output from all nodes in the production. Centralizing logs simplifies troubleshooting and provides a unified view of system activity.</p>\n\n---\n\n<h2>Best Practices</h2>\n\n<h3>During Pre-Production</h3>\n\n<p>Establish your show properties early in the production process: <ul> <li>Set the frame rate to match your content and output requirements</li> <li>Configure host addresses for your network environment</li> <li>Define sync groups based on your display topology</li></p>\n\n</ul>\n<h3>During Technical Rehearsals</h3>\n\n<p>Technical rehearsals often reveal issues related to show properties: <ul> <li>Verify sync group membership matches physical node connections</li> <li>Confirm frame rate compatibility with content and displays</li> <li>Test genlock settings if using synchronized SDI outputs</li></p>\n\n</ul>\n<h3>During Live Shows</h3>\n\n<p>Maintain stability during live operation: <ul> <li>Avoid changing frame rate or host configuration</li> <li>Consider disabling auto-update assets to prevent surprises</li> <li>Document your property settings for quick recovery if needed</li></p>\n\n</ul>\nIf a property change becomes necessary during a live show, pause playback to a safe state before making adjustments. The brief transition is preferable to unexpected disruptions during active content playback.",
      "Show Consolidation": "<h2>Show Consolidation</h2>\n\n<p>In a typical WATCHOUT workflow, your show file references media assets stored on an Asset Manager. The show file itself is relatively small — it contains display configurations, timeline data, and cue definitions, but not the actual media files. This design is efficient for production, but it means the show depends on the Asset Manager being available with the correct assets.</p>\n\n<p><strong>Consolidation</strong> solves this dependency by packaging the show file together with copies of all its referenced assets into a single self-contained unit. A consolidated show can be moved between systems, archived, or deployed without needing access to the original Asset Manager.</p>\n\n<h3>When to Consolidate</h3>\n\n<p>Consolidation is useful in several scenarios:</p>\n\n<ul>\n<li><strong>Archiving a finished show</strong> — after a production wraps, consolidate the show to create a complete, portable archive that includes all media. This ensures the show can be reopened years later without hunting for the original asset files.</li>\n<li><strong>Transferring to a different site</strong> — when moving a show from a programming studio to an on-site production system, a consolidated package ensures all assets travel with the show file, eliminating the risk of missing media.</li>\n<li><strong>Creating a backup snapshot</strong> — before making major edits to a show, consolidate the current state as a recoverable checkpoint that includes both the show data and the exact media versions in use.</li>\n<li><strong>Offline work</strong> — when you need to review or edit a show on a machine that doesn't have access to the Asset Manager or the original media storage.</li>\n\n</ul>\n<h3>Consolidating a Show</h3>\n\n<p>To consolidate your show:</p>\n\n<ol>\n<li>Open the show you want to consolidate in Producer.</li>\n<li>Choose <strong>File → Consolidate Show</strong>.</li>\n<li>Select a destination folder where the consolidated package will be created.</li>\n<li>The consolidation process begins, copying all referenced assets into the package.</li>\n\n</ol>\nDuring consolidation, a progress indicator shows the current task and overall completion. The process copies every asset referenced by the show — images, videos, audio files, display data, models, EDID files, fonts, SVGs, and any other asset types used in the production.\n\n<p>The resulting consolidated package contains the show file alongside all its media, making it fully self-contained. The size of the consolidated package depends on the total size of your referenced assets, so expect it to be significantly larger than the show file alone.</p>\n\n<div class='note-box'><p>Consolidation copies the current versions of all referenced assets. If assets are being actively optimized or transferred when you consolidate, the package will contain whatever state is available at that moment. For best results, ensure all asset processing is complete before consolidating.\n</p></div>\n\n<h3>Unconsolidating a Show</h3>\n\n<p>If you want to reverse consolidation — restoring the show to reference assets from the Asset Manager rather than its embedded copies — use the unconsolidate command:</p>\n\n<ol>\n<li>Open the consolidated show in Producer.</li>\n<li>Choose <strong>File → Unconsolidate Show</strong>.</li>\n<li>Specify the consolidated package path and the target show file location.</li>\n\n</ol>\nUnconsolidation restores the show to its normal Asset Manager-dependent mode. The show file goes back to referencing assets by their Asset Manager identifiers, and subsequent operations (adding new media, optimizing assets, distributing to Runners) use the Asset Manager as usual.\n\n<p>This is typically done when deploying a consolidated show to a new production environment: you unconsolidate the show, connect to the local Asset Manager, and the assets are ingested into the new Asset Manager's library.</p>\n\n<h3>Considerations</h3>\n\n<p><strong>File size:</strong> Consolidated packages can be very large, especially for shows with high-resolution video content. Ensure you have sufficient disk space at the destination before starting consolidation.</p>\n\n<p><strong>Multi-node setups:</strong> Consolidation creates a portable package, but it does not replace the normal asset distribution workflow for multi-Runner deployments. When you deploy a consolidated show to a production system, you will typically unconsolidate it so the Asset Manager can distribute the assets to all Runner nodes as part of the standard pipeline.</p>\n\n<p><strong>Progress and interruption:</strong> The consolidation process runs as a background operation with progress reporting. If you need to cancel, close the progress dialog. However, a partial consolidation may result in an incomplete package, so it is best to let the process complete.</p>",
      "Show Information": "<h2>Show Information</h2>\n\n<p>The <strong>Show Information</strong> dialog provides a statistical overview of the current show, giving you a quick summary of its contents, complexity, and file details. It is a read-only view — no settings are changed here — designed for auditing, documentation, and pre-deployment verification.</p>\n\n<h3>Accessing Show Information</h3>\n\n<p>Open the dialog from <strong>File → Show Information</strong>. The dialog loads the current show's data and presents it in a series of expandable sections.</p>\n\n<h3>Statistics</h3>\n\n<p>The <strong>Statistics</strong> section is the primary overview, organized into expandable subsections:</p>\n\n<h4>Cue Summary</h4>\n\n<p>Shows the <strong>total number of cues</strong> across the entire show, with an expandable breakdown by cue kind:</p>\n\n<ul>\n<li><strong>Media Cues</strong> — cues that render visual or audio content (images, video, audio, compositions, captures)</li>\n<li><strong>Control Cues</strong> — playback control cues (go, pause, stop, jump, etc.)</li>\n<li><strong>Output Cues</strong> — cues that affect display output behavior</li>\n<li><strong>Variable Cues</strong> — cues that set or modify show variables/inputs</li>\n<li><strong>Marker Cues</strong> — comment and marker cues used for notes, show calling, and countdown references</li>\n\n</ul>\nThis breakdown helps you understand the composition of your show at a glance — whether it's primarily media-driven or relies heavily on control logic.\n\n<h4>Timeline Details</h4>\n\n<p>Shows the <strong>number of timelines</strong> in the show. Expanding this section reveals each timeline individually with:</p>\n\n<ul>\n<li><strong>Timeline name</strong> — the name you assigned to the timeline</li>\n<li><strong>Duration</strong> — the total duration of the timeline, formatted as HH:MM:SS or MM:SS</li>\n<li><strong>Cue count</strong> — an expandable sub-section showing the total number of cues in that timeline, broken down by kind (media, control, output, variable, marker)</li>\n\n</ul>\nThis per-timeline detail is useful for identifying which timelines are the most complex and where the bulk of your cues reside.\n\n<h4>Compositions</h4>\n\n<p>Displays the <strong>number of compositions</strong> defined in the show. Compositions are self-contained visual elements with their own internal layers and cues, used as reusable building blocks across timelines.</p>\n\n<h4>Display Summary</h4>\n\n<p>Shows the <strong>total number of displays</strong> with a breakdown by output type:</p>\n\n<ul>\n<li><strong>GPU Displays</strong> — displays using direct GPU output to connected monitors or projectors</li>\n<li><strong>NDI Displays</strong> — displays outputting via NDI network video</li>\n<li><strong>SDI Displays</strong> — displays outputting via SDI hardware (Deltacast cards)</li>\n<li><strong>Virtual Displays</strong> — software-only displays used for compositions, previsualization, or design work</li>\n\n</ul>\nThis overview is helpful for verifying that your display configuration matches the expected hardware setup before deployment.\n\n<h3>Asset Summary</h3>\n\n<p>The <strong>Assets</strong> section shows the <strong>total number of used assets</strong> in the show, with a breakdown by asset type:</p>\n\n<ul>\n<li><strong>Images</strong> — still image files (PNG, JPEG, TIFF, BMP, WebP, EXR, PSD)</li>\n<li><strong>Videos</strong> — video files (MP4, MOV, AVI, MKV, HAP, ProRes, H.264, H.265)</li>\n<li><strong>Audio</strong> — audio files (WAV, MP3, AAC, FLAC, OGG)</li>\n<li><strong>Compositions</strong> — composition assets</li>\n<li><strong>Display Data</strong> — display calibration and configuration data (MPCDI, etc.)</li>\n<li><strong>Models</strong> — 3D model files used for projection mapping</li>\n<li><strong>EDID</strong> — captured EDID data from display hardware</li>\n<li><strong>Art-Net Fixtures</strong> — Art-Net fixture definition files</li>\n<li><strong>Art-Net Recordings</strong> — recorded Art-Net data files</li>\n<li><strong>Fonts</strong> — font files used by SVG or text elements</li>\n<li><strong>SVGs</strong> — scalable vector graphics</li>\n<li><strong>Unknown</strong> — assets referenced by the show that could not be found in the Asset Manager. A non-zero count here may indicate missing or deleted assets.</li>\n\n</ul>\nThe asset count includes only assets that are actually referenced by the show (used in cues or display configurations), not every asset in the Asset Manager's library.\n\n<h3>Technical Details</h3>\n\n<p>The <strong>Technical Details</strong> section shows file-level information about the show:</p>\n\n<ul>\n<li><strong>Name</strong> — the show file name (without extension)</li>\n<li><strong>Created</strong> — the file creation date and time</li>\n<li><strong>File Path</strong> — the full path to the show file on disk</li>\n<li><strong>File Size</strong> — the size of the show file, formatted in human-readable units (KB, MB, GB)</li>\n<li><strong>Last Modified</strong> — the most recent modification date and time</li>\n\n</ul>\nIf the show was opened from a Director (not from a local file), these fields display \"n/a\" since there is no local file to report on.\n\n<h3>Use Cases</h3>\n\n<p><strong>Pre-deployment verification:</strong> Before loading a show onto a production system, open Show Information to confirm the display count matches the physical setup, check that there are no unknown/missing assets, and verify the timeline count and cue complexity.</p>\n\n<p><strong>Performance diagnostics:</strong> If playback performance is lower than expected, the cue count and timeline complexity can help identify whether the show is pushing system limits. A very high cue count on a single timeline, or many simultaneously active timelines, may require optimization.</p>\n\n<p><strong>Show documentation:</strong> Use the statistics as a quick reference when handing off a show to another operator, or when documenting a production for archival purposes. The information provides a concise summary of what the show contains without needing to manually inspect every timeline and asset.</p>\n\n<p><strong>Asset auditing:</strong> The asset breakdown and unknown asset count help identify whether all required media is present and accounted for. If the unknown count is greater than zero, some assets referenced by cues may have been deleted or not yet transferred to the Asset Manager.</p>"
    }
  },
  "4. Displays and Outputs": {
    "overview": "<h1>DISPLAYS AND OUTPUTS</h1>\n\n<p>Learn how to configure displays, projectors, and video walls in WATCHOUT. Proper display setup is essential for achieving seamless multi-screen presentations.</p>",
    "sections": {
      "Adding Displays": "<h2>Adding Displays</h2>\n\n<p>Displays are the output surfaces your cues render to. In WATCHOUT 7, each display is a configurable device object with placement, routing, and output settings.</p>\n\n<h3>Add a Physical Display</h3>\n\n<p>From the <strong>Stage</strong> window, choose:</p>\n\n<ul>\n<li><strong>Stage → Add Display</strong></li>\n<li>Right-click context action for display creation</li>\n\n</ul>\nYou can also add displays from the <strong>Network</strong> window to target a selected node.\n\n<h3>Initial Configuration Checklist</h3>\n\n<p>After adding a display, set:</p>\n\n<ul>\n<li><strong>Name</strong> (clear operator-friendly label)</li>\n<li><strong>Address / Host</strong> (target node alias)</li>\n<li><strong>Resolution</strong> (<code>width × height</code>)</li>\n<li><strong>Output type</strong> (GPU, SDI, NDI, or Virtual)</li>\n<li><strong>Channel</strong> (physical output channel)</li>\n\n</ul>\n<h3>Placement on Stage</h3>\n\n<p>Set display size and position to match the real-world layout:</p>\n\n<ul>\n<li>Use exact pixel dimensions from the processor or projector chain.</li>\n<li>Align displays in stage coordinates before adding cues.</li>\n<li>Use <strong>Frame All Displays</strong> to verify overall layout.</li>\n\n</ul>\n<h3>Verify with a Test Cue</h3>\n\n<p>Before building the full show:</p>\n\n<ol>\n<li>Add a simple test image/video cue.</li>\n<li>Route it to the new display.</li>\n<li>Confirm output appears on the expected node and connector.</li>\n\n</ol>\n<div class='info-box'><p><strong>Tip:</strong> Use descriptive names like <code>Left_LED_Wall_A</code> instead of generic names like <code>Display 1</code>.\n</p></div>",
      "Virtual Displays": "<h2>Virtual Displays</h2>\n\n<p>A virtual display behaves like a normal display in the Stage and Timeline, but it is not tied to a physical connector. It is useful for design, planning, and previsualization.</p>\n\n<h3>When to Use Virtual Displays</h3>\n\n<p>Use virtual displays when you need to:</p>\n\n<ul>\n<li>Design content before hardware is on site</li>\n<li>Build a stage map for client review</li>\n<li>Prepare layout/animation while waiting for final routing details</li>\n<li>Simulate a complete system on a laptop or single workstation</li>\n\n</ul>\n<h3>How They Behave</h3>\n\n<p>Virtual displays support standard workflow operations:</p>\n\n<ul>\n<li>Cue placement and stacking</li>\n<li>Tween animation</li>\n<li>Timeline playback preview</li>\n<li>Grouping and composition work</li>\n\n</ul>\n<h3>Transitioning to Physical Outputs</h3>\n\n<p>When hardware is ready:</p>\n\n<ol>\n<li>Replace virtual targets with GPU/SDI/NDI outputs as needed.</li>\n<li>Set host address and channel routing.</li>\n<li>Validate resolution, frame rate, and color settings.</li>\n\n</ol>\n<h3>Best Practice</h3>\n\n<p>Keep a naming convention that distinguishes virtual from physical targets, for example:</p>\n\n<ul>\n<li><code>VIRT_MainWall</code></li>\n<li><code>VIRT_SideScreen_R</code></li>\n\n</ul>\nThis avoids routing mistakes during deployment.",
      "3D Mapping Projectors": "<h2>3D Mapping Projectors</h2>\n\n<p>Projector displays extend WATCHOUT from flat 2D layouts to spatially mapped output. Projector mode uses camera/frustum parameters and calibration tools to align content to real surfaces.</p>\n\n<h3>Adding a Projector</h3>\n\n<p>Use:</p>\n\n<ul>\n<li><strong>Stage → Add 3D Projector</strong></li>\n<li>Network context actions for selected node</li>\n\n</ul>\nYou can add at default placement or at a chosen stage/world position.\n\n<h3>Core Projector Parameters</h3>\n\n<p>Projector displays expose parameters such as:</p>\n\n<ul>\n<li><strong>Eye</strong> (projector position)</li>\n<li><strong>Target</strong> (look-at point)</li>\n<li><strong>Roll</strong></li>\n<li><strong>Lens shift</strong> (horizontal/vertical)</li>\n<li><strong>Width/Distance ratio</strong></li>\n\n</ul>\nThese define the projection frustum used for mapping.\n\n<h3>Projector Camera Mode</h3>\n\n<p>Switch Stage camera mode to <strong>Projector</strong> for alignment work. WATCHOUT supports calibration workflows with virtual/reality points and continuous/manual calibration behavior.</p>\n\n<h3>Calibration Requirements</h3>\n\n<p>For reality-point adjustment workflows, provide enough calibration points first.</p>\n\n<div class='warning-box'><p>Projector calibration in 2D reality mode requires at least six virtual points before editing reality points.\n</p></div>\n\n<h3>Operational Notes</h3>\n\n<ul>\n<li>Projector mode is not available while viewing a composition-only stage context.</li>\n<li>Keep calibration and geometry edits versioned like any other critical show state.</li>\n\n</ul>",
      "Display Grid Setup": "<h2>Display Grid Setup</h2>\n\n<p>Grid tools speed up setup for LED walls, tiled monitors, and repeated projection arrays.</p>\n\n<h3>Create Display Grid</h3>\n\n<p>Use <strong>Create Display Grid</strong> to generate multiple displays in one operation.</p>\n\n<p>Typical parameters:</p>\n\n<ul>\n<li><strong>Columns / Rows</strong></li>\n<li><strong>Display Resolution</strong></li>\n<li><strong>Horizontal / Vertical spacing</strong></li>\n<li><strong>Start position</strong> (left/bottom anchor)</li>\n\n</ul>\n<h3>Arrange Existing Displays as Grid</h3>\n\n<p>Use <strong>Arrange as Grid</strong> when displays already exist but need structured alignment.</p>\n\n<p>This is useful after importing or manual creation where displays are slightly misaligned.</p>\n\n<p>The arrange tools support different ordering strategies:</p>\n\n<ul>\n<li><strong>Closest first</strong></li>\n<li><strong>Row order</strong></li>\n<li><strong>Column order</strong></li>\n\n</ul>\n<h3>Arrange Selected Cues as Grid</h3>\n\n<p>The Stage also provides <strong>Arrange as Grid</strong> for selected cues. This is useful when you want rapid layout structure without changing display geometry.</p>\n\n<p>Typical use:</p>\n\n<ol>\n<li>Multi-select cues in Stage.</li>\n<li>Open <strong>Arrange as Grid</strong>.</li>\n<li>Set rows/columns, spacing, and strategy.</li>\n<li>Apply and fine-tune manually if needed.</li>\n\n</ol>\n<h3>Pack Cues Inside a Display</h3>\n\n<p>Use <strong>Pack Inside Display</strong> to fit selected cues inside a target display rectangle.</p>\n\n<p>This is useful when:</p>\n\n<ul>\n<li>You need quick normalization after freehand cue placement.</li>\n<li>You want selected cues constrained to a specific output region.</li>\n<li>You are preparing cue clusters for handoff to another operator.</li>\n\n</ul>\n<h3>Recommended Workflow</h3>\n\n<ol>\n<li>Create or arrange the grid.</li>\n<li>Frame all displays and verify orientation.</li>\n<li>Rename displays logically by row/column.</li>\n<li>Apply output/channel assignments.</li>\n<li>Add test content spanning the full grid.</li>\n\n</ol>\n<h3>Grid Strategy Tips</h3>\n\n<ul>\n<li>For LED processors, match processor canvas dimensions exactly.</li>\n<li>Keep spacing at zero unless you intentionally model physical gaps.</li>\n<li>Use separate stage tiers for alternate grid states (rehearsal vs show variants).</li>\n\n</ul>",
      "Display Properties": "<h2>Display Properties</h2>\n\n<p>Display Properties control how each display is rendered, routed, and calibrated.</p>\n\n<h3>General Properties</h3>\n\n<ul>\n<li><strong>Name / Color / Enabled / Locked</strong></li>\n<li><strong>Address (host alias)</strong></li>\n<li><strong>Placement and orientation</strong></li>\n<li><strong>Tier visibility</strong> (which stage tiers can show cues)</li>\n\n</ul>\n<h3>Output Properties</h3>\n\n<table>\n<tr><th>Property</th><th>Purpose</th></tr>\n<tr><td><strong>Output Type</strong></td><td><code>GPU</code>, <code>SDI</code>, <code>NDI</code>, or <code>Virtual</code></td></tr>\n<tr><td><strong>Channel</strong></td><td>Physical/logic output index</td></tr>\n<tr><td><strong>Resolution</strong></td><td>Render target dimensions</td></tr>\n<tr><td><strong>Color Depth</strong></td><td>Output precision (for supported hardware)</td></tr>\n<tr><td><strong>Color Space</strong></td><td>Display color pipeline target</td></tr>\n<tr><td><strong>Interlaced</strong></td><td>Enable interlaced output where required</td></tr>\n<tr><td><strong>Delay Frames</strong></td><td>Output delay compensation</td></tr>\n<tr><td><strong>Max Quality</strong></td><td>Higher quality render path where needed</td></tr>\n</table>\n\n<h3>Signal and Calibration</h3>\n\n<p>Display-level calibration settings include:</p>\n\n<ul>\n<li><strong>White point</strong></li>\n<li><strong>NDI calibration stream</strong></li>\n<li><strong>Render info overlay</strong></li>\n<li><strong>Warp/mask/soft-edge integration</strong></li>\n\n</ul>\n<h3>Practical Advice</h3>\n\n<ul>\n<li>Keep channel numbering consistent with physical labeling.</li>\n<li>Use lock state once routing is approved.</li>\n<li>Document non-default delay/color settings for handoff.</li>\n\n</ul>",
      "Edge Blending": "<h2>Edge Blending</h2>\n\n<p>Edge blending smooths overlap regions between adjacent projected outputs so they appear as one continuous image.</p>\n\n<h3>Automatic Soft Edges</h3>\n\n<p>WATCHOUT supports automatic soft-edge generation using overlap geometry between displays.</p>\n\n<p>Under the hood, overlap regions are converted into gradient-intensity meshes so brightness can be feathered across boundaries.</p>\n\n<h3>Blend Control Methods</h3>\n\n<p>Common methods include:</p>\n\n<ul>\n<li><strong>Automatic soft edges</strong> from overlapping display geometry</li>\n<li><strong>Mask-based shaping</strong> for custom overlap boundaries</li>\n<li><strong>Manual warp/mask refinement</strong> for irregular surfaces</li>\n\n</ul>\n<h3>Calibration Workflow</h3>\n\n<ol>\n<li>Align projector geometry first.</li>\n<li>Enable soft edges and review overlap zones.</li>\n<li>Fine-tune masks where automatic blending is insufficient.</li>\n<li>Validate using grayscale ramps and full-brightness test images.</li>\n\n</ol>\n<h3>Common Pitfalls</h3>\n\n<ul>\n<li>Incorrect projector black levels can make seams visible.</li>\n<li>Non-uniform brightness or color temperature across projectors reduces blend quality.</li>\n<li>Overly narrow overlaps leave no room for smooth falloff.</li>\n\n</ul>\n<div class='info-box'><p>Blend calibration is most reliable in a controlled lighting environment with stable projector warm-up.\n</p></div>",
      "Warp Geometry": "<h2>Warp Geometry</h2>\n\n<p>Geometry correction aligns rendered imagery to real-world surfaces. In WATCHOUT, this is handled through warp geometry and optional mask geometry.</p>\n\n<h3>Warp Geometry</h3>\n\n<p>Warp geometry is mesh-based and supports:</p>\n\n<ul>\n<li>Adjustable junction points</li>\n<li>Handle-based curve shaping</li>\n<li>Perspective correction transforms</li>\n<li>Per-display editing</li>\n\n</ul>\nThis allows precise correction for curved screens, imperfect mounting, and non-rectangular targets.\n\n<h3>Mask Geometry</h3>\n\n<p>Mask geometry controls where pixels are visible and how edges are shaped. Use it to:</p>\n\n<ul>\n<li>Hide spill outside scenic boundaries</li>\n<li>Build custom blend/feather regions</li>\n<li>Combine multiple mask regions on one display</li>\n\n</ul>\n<h3>Recommended Workflow</h3>\n\n<ol>\n<li>Complete physical alignment first.</li>\n<li>Apply coarse warp adjustments.</li>\n<li>Add fine curve/handle corrections.</li>\n<li>Add masks for cutouts and scenic limits.</li>\n<li>Re-check cue positioning with representative content.</li>\n\n</ol>\n<h3>Quality Control</h3>\n\n<p>Validate with:</p>\n\n<ul>\n<li>Grid test patterns</li>\n<li>Straight-line graphics for distortion checks</li>\n<li>Real show media at final brightness</li>\n\n</ul>\nSmall geometry errors become obvious once motion and high-contrast content play back.",
      "Display Masks": "<h2>Display Masks</h2>\n\n<p>Display masks control which pixels on a display are visible and how their edges are shaped. Unlike warp geometry, which repositions pixels to correct for surface distortion, masks operate as alpha-based overlays that hide or reveal regions of the rendered output. Masks are applied <em>after</em> the warp stage in the rendering pipeline, meaning they work on already-corrected imagery.</p>\n\n<p>Every display in WATCHOUT can have an independent set of mask surfaces. Masks are especially useful in projection environments where light spills beyond the intended surface, or where scenic elements require non-rectangular output boundaries.</p>\n\n<h3>Accessing the Mask Editor</h3>\n\n<p>There are two ways to enable and edit masks on a display:</p>\n\n<ul>\n<li><strong>Device Properties → Mask section:</strong> Toggle <strong>Enabled</strong> to activate the custom mask for the selected display, then click <strong>Edit</strong> to open the mask editor in the Stage view.</li>\n<li><strong>Stage context menu:</strong> Right-click a display and choose <strong>Edit Display Mask</strong> to enter mask editing mode directly.</li>\n\n</ul>\nWhen the mask editor is active, the Stage view switches to a specialized editing mode where you can manipulate mask junction points, add or remove mask surfaces, and preview the result in real time.\n\n<h3>Mask Surfaces</h3>\n\n<p>A single display can contain multiple mask surfaces, each acting as an independent layer. Every mask surface has its own:</p>\n\n<ul>\n<li><strong>Name</strong> — a label to identify the surface (e.g., \"Left Spill Cut\" or \"Scenic Border\")</li>\n<li><strong>Junction grid</strong> — the mesh of control points that defines the shape</li>\n<li><strong>Gamma correction</strong> — a per-surface gamma value that controls the intensity curve of the feathered edge</li>\n<li><strong>Enabled toggle</strong> — individual surfaces can be enabled or disabled without deleting them</li>\n\n</ul>\nMultiple mask surfaces on the same display are composited together. This means you can combine, for example, a side-edge mask with an irregular scenic cutout mask on a single output.\n\n<h3>Built-in Mask Types</h3>\n\n<p>WATCHOUT provides several preset mask shapes that serve as starting points. These create a properly structured junction grid that you can then refine:</p>\n\n<ul>\n<li><strong>Left Mask</strong> — hides the left edge of the display with a feathered transition toward the center. Useful for blending overlap regions where a neighboring projector covers the left side.</li>\n<li><strong>Right Mask</strong> — the mirror of the left mask, hiding the right edge.</li>\n<li><strong>Top Mask</strong> — hides the top edge with a downward feather.</li>\n<li><strong>Bottom Mask</strong> — hides the bottom edge with an upward feather.</li>\n<li><strong>Rectangular Mask</strong> — creates a rectangular cutout centered on the display, with feathered edges on all four sides. This is useful for framing output within a scenic opening or masking a border region.</li>\n<li><strong>Round Mask</strong> — creates an elliptical mask centered on the display. The oval shape is built from a grid of junction points with Bézier handles that approximate a smooth curve. Ideal for circular screens, gobos, or spotlight-shaped output regions.</li>\n\n</ul>\nEach preset configures an opaque region (where content is hidden), a feathered transition region, and a fully visible region. After creation, all points can be freely repositioned and the feathered edges adjusted.\n\n<h3>Editing Mask Points</h3>\n\n<p>Mask geometry is defined by a grid of <strong>junction points</strong>. Each junction has the following properties:</p>\n\n<ul>\n<li><strong>Position (X / Y)</strong> — the location of the point in normalized display coordinates, where (0, 0) is the lower-left corner and (1, 1) is the upper-right corner of the display.</li>\n<li><strong>Alpha value</strong> — a number between 0 and 1 that controls the opacity at that point. A value of 0 means the content is fully visible (the mask is transparent), while a value of 1 means the content is fully hidden (the mask is opaque). The renderer interpolates alpha values smoothly across the mesh between junction points.</li>\n<li><strong>Bézier handles</strong> — each junction can have up to four directional handles (Left, Right, Up, Down) that control the curvature of the mesh edges passing through that point. By adjusting handle length and angle, you can create smooth curves instead of straight-line segments between junctions.</li>\n<li><strong>Smooth toggle</strong> — when enabled, forces the handles at a junction to maintain tangent continuity (G¹ continuity), so curves flowing through the point form a smooth, kink-free transition. Disable this when you need a sharp corner or abrupt direction change at a junction.</li>\n\n</ul>\nThe mask mesh requires a minimum of two rows and two columns of junction points. You can add rows and columns by clicking on an edge between two existing junctions — the editor inserts a new junction at that position, splitting the adjacent Bézier curves while preserving the overall shape. Rows and columns can also be removed, as long as at least two remain in each dimension.\n\n<h3>Mask Images</h3>\n\n<p>In addition to geometric masks, you can assign an <strong>image asset</strong> as a mask source on a display. This is useful when you have a pre-rendered mask texture — for example, an alpha map exported from a 3D modeling tool or a camera-captured calibration image.</p>\n\n<p>To assign a mask image, select the display and set the mask image property to the desired asset. To remove it, clear the asset reference. Mask images and geometric masks can coexist; the image acts as an additional masking layer.</p>\n\n<h3>Gamma Correction</h3>\n\n<p>Each mask surface has a <strong>gamma correction</strong> parameter that adjusts how the feathered transition between visible and hidden regions is rendered. The default value approximates a perceptually linear fade, but depending on the display technology and viewing environment, you may need to adjust it:</p>\n\n<ul>\n<li><strong>Lower gamma values</strong> (below the default) produce a softer, more gradual fade that may look more natural on projectors with higher native contrast.</li>\n<li><strong>Higher gamma values</strong> produce a faster rolloff, concentrating the transition in a narrower band.</li>\n\n</ul>\nGamma correction is particularly important when masks are used in combination with edge blending. Mismatched gamma between the mask feather and the soft-edge blend can produce visible intensity bands or dark seams in the overlap region.\n\n<h3>Automatic Soft Edges</h3>\n\n<p>In addition to custom masks, WATCHOUT offers an <strong>Automatic Soft Edges</strong> feature found in the Mask section of Device Properties. When enabled, the system automatically generates soft-edge gradients wherever overlapping displays are detected. This is a quick way to set up basic blend zones without manual mask editing.</p>\n\n<p>Automatic soft edges have their own <strong>Gamma Correction</strong> slider (range 0.5–1.5, default 1.0) that controls the intensity falloff of the generated blend gradients. This setting is separate from the per-surface gamma of custom masks.</p>\n\n<div class='note-box'><p>Automatic soft edges are not available for projector-type displays or canvas displays. Use custom masks for these configurations.\n</p></div>\n\n<h3>Common Workflows</h3>\n\n<p><strong>Masking projection spill:</strong> When a projector illuminates an area larger than the intended surface, add a mask to cut the output at the scenic boundary. Start with a rectangular or side mask preset, then adjust junction points to follow the edge of the physical surface.</p>\n\n<p><strong>Shaping output for scenic elements:</strong> For irregularly shaped screens — curved walls, architectural features, or set pieces — use a combination of junction points with Bézier handles to trace the contour of the surface. The round mask preset is a good starting point for circular or oval elements.</p>\n\n<p><strong>Custom blend regions with edge blending:</strong> When the automatic soft-edge feature does not produce satisfactory results — for example, on non-planar surfaces or with uneven overlap widths — use custom masks to manually define the blend zone. Place junction points along the overlap boundary and set alpha values to create a graduated transition that matches the neighboring display's mask.</p>\n\n<p><strong>Multi-layer masking:</strong> Combine multiple mask surfaces on a single display for complex scenarios. For instance, one surface can handle the blend zone on the left edge, while another cuts an irregular scenic border on the right.</p>\n\n<h3>Relationship to Warp Geometry</h3>\n\n<p>Warp geometry and display masks are independent systems that serve different purposes in the rendering pipeline:</p>\n\n<ul>\n<li><strong>Warp geometry</strong> repositions pixels — it corrects for surface curvature, projector alignment errors, and perspective distortion by shifting where each pixel is drawn.</li>\n<li><strong>Display masks</strong> control pixel visibility — they determine whether a pixel is shown, hidden, or partially transparent by applying an alpha overlay.</li>\n\n</ul>\nIn the rendering chain, warp is applied first, and masks are applied afterward on the already-warped output. This means mask coordinates correspond to the final display surface, not the pre-warp content space.\n\n<p>As a general rule: use warp to make the image fit the surface geometry, and use masks to shape the visible boundary and blend zones after the geometry is correct.</p>",
      "SDI Output": "<h2>SDI Output</h2>\n\n<p>SDI (Serial Digital Interface) is a professional video transport standard used widely in broadcast, live event, and AV installation environments. In WATCHOUT, SDI is one of the four display output types alongside GPU, NDI, and Virtual. Choosing SDI routes the rendered display output through a dedicated SDI capture/output card installed in the Runner node, delivering an uncompressed digital video signal over coaxial BNC cabling.</p>\n\n<p>SDI is the right choice when your downstream equipment — video switchers, LED processors, recording systems, or broadcast infrastructure — expects a baseband SDI signal rather than a direct GPU output or network-based stream.</p>\n\n<h3>Configuring an SDI Display</h3>\n\n<p>To set up a display for SDI output:</p>\n\n<ol>\n<li>Select the display in the Stage or Device list.</li>\n<li>In <strong>Device Properties → Output</strong>, set the <strong>Output Type</strong> to <strong>SDI</strong>.</li>\n<li>Assign the <strong>Channel</strong> number corresponding to the physical SDI output connector on the installed card.</li>\n<li>Set the <strong>Resolution</strong> to match the expected downstream signal format.</li>\n<li>Choose the appropriate <strong>SDI Link Type</strong> for the target resolution and bandwidth.</li>\n\n</ol>\n<h3>SDI Link Types</h3>\n\n<p>The link type determines how many physical SDI connections are used to transport a single display's output. Higher resolutions and frame rates require more bandwidth than a single SDI link can carry, so multiple links are bonded together:</p>\n\n<ul>\n<li><strong>Single-Link</strong> — uses one SDI connection. Supports resolutions up to HD (1920×1080) at standard frame rates on 3G-SDI, or SD formats on HD-SDI. This is the default and most common configuration.</li>\n<li><strong>Dual-Link</strong> — uses two SDI connections bonded together, doubling the available bandwidth. Required for resolutions or color depths that exceed single-link capacity, such as 1080p at higher frame rates or some 2K formats with extended bit depth.</li>\n<li><strong>Quad-Link Interleaved</strong> — uses four SDI connections with the image samples interleaved across the links. This supports UHD/4K resolutions (3840×2160) by distributing alternating pixel data across all four cables.</li>\n<li><strong>Quad-Link Quadrant</strong> — uses four SDI connections where each link carries one spatial quadrant of the full image. This is an alternative 4K transport method where each cable transmits a distinct quarter of the frame. Some downstream equipment prefers one quad-link method over the other, so check your receiver's specifications.</li>\n\n</ul>\n<h3>Channel Assignment</h3>\n\n<p>The <strong>Channel</strong> property identifies which physical output port on the SDI card is used for this display. Channel numbering starts at 1 and maps directly to the hardware connectors. If your Runner node has a card with four SDI outputs, channels 1–4 correspond to those four BNC connectors.</p>\n\n<p>When using dual-link or quad-link modes, the channel number refers to the first connector in the group — the card automatically bonds the required number of adjacent outputs.</p>\n\n<h3>Color and Signal Settings</h3>\n\n<p>SDI output in WATCHOUT uses the following signal characteristics:</p>\n\n<ul>\n<li><strong>Color Depth</strong> — SDI outputs currently operate at 8 bits per component. The system converts the internally rendered imagery to 8-bpc YCbCr for SDI transport using the UYVY packed format.</li>\n<li><strong>Color Space</strong> — the SDI rendering pipeline uses Rec. 709 color primaries with an SDR transfer function for the YCbCr conversion. This matches the standard color encoding expected by most professional SDI equipment.</li>\n<li><strong>Interlaced</strong> — enable this toggle when the downstream equipment requires an interlaced signal (e.g., 1080i for broadcast contribution). When disabled, the output is progressive.</li>\n\n</ul>\n<h3>Max Quality Mode</h3>\n\n<p>The <strong>Render with maximum quality</strong> toggle selects a higher-precision intermediate rendering format. When enabled, the internal render buffer uses 16-bit floating-point (RGBA16F) instead of the default 11/11/10-bit packed float (R11F_G11F_B10F). This can reduce banding artifacts in gradients and subtle color transitions, at the cost of slightly higher GPU memory usage. Enable this when the content demands it — particularly for HDR-mastered material or content with extensive color grading.</p>\n\n<h3>Genlock</h3>\n\n<p>In multi-display SDI environments, frame-accurate synchronization is critical to prevent tearing or timing mismatches between outputs. WATCHOUT supports <strong>SDI Genlock</strong>, which locks the frame output timing of SDI displays to an external reference signal (typically blackburst or tri-level sync).</p>\n\n<p>Genlock is controlled as a <strong>show-level property</strong> (not per-display). When enabled, all SDI outputs across the system synchronize their frame delivery to the reference signal provided to the SDI card's genlock input.</p>\n\n<p>To enable SDI genlock:</p>\n\n<ol>\n<li>Open <strong>Show Properties</strong> (Preferences).</li>\n<li>Enable the <strong>SDI Genlock</strong> toggle.</li>\n<li>Ensure the SDI card's reference input is connected to a valid sync source.</li>\n\n</ol>\nGenlock ensures that all Runner nodes with SDI outputs deliver frames at precisely the same time, which is essential for seamless multi-projector arrays, LED wall setups, and broadcast environments where downstream equipment expects time-aligned signals.\n\n<h3>Frame Delay</h3>\n\n<p>The <strong>Delay Frames</strong> setting (0–10 frames) adds a configurable output delay to the display. Each frame of delay adds one additional frame buffer to the rendering pipeline before the pixels are sent to the SDI output.</p>\n\n<p>This is useful for compensating processing latency in downstream equipment. For example, if an LED processor introduces a fixed two-frame delay, you can add a matching delay to other displays in the system so that all outputs appear synchronized to the viewer.</p>\n\n<p>The delay buffer is allocated at initialization — the SDI output always maintains (delay + 1) render target buffers in a ring, presenting the oldest completed frame while rendering into the newest.</p>\n\n<h3>Hardware Requirements</h3>\n\n<p>SDI output in WATCHOUT requires a <strong>Deltacast</strong> SDI capture/output card installed in the Runner node. The system uses both the Deltacast SDK for stream management and the Deltacast GPU SDK for zero-copy texture transfer between the GPU render pipeline and the SDI output.</p>\n\n<p>Key requirements:</p>\n\n<ul>\n<li><strong>Deltacast SDI card</strong> with output capability (e.g., Deltacast DELTA-12G series or equivalent)</li>\n<li><strong>Deltacast drivers and SDK libraries</strong> installed and accessible on the Runner machine</li>\n<li><strong>GPU with OpenGL compute shader support</strong> for the UYVY conversion and warp/blend compositing</li>\n\n</ul>\nIf the required Deltacast libraries are not loaded, the Runner will log an error and the SDI display will not initialize. Verify that the Deltacast drivers are correctly installed and that the card is recognized by the operating system before configuring SDI outputs.\n\n<div class='info-box'><p>When troubleshooting SDI output, check the Runner's log for messages about stream creation and texture attachment. The log reports the channel number, resolution, and any initialization failures with specific error codes from the Deltacast SDK.\n</p></div>",
      "HDR and Color Management": "<h2>HDR and Color Management</h2>\n\n<p>WATCHOUT includes a color-managed rendering pipeline that handles the full chain from media decode through compositing to display output. This pipeline supports both standard dynamic range (SDR) and high dynamic range (HDR) workflows, with configurable color spaces and transfer functions at the asset, cue, and display levels.</p>\n\n<p>Understanding how color spaces, transfer functions, and bit depth interact is important for achieving accurate, consistent color across multi-display setups — especially when mixing SDR and HDR content or driving displays with different capabilities.</p>\n\n<h3>Color Spaces</h3>\n\n<p>A color space defines the range of colors (the \"gamut\") that can be represented, specified by three color primaries and a white point. WATCHOUT supports the following color spaces for display output:</p>\n\n<ul>\n<li><strong>sRGB</strong> — the standard color space for computer displays, using Rec. 709 primaries with the sRGB transfer function. This is appropriate for most conventional displays and projectors.</li>\n<li><strong>sRGB (gamma 2.2)</strong> — identical primaries to sRGB but using a simple 2.2 power-law gamma curve instead of the sRGB piecewise function. Some display hardware and workflows assume a pure gamma 2.2 characteristic. This is the default color space for new displays.</li>\n<li><strong>Rec. 601</strong> — the legacy standard-definition color space, sometimes relevant for SD broadcast or older equipment.</li>\n<li><strong>Rec. 709</strong> — the HD broadcast standard, sharing primaries with sRGB but using the SDR (BT.1886) transfer function. Use this for broadcast-oriented outputs and SDI feeds.</li>\n<li><strong>Rec. 2020</strong> — a wide-gamut color space that covers a significantly larger portion of visible colors than Rec. 709. Used for UHD/4K SDR content that requires extended color accuracy. Because no current display hardware can reproduce the full Rec. 2020 gamut, this space serves as a target for wide-gamut content that will be displayed on the best available hardware.</li>\n<li><strong>Rec. 2100 PQ</strong> — combines Rec. 2020 wide-gamut primaries with the Perceptual Quantizer (PQ) transfer function, as defined in the SMPTE ST 2084 standard. PQ maps absolute luminance levels up to 10,000 nits, making it the foundation of HDR10 delivery.</li>\n<li><strong>Rec. 2100 PQ (HDR10)</strong> — the same as Rec. 2100 PQ but with HDR10 static metadata signaling enabled. Use this when the display or downstream equipment expects HDR10 metadata (MaxCLL, MaxFALL) in the signal.</li>\n<li><strong>Rec. 2100 HLG</strong> — combines Rec. 2020 primaries with the Hybrid Log-Gamma (HLG) transfer function. HLG is designed to be backward-compatible with SDR displays — the lower portion of the curve resembles a standard gamma curve, while the upper portion extends into HDR. This is commonly used in live broadcast HDR workflows.</li>\n\n</ul>\nWhen rendering, WATCHOUT performs all pixel operations (blending, interpolation, compositing) in linear light. Source media is linearized on decode, processed internally, and then delinearized to the target transfer function on output. If the source and destination color primaries differ, a 3×3 matrix transform converts between them.\n\n<h3>Transfer Functions</h3>\n\n<p>Transfer functions define how linear light values are encoded into the non-linear signal that displays expect. Encoding fewer bits for bright values and more bits for dark values matches human visual perception, reducing visible banding:</p>\n\n<ul>\n<li><strong>sRGB</strong> — a piecewise curve with a linear segment near black and a power-law segment for the rest. Standard peak brightness is 80 nits. Used with sRGB and standard computer displays.</li>\n<li><strong>SDR (BT.1886)</strong> — the broadcast SDR transfer function with a standard peak brightness of 100 nits. Used with Rec. 709 and Rec. 601 outputs.</li>\n<li><strong>PQ (Perceptual Quantizer)</strong> — an absolute luminance curve covering 0–10,000 nits. PQ encodes luminance values that map directly to real-world brightness levels, enabling HDR content to specify exact nit values. Used with Rec. 2100 PQ and HDR10.</li>\n<li><strong>HLG (Hybrid Log-Gamma)</strong> — a relative luminance curve with a standard peak of 1,000 nits. The lower half uses a gamma-like curve (backward-compatible with SDR displays), and the upper half uses a logarithmic extension for HDR highlights. Used with Rec. 2100 HLG.</li>\n\n</ul>\nThe choice of transfer function is determined by the color space you select on the display. For example, selecting Rec. 2100 PQ automatically uses the PQ transfer function.\n\n<h3>Display Color Depth</h3>\n\n<p>Color depth determines how many bits are used per color component in the output signal. Higher bit depth reduces banding artifacts, which is especially important for HDR content:</p>\n\n<ul>\n<li><strong>8 bpc (bits per component)</strong> — 256 levels per channel. Standard for SDR content on most displays. Adequate for sRGB and Rec. 709 workflows.</li>\n<li><strong>10 bpc</strong> — 1,024 levels per channel. Recommended for HDR output and wide-gamut content. PQ-encoded HDR10 requires at least 10-bit output to avoid visible banding in dark areas and gradients.</li>\n<li><strong>12 bpc</strong> — 4,096 levels per channel. Available for display hardware that supports it; useful for professional mastering and reference monitoring.</li>\n<li><strong>16 bpc</strong> — 65,536 levels per channel. The highest precision available, suitable for specialized workflows requiring extreme accuracy.</li>\n\n</ul>\nColor depth is configured per display in <strong>Device Properties → Output → Signal</strong> and is available for GPU output types. SDI outputs currently operate at 8 bpc.\n\n<h3>SDR White Point (Per-Cue)</h3>\n\n<p>When SDR content plays on an HDR display, the system needs to know how bright \"white\" in the SDR content should appear relative to the HDR luminance range. The <strong>SDR White Point</strong> property on media cues controls this mapping.</p>\n\n<p>The value is specified in nits (candelas per square meter) and ranges from 80 to 10,000. For example:</p>\n\n<ul>\n<li>A value of <strong>100 nits</strong> means SDR white maps to 100 nits on the HDR display — typical for content mastered to broadcast SDR standards.</li>\n<li>A value of <strong>200 nits</strong> boosts SDR content to appear brighter, which may be appropriate for content viewed in bright ambient light.</li>\n\n</ul>\nThis setting only takes effect when the display is configured for an HDR color space. On SDR displays, it has no impact.\n\n<h3>Per-Display Color Settings</h3>\n\n<p>Each display in WATCHOUT has independent color configuration in the <strong>Output → Signal</strong> section of Device Properties:</p>\n\n<ul>\n<li><strong>Color Space</strong> — selects the target color space and transfer function for GPU outputs. The available options are the full list described above (sRGB, sRGB gamma 2.2, Rec. 709, Rec. 2020, Rec. 2100 PQ, Rec. 2100 PQ HDR10, Rec. 2100 HLG).</li>\n<li><strong>Color Depth</strong> — selects the output bit depth (8, 10, 12, or 16 bpc) for GPU outputs.</li>\n\n</ul>\nThese settings tell the renderer what format to output. They should match the capabilities of the physical display hardware. Setting an HDR color space on a display that only supports SDR will result in incorrect rendering.\n\n<h3>NDI Color Space</h3>\n\n<p>Displays configured with NDI output have a separate <strong>NDI Color Space</strong> setting that controls the color encoding of the NDI stream. The available options are:</p>\n\n<ul>\n<li><strong>Auto</strong> — lets the system choose based on resolution and context.</li>\n<li><strong>Rec. 601</strong> — for SD-resolution NDI streams or legacy receivers.</li>\n<li><strong>Rec. 709</strong> — the standard for HD NDI streams.</li>\n<li><strong>Rec. 2020</strong> — for wide-gamut NDI delivery to compatible receivers.</li>\n\n</ul>\nThe NDI color space is independent of the GPU color space setting, since NDI and GPU outputs may serve different destinations with different requirements. NDI outputs also support the <strong>Interlaced</strong> toggle for compatibility with interlaced NDI receivers.\n\n<h3>Asset Color Space</h3>\n\n<p>Media assets carry color metadata that tells the renderer how to interpret the source pixels. WATCHOUT's decode pipeline detects the color space from the media container or codec metadata when available. If the metadata is missing or incorrect, you can override the asset's color space in the asset properties.</p>\n\n<p>The renderer uses this information to linearize the source correctly and, if necessary, convert from the asset's color primaries to the display's target primaries during compositing. Accurate asset color metadata is essential for correct rendering — if a Rec. 2020 asset is incorrectly tagged as Rec. 709, the colors will be desaturated on output.</p>\n\n<h3>White Point Calibration</h3>\n\n<p>Every display has a <strong>White Point</strong> setting in Device Properties, consisting of separate Red, Green, and Blue sliders (each ranging from 0.0 to 1.0, defaulting to 1.0). This is a per-display color temperature correction that adjusts the white balance of the output.</p>\n\n<p>The primary use case is <strong>projector color matching</strong> in multi-projector setups. When adjacent projectors have slightly different color temperatures (one appears warmer, another cooler), adjusting the white point sliders brings them into visual alignment. For example, if a projector's output appears too blue, reduce the Blue slider slightly until the white tone matches neighboring units.</p>\n\n<p>White point correction is applied as a per-pixel RGB multiplier in the output shader, after all other compositing and color space conversion has been completed. It affects the entire output of the display uniformly.</p>\n\n<h3>Tone Mapping</h3>\n\n<p>When HDR content is rendered to an SDR display, the high dynamic range must be compressed to fit the SDR output range without losing important detail in highlights and shadows. WATCHOUT uses a <strong>Hable tone mapping operator</strong> for this conversion, which preserves natural-looking midtones while smoothly compressing highlights toward peak white.</p>\n\n<p>Tone mapping is applied automatically when the source content has a wider dynamic range than the target display. No manual configuration is required — the system handles the conversion based on the source and destination transfer functions.</p>\n\n<h3>Practical Workflow</h3>\n\n<p><strong>Pure SDR setup:</strong> For conventional SDR workflows, set displays to sRGB (gamma 2.2) or Rec. 709 with 8-bpc output. No additional color management configuration is needed beyond matching the display's native capability.</p>\n\n<p><strong>Pure HDR setup:</strong> Set displays to Rec. 2100 PQ (or HDR10) with 10-bpc output. Ensure the physical display hardware supports HDR10 signaling. All content should be mastered or tagged with the correct HDR color metadata.</p>\n\n<p><strong>Mixed SDR/HDR content on HDR displays:</strong> Set the display to an HDR color space and use the per-cue SDR White Point property to control how SDR assets map into the HDR luminance range. Start with 100–200 nits and adjust based on the ambient viewing environment.</p>\n\n<p><strong>Multi-display color consistency:</strong> Use the per-display white point sliders to visually match color temperature across all outputs. Work with a neutral test image (gray ramp or white field) and adjust under final show lighting conditions. Lock display settings once calibration is approved to prevent accidental changes.</p>",
      "Test Patterns": "<h2>Test Patterns</h2>\n\n<p>Test patterns are built-in diagnostic output modes rendered directly by the Runner on a per-display basis. They are independent of show content and timeline playback, making them essential tools for verifying display setup, signal routing, geometry correction, and color calibration before or during a production.</p>\n\n<h3>Accessing Test Patterns</h3>\n\n<p>Test pattern controls are found in <strong>Device Properties → Test Pattern</strong> for any selected display. The section provides a set of output mode buttons and an additional toggle for the render info overlay.</p>\n\n<p>To activate a test pattern, select the desired mode from the button group. To return to normal show output, select <strong>None</strong>.</p>\n\n<h3>Output Modes</h3>\n\n<p>WATCHOUT provides five display output modes, controlled from the Test Pattern section:</p>\n\n<ul>\n<li><strong>None</strong> — normal operation. The display renders show content from the timeline as usual. This is the default mode.</li>\n<li><strong>Muted</strong> — the display output is suppressed (black). Show content continues to play on the timeline but is not rendered to this display's output. Use this to temporarily black out a display without stopping playback or modifying the show.</li>\n<li><strong>White</strong> — the display renders a solid white field at full brightness. This is useful for checking projector alignment, verifying that the signal path is active, and assessing display uniformity. Because this mode ignores the warp and mask pipeline, the white field fills the entire raw output area.</li>\n<li><strong>Masked</strong> — the display renders a solid white field with the current warp geometry and mask applied. This shows exactly which pixels are visible after all geometry correction and masking. Use it to verify that warp and mask settings are producing the expected output shape and to check for gaps or overlaps in a multi-display blended setup.</li>\n<li><strong>Pattern</strong> — the display renders a built-in test pattern (typically a grid or alignment chart) through the full rendering pipeline including warp and mask. This is the primary diagnostic mode for verifying geometric accuracy, resolution, aspect ratio, and pixel alignment.</li>\n\n</ul>\n<h3>Render Info Overlay</h3>\n\n<p>The <strong>Render Info</strong> toggle (available alongside the output mode buttons) enables a heads-up diagnostic overlay on the display output. When active, the Runner renders technical information directly onto the display, such as the display name, resolution, frame rate, and other runtime diagnostics.</p>\n\n<p>This overlay is drawn on top of whatever output mode is currently active — whether normal show content, a test pattern, or a white field. It is useful for quickly identifying which physical output corresponds to which display in the WATCHOUT configuration, especially in large multi-display systems where it can be difficult to tell outputs apart by visual content alone.</p>\n\n<h3>Common Use Cases</h3>\n\n<p><strong>Verifying signal routing:</strong> After configuring displays and assigning output channels, switch each display to <strong>White</strong> mode one at a time. This confirms that the correct physical output activates for each display in the WATCHOUT configuration. If the wrong screen lights up, the channel assignment or host address needs to be corrected.</p>\n\n<p><strong>Checking warp and mask geometry:</strong> Use <strong>Masked</strong> mode to see the exact output boundary after warp correction and masking. The white field makes it easy to spot misalignment, gaps between adjacent displays, or mask edges that don't follow the physical surface. Follow up with <strong>Pattern</strong> mode to check for geometric distortion using the grid lines.</p>\n\n<p><strong>Display alignment in multi-projector setups:</strong> Switch all overlapping projectors to <strong>Pattern</strong> mode simultaneously. The grid patterns from adjacent displays should align at the overlap boundaries. Misalignment indicates that warp geometry or projector placement needs adjustment.</p>\n\n<p><strong>Color uniformity checks:</strong> Use <strong>White</strong> mode across all displays to compare brightness and color temperature. Differences are immediately visible and can be corrected using the per-display White Point sliders.</p>\n\n<p><strong>Isolating content issues:</strong> If a display appears incorrect during playback, switch it to <strong>Muted</strong> and then back to <strong>None</strong> to determine whether the issue is in the content, the display configuration, or the signal path.</p>\n\n<h3>Interaction with Show Playback</h3>\n\n<p>Test pattern modes operate at the output stage of the rendering pipeline. When a non-default mode is active:</p>\n\n<ul>\n<li>The timeline continues to run and cues continue to be evaluated, but the rendered show content is replaced (not overlaid) by the selected test pattern or solid color.</li>\n<li>Switching back to <strong>None</strong> immediately resumes normal show output without interrupting playback.</li>\n<li>Test pattern modes are <strong>not saved</strong> as part of the show file. They are runtime-only display states that reset to <strong>None</strong> when the Runner restarts or the show is reloaded.</li>\n\n</ul>\nThis means you can safely use test patterns during setup and rehearsal without affecting the show data or worrying about accidentally leaving a display in test mode for the performance.\n\n<div class='info-box'><p>During technical rehearsal, use the <strong>Render Info</strong> overlay on all displays to keep track of which output is which, then disable it before the audience enters.\n</p></div>",
      "Display Calibration": "<h2>Display Calibration</h2>\n\n<p>Calibration is the process of aligning WATCHOUT's rendered output to the physical reality of the display surface. This encompasses projector alignment for 3D mapping, camera-based calibration via NDI streams, EDID management for display identification, and external calibration integration through the HTTP API.</p>\n\n<h3>NDI Calibration Stream</h3>\n\n<p>For camera-based calibration workflows, each GPU display can be assigned an <strong>NDI Calibration Stream</strong> in the <strong>Calibration</strong> section of Device Properties. This setting specifies the name of an NDI video stream that carries a live camera feed of the display surface.</p>\n\n<p>When configured, the Runner can receive the NDI stream and use it as a reference input for alignment. This is typically used in automated or semi-automated calibration systems where a camera observes the projected output and provides feedback for geometric correction.</p>\n\n<p>To set up an NDI calibration stream:</p>\n\n<ol>\n<li>Select the display in Device Properties.</li>\n<li>Open the <strong>Calibration</strong> section.</li>\n<li>Enter the NDI stream name in the <strong>Calibration Stream</strong> field.</li>\n\n</ol>\nThe stream name should match the NDI source name exactly as it appears on the network. The calibration system uses this stream to compare the expected output pattern with the observed result on the physical surface.\n\n<h3>Projector Calibration (3D Mapping)</h3>\n\n<p>For 3D projector displays, WATCHOUT provides a dedicated calibration system that uses point correspondences to compute the projector's position, orientation, and lens parameters. This is essential for accurate projection mapping where content must align precisely to a physical 3D model.</p>\n\n<h4>Virtual Points and Reality Points</h4>\n\n<p>The calibration process works with two sets of points:</p>\n\n<ul>\n<li><strong>Virtual points</strong> are placed on the 3D model in the Stage view. They represent known locations on the surface where you want the projected image to land. Virtual points are defined in world coordinates (X, Y, Z).</li>\n<li><strong>Reality points</strong> are the corresponding positions on the projector's 2D output where those virtual-point locations actually appear when projected. Reality points are defined in normalized screen coordinates.</li>\n\n</ul>\nThe calibration algorithm uses these point pairs to solve for the projector's intrinsic parameters (focal length, lens shift) and extrinsic parameters (position, orientation) using a camera calibration model.\n\n<h4>Calibration Workflow</h4>\n\n<ol>\n<li><strong>Switch to Calibration mode</strong> — in the Stage toolbar, switch the projector view from <strong>View</strong> mode to <strong>Calibration</strong> mode. This enables the calibration point editing tools.</li>\n\n<p><li><strong>Place virtual points</strong> — using the point tools in the Stage view, add virtual points on the 3D model at clearly identifiable surface locations (corners, edges, landmarks). You can add, move, and remove points using the toolbar actions.</li></p>\n\n<p><li><strong>Place at least six points</strong> — the calibration algorithm requires a minimum of six virtual points before you can edit reality points. This minimum ensures the system has enough constraints to solve for all projector parameters.</li></p>\n\n</ol>\n<div class='warning-box'><p>You need to create at least six virtual points to edit the reality points.\n</p></div>\n\n<ol>\n<li><strong>Edit reality points</strong> — once six or more virtual points exist, switch to reality-point editing. For each virtual point, adjust the corresponding reality point to match where that location actually appears on the projector's output. The Stage view shows both sets of points for comparison.</li>\n\n<p><li><strong>Calibrate</strong> — trigger the calibration computation. The system solves for the projector parameters that best align the virtual and reality point pairs.</li></p>\n\n</ol>\n<h4>Continuous vs. Manual Calibration</h4>\n\n<p>The calibration toolbar provides two calibration behaviors:</p>\n\n<ul>\n<li><strong>Continuous calibration</strong> — the system recalculates the projector parameters automatically every time you move a point. This provides real-time feedback as you adjust reality points, making it easier to converge on an accurate alignment.</li>\n<li><strong>Manual calibration</strong> — the system only recalculates when you explicitly press the Calibrate button. Use this when you want to adjust multiple points before triggering a recalculation, or when continuous recalculation is distracting.</li>\n\n</ul>\n<h4>Calibration Accuracy</h4>\n\n<p>After calibration, WATCHOUT displays an <strong>accuracy indicator</strong> that shows how well the computed projector model aligns the virtual and reality points. A low error value (reprojection error) indicates good alignment. An error above 100 indicates a significant problem — typically caused by incorrect point placement, insufficient point count, or a physical setup that doesn't match the model.</p>\n\n<p>If the accuracy is poor, review the point placements and check for:</p>\n\n<ul>\n<li>Points that are nearly coplanar (insufficient 3D variation)</li>\n<li>Incorrectly matched virtual/reality pairs</li>\n<li>Physical obstructions or distortions not captured in the model</li>\n\n</ul>\n<h4>Reposition Action</h4>\n\n<p>The <strong>Reposition</strong> action moves all reality points to sit directly on top of their corresponding virtual points in the current projector view. This is useful as a reset or starting point before manual fine-tuning — it gives you a clean baseline where both point sets overlap, and you can then adjust individual reality points to account for real-world discrepancies.</p>\n\n<h4>Projector Parameter Locking</h4>\n\n<p>During calibration, you can lock specific projector parameters to prevent the calibration algorithm from changing them:</p>\n\n<ul>\n<li><strong>Lock Lens Shift</strong> — prevents the calibration from adjusting the horizontal and vertical lens shift values. Use this when you know the lens shift setting from the projector's specification sheet and want to preserve it.</li>\n<li><strong>Lock Width / Distance Ratio</strong> — prevents the calibration from adjusting the throw ratio. Use this when the throw ratio is precisely known from the lens data.</li>\n\n</ul>\nLocking parameters reduces the degrees of freedom in the calibration solve, which can improve accuracy when the locked values are known to be correct, but can also degrade results if the locked values are wrong.\n\n<h3>EDID Capture</h3>\n\n<p>EDID (Extended Display Identification Data) is a data block that displays transmit to describe their capabilities — supported resolutions, timing modes, color depth, and manufacturer information. WATCHOUT can capture and save a display's EDID data as an asset in the show.</p>\n\n<p>To capture EDID:</p>\n\n<ol>\n<li>Select the GPU display in Device Properties.</li>\n<li>In the <strong>Output</strong> section, locate the EDID row.</li>\n<li>Click <strong>Save EDID</strong>.</li>\n\n</ol>\nThe captured EDID is stored as an asset that you can reference later for troubleshooting or for applying to other displays. You can also select a previously captured EDID asset from the dropdown to apply it to the display, or choose <strong>Current Monitor</strong> to use the live EDID from the connected display hardware, or <strong>Keep</strong> to not send any EDID override.\n\n<div class='note-box'><p>The display must be <strong>enabled</strong> to capture its EDID. If the display is disabled, the Save EDID button will be inactive.\n</p></div>\n\n<p>EDID capture is particularly useful in rental and staging environments where you need to document the exact display capabilities at each venue, or when troubleshooting resolution and timing issues where the display is not advertising the expected modes.</p>\n\n<h3>External Calibration Triggers</h3>\n\n<p>WATCHOUT supports an external calibration trigger mechanism that allows third-party calibration systems to put displays into calibration mode via the HTTP API. This is used in automated calibration workflows where an external system (such as VIOSO or other camera-based alignment tools) needs WATCHOUT to display calibration patterns while the external system captures and processes the result.</p>\n\n<p>The trigger works through the Operative's HTTP input endpoint:</p>\n\n<ul>\n<li><strong>Endpoint:</strong> <code>POST /v0/inputs</code> on the Operative's external port</li>\n<li><strong>Input key:</strong> <code>displaycalibration</code></li>\n<li><strong>Value:</strong> <code>1.0</code> to enter calibration mode, <code>0.0</code> to exit</li>\n\n</ul>\nA typical automated calibration sequence:\n\n<ol>\n<li>The external system sends <code>displaycalibration = 1.0</code> to put WATCHOUT displays into calibration mode.</li>\n<li>The external system runs its calibration process (projecting patterns, capturing camera images, computing corrections).</li>\n<li>The external system copies the resulting calibration data (e.g., MPCDI files) to the expected location.</li>\n<li>The external system sends <code>displaycalibration = 0.0</code> to return WATCHOUT to normal operation.</li>\n\n</ol>\nThis integration supports hardware trigger devices (such as Elgato Stream Deck) for operator-initiated recalibration in permanent installations.\n\n<h3>Best Practices</h3>\n\n<p>For the best calibration results, follow this recommended order of operations:</p>\n\n<ol>\n<li><strong>Physical alignment</strong> — mount and aim projectors/displays as accurately as possible before any software correction. The less the software needs to compensate, the better the final image quality.</li>\n<li><strong>Coarse warp</strong> — apply initial warp geometry correction to get the output roughly aligned to the surface.</li>\n<li><strong>Calibration</strong> — run the projector calibration (for 3D mapping) or external calibration workflow to compute precise alignment parameters.</li>\n<li><strong>Fine adjustment</strong> — refine warp junction points and handles for any remaining geometric errors.</li>\n<li><strong>Mask</strong> — add masks to shape the visible output boundary, cut spill, and define blend zones.</li>\n<li><strong>Content verification</strong> — play representative show content at final brightness and verify that alignment, color, and blending are correct across all displays.</li>\n\n</ol>\n<div class='info-box'><p>Save a snapshot of the show file after successful calibration so you can revert if subsequent edits introduce problems. Treat calibration state as critical show data.\n</p></div>"
    }
  },
  "5. Assets & Asset Manager": {
    "overview": "<h1>ASSETS & ASSET MANAGER</h1>\n\n<p>The Asset Manager is the central hub for all media content in WATCHOUT 7. It handles importing, organizing, optimizing, and distributing media files across your production network. Understanding the Asset Manager is essential for efficient show production.</p>",
    "sections": {
      "Asset Manager": "<h2>Asset Manager</h2>\n\n<p>The Asset Manager is the background service that handles all media in a WATCHOUT 7 show. It accepts source files, optimizes them for real-time playback, and distributes the results to every display server on the network.</p>\n\n<h3>Overview</h3>\n\n<p>Every WATCHOUT show has exactly one Asset Manager, which runs on the node designated in the show's host configuration. The Asset Manager provides:</p>\n\n<ul>\n<li><strong>Centralized storage</strong> – all media files are managed from a single location.</li>\n<li><strong>Automatic optimization</strong> – source files are transcoded to GPU-friendly playback codecs (HAP by default).</li>\n<li><strong>Network distribution</strong> – optimized assets are transferred to display servers when a show goes online.</li>\n<li><strong>Version tracking</strong> – changes to source files are detected and, if configured, re-optimized automatically.</li>\n\n</ul>\nWhen an asset is added, the Asset Manager copies the source file, runs the optimizer, and stores both the original and the optimized version. Display servers receive only the optimized file.\n\n<h3>The Assets Window</h3>\n\n<p>The Assets window is the primary interface for browsing and managing media. Open it from <strong>Window → Assets</strong> or press <strong>Ctrl+2</strong>.</p>\n\n<p><!-- screenshot: Assets window overview showing toolbar, search bar, tree table with folders and assets --></p>\n\n<p>The window displays assets in a tree table with the following default columns:</p>\n\n<ul>\n<li><strong>Name</strong> – file name, with an icon indicating asset type and status.</li>\n<li><strong>Image</strong> – thumbnail preview (shown for video, image, SVG, composition, and font assets).</li>\n<li><strong>Dimensions</strong> – pixel resolution (width × height) or 3D bounding box.</li>\n<li><strong>Duration</strong> – length for video and audio assets (HH:MM:SS.ms).</li>\n<li><strong>Date</strong> – creation or modification timestamp.</li>\n\n</ul>\nAdditional columns can be enabled from the column menu (gear icon in the top-right corner):\n\n<ul>\n<li><strong>Type</strong> – the asset kind (Video, Image, Audio, etc.).</li>\n<li><strong>FPS</strong> – frame rate for video assets.</li>\n<li><strong>Codec</strong> – the optimized or original codec name.</li>\n<li><strong>Color Space</strong> – color space and transfer function (e.g. Rec. 709, sRGB, Rec. 2100 PQ).</li>\n<li><strong>Channels</strong> – audio channel count.</li>\n<li><strong>Original Path</strong> – the source file location on disk.</li>\n\n</ul>\n<h3>Asset Status Indicators</h3>\n\n<p>Each asset displays a status icon next to its name:</p>\n\n<ul>\n<li><strong>Star</strong> – the asset is new (not yet clicked or viewed since it was added).</li>\n<li><strong>Hourglass</strong> – the asset is pending optimization (waiting in the queue).</li>\n<li><strong>Upload arrow</strong> – the asset is currently being uploaded to the Asset Manager.</li>\n<li><strong>Gears</strong> – the asset is currently being optimized.</li>\n<li><strong>Recycle icon</strong> – the asset is a dynamic (auto-updating) asset.</li>\n<li><strong>Progress bar</strong> – a linear progress bar appears beneath the name during upload or optimization.</li>\n\n</ul>\nAssets that failed to optimize are shown with a red name. Select the asset and check the Properties panel for error details.\n\n<h3>Adding Assets</h3>\n\n<p>There are several ways to add media to a show:</p>\n\n<ul>\n<li><strong>Drag and drop</strong> – drag files directly from your file manager into the Assets window. Drop onto a folder row to place them in that folder.</li>\n<li><strong>Add Media File</strong> – right-click in the Assets window and choose <strong>New → Add Media File</strong>, or use the menu shortcut. A file browser opens to select one or more files.</li>\n<li><strong>Add Image Sequence</strong> – right-click and choose <strong>New → Add Image Sequence</strong>, then select the folder containing the numbered frames.</li>\n<li><strong>Asset Watcher</strong> – configure watched folders that automatically import new or changed files (see [Asset Watcher](../09-asset-watcher)).</li>\n<li><strong>Web User Interface</strong> – upload files remotely through the browser-based interface (see [Web User Interface](../08-web-user-interface)).</li>\n\n</ul>\n> <strong>Tip:</strong> When a single folder or dynamic asset is selected, newly added files are placed inside that folder automatically.\n\n<h3>Organizing Assets with Folders</h3>\n\n<p>Create folders to keep large shows organized:</p>\n\n<ol>\n<li>Right-click in the Assets window and choose <strong>New → New Folder</strong>.</li>\n<li>Enter a name and press <strong>OK</strong>.</li>\n<li>Drag assets into the folder to move them.</li>\n\n</ol>\nFolder operations:\n\n<ul>\n<li><strong>Collapse All Folders</strong> / <strong>Expand All Folders</strong> – available from the context menu to quickly navigate large asset trees.</li>\n<li><strong>Drag and drop reorder</strong> – drag assets or folders to reorder them within the same parent.</li>\n<li>Folder open/closed states are remembered per-node and persist between sessions.</li>\n\n</ul>\n> <strong>Note:</strong> Composition and dynamic asset folders are special containers managed by the system. You cannot move assets into or out of composition folders.\n\n<h3>Searching and Filtering</h3>\n\n<p>Click the magnifying glass icon (or press <strong>Ctrl+F</strong> when the Assets window is active) to open the search panel.</p>\n\n<p><!-- screenshot: Search panel expanded, showing text field, type dropdown, and filter checkboxes --></p>\n\n<p>The search panel provides:</p>\n\n<ul>\n<li><strong>Text search</strong> – type one or more keywords. The list filters to assets whose name or folder path contains all keywords (case-insensitive).</li>\n<li><strong>Type filter</strong> – restrict results by asset type: All, Video, Image, Audio, Model, Other, Failed, Used, or Unused.</li>\n<li><strong>Only New</strong> – show only assets that haven't been viewed yet.</li>\n<li><strong>Only Selected Cues</strong> – show only assets referenced by currently selected cues.</li>\n<li><strong>Preparing</strong> – show only assets that are currently uploading or optimizing.</li>\n\n</ul>\nWhen a search or type filter is active, folders expand automatically so matching assets are visible. Press <strong>Escape</strong> to clear the search and restore the previous folder state.\n\n<h3>Sorting</h3>\n\n<p>Click any sortable column header to sort the asset list by that column. Click again to reverse the sort direction. When a column sort is active, the tree view temporarily flattens into a flat list — folder hierarchy is restored when sorting is cleared.</p>\n\n<h3>Context Menu</h3>\n\n<p>Right-click in the Assets window to access:</p>\n\n<ul>\n<li><strong>New</strong> – create folders, shapes (Rectangle, Ellipse, Text), Art-Net fixtures, dynamic assets, or asset versions.</li>\n<li><strong>Delete</strong> – remove selected assets (with confirmation). Assets currently in use on the timeline require additional confirmation.</li>\n<li><strong>Find Cues</strong> – select all cues on the timeline that reference the selected asset(s).</li>\n<li><strong>Collapse/Expand All Folders</strong> – toggle folder visibility.</li>\n<li><strong>Asset Manager Settings</strong> – open the codec and optimization settings dialog.</li>\n<li><strong>Transfer Assets</strong> – export selected or all assets, import from another location, or cache assets on specific runners.</li>\n<li><strong>Asset Web</strong> – open the web-based asset management interface in your browser.</li>\n\n</ul>\n<h3>Keyboard Navigation</h3>\n\n<ul>\n<li><strong>Up / Down arrows</strong> – move selection through the asset list.</li>\n<li><strong>Left / Right arrows</strong> – collapse or expand folders.</li>\n<li><strong>Home / End</strong> – jump to the first or last asset.</li>\n<li><strong>Enter</strong> – open the Properties panel for the selected asset.</li>\n<li><strong>Delete</strong> – delete the selected asset(s).</li>\n<li><strong>Escape</strong> – clear the search and deselect all assets.</li>\n<li><strong>Ctrl+A</strong> – select all visible assets.</li>\n<li><strong>Ctrl+F</strong> – open the search panel.</li>\n\n</ul>",
      "Asset Types": "<h2>Asset Types</h2>\n\n<p>WATCHOUT 7 supports a range of asset types, each serving a different role in a show. The Asset Manager classifies every asset into one of the types described below.</p>\n\n<h3>Visual Media</h3>\n\n<p>Visual media assets produce imagery on displays. They are transcoded by the optimizer and distributed to display servers.</p>\n\n<p><strong>Image</strong> – still images imported from files. Common formats include JPEG, PNG, BMP, TGA, TIFF, EXR, and PSD. Images are optimized into a GPU-friendly format when added to a show.</p>\n\n<p><strong>Video</strong> – motion media imported from video files. Supported source codecs include HAP, HAP Alpha, HAP Q, ProRes 422/4444, DNxHR, H.264, HEVC/H.265, and NotchLC. During optimization, video files are transcoded to the configured output codec (HAP by default).</p>\n\n<p><strong>SVG</strong> – vector shape assets. SVGs can be imported from external files or created directly within WATCHOUT using the built-in shape editor (see [SVG Shapes](../05-svg-shapes)). SVG assets are rendered as images at a configurable resolution.</p>\n\n<p><strong>Image Sequence</strong> – a folder of numbered image files (e.g. <code>frame_0001.png</code>, <code>frame_0002.png</code>) that is treated as a single video-like asset. Supported frame formats include JPEG, PNG, TGA, TIFF, and EXR (see [Image Sequences](../07-image-sequences)).</p>\n\n<h3>Audible Media</h3>\n\n<p><strong>Audio</strong> – sound files in WAV, AIFF, MP3, AAC, FLAC, or OGG format. WAV is recommended for uncompressed quality. Audio assets display sample rate, bit depth, and channel count in their properties.</p>\n\n<h3>3D Models</h3>\n\n<p><strong>Model</strong> – 3D object files that can be placed on the stage. Models display a 3D bounding box (X × Y × Z) instead of a pixel resolution.</p>\n\n<h3>Compositions</h3>\n\n<p><strong>Composition</strong> – a nested timeline packaged as a reusable asset. Compositions appear in the Assets window as a special folder that contains the video and audio sub-assets it uses. You cannot move assets into or out of a composition folder manually — its contents are managed by the system.</p>\n\n<h3>Fonts</h3>\n\n<p><strong>Font</strong> – font files used by SVG text shapes. Fonts are added as assets and then referenced by text shapes via the font selector in the Shape Properties panel. Font assets show a thumbnail preview of the typeface.</p>\n\n<h3>Display Data</h3>\n\n<p><strong>Display Data</strong> – projection mapping data files (such as MPCDI files) that define display geometry for warped or blended projections. Display data assets show MPCDI version and canvas size information in their properties.</p>\n\n<h3>Art-Net Assets</h3>\n\n<p><strong>Art-Net Fixture</strong> – a fixture definition created from a built-in preset. Art-Net fixtures are used with the Art-Net input system for DMX-based control of show parameters.</p>\n\n<p><strong>Art-Net Recording</strong> – a captured recording of Art-Net data for playback on the timeline.</p>\n\n<h3>EDID</h3>\n\n<p><strong>EDID</strong> – captured EDID data from a display device. You can save an EDID snapshot from a connected display through the Network window.</p>\n\n<h3>Folders</h3>\n\n<p><strong>Folder</strong> – a user-created container for organizing assets. Folders can be nested and support drag-and-drop reordering. Some folder types are special:</p>\n\n<ul>\n<li><strong>Regular folders</strong> – created by the user to organize assets freely.</li>\n<li><strong>Composition folders</strong> – system-managed containers whose contents cannot be modified by the user.</li>\n<li><strong>Dynamic asset folders</strong> – auto-updating containers that hold multiple versions of the same asset (see [Dynamic Assets](../06-dynamic-assets)).</li>\n\n</ul>\n<h3>Type Filtering</h3>\n\n<p>The Assets window search panel includes a type filter dropdown with the following categories:</p>\n\n<ul>\n<li><strong>All</strong> – show every asset.</li>\n<li><strong>Video</strong> – video files and image sequences.</li>\n<li><strong>Image</strong> – still images and SVGs.</li>\n<li><strong>Audio</strong> – sound files.</li>\n<li><strong>Model</strong> – 3D model files.</li>\n<li><strong>Other</strong> – any asset that doesn't fall into the above categories (fonts, display data, Art-Net fixtures, etc.).</li>\n<li><strong>Failed</strong> – assets that encountered an error during optimization.</li>\n<li><strong>Used</strong> – assets referenced by at least one cue on the timeline.</li>\n<li><strong>Unused</strong> – assets not referenced by any cue.</li>\n\n</ul>",
      "Asset Properties": "<h2>Asset Properties</h2>\n\n<p>Select one or more assets in the Assets window to view their properties in the Properties panel. Double-click an asset or press <strong>Enter</strong> to focus the Properties panel directly.</p>\n\n<p>The Properties panel adapts to the asset type, showing only the fields relevant to the selected asset.</p>\n\n<h3>General Information</h3>\n\n<p>All assets display the following read-only fields in the Info section:</p>\n\n<ul>\n<li><strong>Name</strong> – the display name. Click the name field to rename the asset (editable unless the asset is in an error state).</li>\n<li><strong>Type</strong> – the asset kind (Video, Image, Audio, SVG, Composition, etc.).</li>\n<li><strong>UUID</strong> – the unique identifier assigned to the asset.</li>\n<li><strong>Original Path</strong> – the original file location from which the asset was imported.</li>\n\n</ul>\n<h3>Visual Asset Properties</h3>\n\n<p>For image and video assets, the following additional fields appear:</p>\n\n<ul>\n<li><strong>Codec</strong> – the optimized codec (if different from the original, both are shown, e.g. \"H.264 → HAP\").</li>\n<li><strong>Color Space</strong> – the color standard and transfer function. If the input and output differ, both are displayed with an arrow (e.g. \"sRGB → Rec. 709\"). Recognized standards include Rec. 709, Rec. 2020, Rec. 2100 PQ, Rec. 2100 HLG, and sRGB.</li>\n<li><strong>Dimensions</strong> – width × height in pixels for 2D assets, or X × Y × Z bounding box for 3D models.</li>\n<li><strong>Bitrate</strong> – the video bitrate (video assets only).</li>\n<li><strong>Compression Ratio</strong> – the ratio between uncompressed and compressed file size (video and image assets).</li>\n\n</ul>\n<h3>Video-Specific Properties</h3>\n\n<ul>\n<li><strong>Frame Rate</strong> – displayed in frames per second. Fractional rates (e.g. 29.97) are shown with two decimal places.</li>\n<li><strong>Duration</strong> – total playback length, formatted as HH:MM:SS.ms.</li>\n<li><strong>Progress</strong> – optimization or upload progress percentage (visible only while the asset is being processed).</li>\n\n</ul>\n<h3>Audio-Specific Properties</h3>\n\n<ul>\n<li><strong>Channels</strong> – the number of audio channels (1 = mono, 2 = stereo, etc.).</li>\n<li><strong>Sample Rate</strong> – displayed in kHz (e.g. 48 kHz).</li>\n<li><strong>Duration</strong> – total playback length.</li>\n\n</ul>\n<h3>Display Data Properties</h3>\n\n<p>For MPCDI display data assets:</p>\n\n<ul>\n<li><strong>Version</strong> – the MPCDI file version.</li>\n<li><strong>Canvases Size</strong> – the total canvas dimensions.</li>\n\n</ul>\n<h3>Dynamic Asset Properties</h3>\n\n<p>When a dynamic (auto-updating) asset is selected, an additional <strong>Active Version</strong> section appears showing:</p>\n\n<ul>\n<li>The currently active version and its details.</li>\n<li>A version count indicator (e.g. \"2 versions\").</li>\n<li>Controls for managing and switching between versions.</li>\n\n</ul>\nSee [Dynamic Assets](../06-dynamic-assets) for details on version management.\n\n<h3>SVG Shape Properties</h3>\n\n<p>SVG shape assets display a dedicated shape editor instead of the standard property fields. This includes a live preview, geometry controls, fill and stroke colors, and (for text shapes) font and text properties.</p>\n\n<p>See [SVG Shapes](../05-svg-shapes) for full documentation.</p>\n\n<h3>Error Information</h3>\n\n<p>If an asset failed to optimize, the Properties panel displays:</p>\n\n<ul>\n<li><strong>Error</strong> – the error message explaining why optimization failed.</li>\n\n</ul>\nAssets in an error state show their name in red in the Assets window and cannot be renamed or used until the issue is resolved.",
      "Formats & Codecs": "<h2>Formats & Codecs</h2>\n\n<p>Choosing the right source format and optimization codec is crucial for reliable, high-performance playback. This article covers the formats WATCHOUT supports and how the optimizer converts them.</p>\n\n<h3>Video Codecs</h3>\n\n<p>Source video files can use any of the following codecs. During optimization, the Asset Manager transcodes them to the configured output codec.</p>\n\n<p><strong>GPU-decoded (recommended)</strong></p>\n\n<ul>\n<li><strong>HAP</strong> – GPU-decoded, excellent performance, large files. Recommended for most content.</li>\n<li><strong>HAP Alpha</strong> – HAP with an alpha channel for transparent video.</li>\n<li><strong>HAP Q</strong> – higher visual quality than standard HAP, with larger file sizes.</li>\n\n</ul>\n<strong>CPU-decoded</strong>\n\n<ul>\n<li><strong>ProRes 422</strong> – high-quality intermediate codec from Apple.</li>\n<li><strong>ProRes 4444</strong> – ProRes with alpha channel support.</li>\n<li><strong>DNxHR</strong> – Avid's high-resolution codec.</li>\n<li><strong>H.264</strong> – widely compatible, smaller file sizes, higher CPU load.</li>\n<li><strong>HEVC / H.265</strong> – improved compression over H.264, higher CPU load.</li>\n<li><strong>NotchLC</strong> – optimized for real-time graphics from Notch.</li>\n\n</ul>\n<h3>Why HAP is Recommended</h3>\n\n<p>HAP is the default optimization target because it decodes entirely on the GPU:</p>\n\n<ul>\n<li><strong>Minimal CPU usage</strong> – leaves the CPU free for effects, compositing, and control tasks.</li>\n<li><strong>Instant scrubbing</strong> – every frame can be accessed independently, so timeline navigation is smooth.</li>\n<li><strong>High frame rates</strong> – easily handles 60 fps and beyond.</li>\n<li><strong>Large resolutions</strong> – supports 4K, 8K, and higher without CPU bottlenecks.</li>\n\n</ul>\nThe trade-off is larger file sizes and higher storage bandwidth requirements compared to CPU-decoded codecs.\n\n<h3>Container Formats</h3>\n\n<p>WATCHOUT supports the following video container formats:</p>\n\n<ul>\n<li><strong>.mov</strong> – QuickTime; commonly used with HAP, ProRes, and H.264.</li>\n<li><strong>.mp4</strong> – MPEG-4 Part 14; commonly used with H.264 and HEVC.</li>\n<li><strong>.avi</strong> – legacy container; sometimes used with HAP.</li>\n<li><strong>.mkv</strong> – Matroska; supports a wide range of codecs.</li>\n\n</ul>\n<h3>Image Formats</h3>\n\n<ul>\n<li><strong>JPEG</strong> – lossy compression, no transparency. Best for photos and backgrounds.</li>\n<li><strong>PNG</strong> – lossless with 8-bit alpha. Best for graphics, logos, and overlays.</li>\n<li><strong>TIFF</strong> – lossless, supports alpha. High-quality archival images.</li>\n<li><strong>TGA</strong> – legacy format with alpha support.</li>\n<li><strong>BMP</strong> – uncompressed bitmap.</li>\n<li><strong>EXR</strong> – 32-bit floating point with HDR support. Best for high-precision and HDR content.</li>\n<li><strong>PSD</strong> – imported as a flattened image.</li>\n\n</ul>\n<h3>Audio Formats</h3>\n\n<ul>\n<li><strong>WAV</strong> – uncompressed PCM. Recommended for best quality and lowest latency.</li>\n<li><strong>AIFF</strong> – uncompressed audio, similar to WAV.</li>\n<li><strong>MP3</strong> – lossy compression, widely compatible.</li>\n<li><strong>AAC</strong> – lossy compression, higher quality than MP3 at similar bitrates.</li>\n<li><strong>FLAC</strong> – lossless compression.</li>\n<li><strong>OGG</strong> – open-source lossy compression.</li>\n\n</ul>\n<h3>The Optimization Pipeline</h3>\n\n<p>When a source file is added, the Asset Manager processes it through the optimizer:</p>\n\n<ol>\n<li><strong>Upload</strong> – the source file is copied to the Asset Manager's storage.</li>\n<li><strong>Optimize</strong> – the file is transcoded to the configured output codec and quality settings.</li>\n<li><strong>Store</strong> – both the original and the optimized version are retained.</li>\n<li><strong>Distribute</strong> – the optimized file is transferred to display servers when the show goes online.</li>\n\n</ol>\nThe optimizer uses the codec mapping to decide which output codec to use for each input codec (see [Import, Export, and Mapping](../12-import-export-and-mapping)).\n\n<h3>Track Management</h3>\n\n<p>For source files that contain both video and audio tracks, the optimizer offers four track management modes:</p>\n\n<ul>\n<li><strong>Skip Audio</strong> – optimize only the video track; discard audio.</li>\n<li><strong>Skip Video</strong> – optimize only the audio track; discard video.</li>\n<li><strong>Composition</strong> – keep both tracks together as a single composition asset.</li>\n<li><strong>Individual Assets</strong> – split video and audio into separate assets.</li>\n\n</ul>\n<h3>Quality Levels</h3>\n\n<p>For codecs that support quality settings, the optimizer provides five levels:</p>\n\n<ol>\n<li><strong>Good</strong> – smallest file size, lower visual quality.</li>\n<li><strong>Very Good</strong> – balanced.</li>\n<li><strong>Excellent</strong> – higher quality, larger files.</li>\n<li><strong>Optimal</strong> – near-maximum quality.</li>\n<li><strong>Best</strong> – maximum quality, largest files.</li>\n\n</ol>\n<h3>Bandwidth Limit</h3>\n\n<p>The Asset Manager Settings dialog includes a <strong>Bandwidth Limit</strong> setting (in Mbit/s) that caps the data rate used when transferring assets to display servers. Set to <strong>0</strong> for unlimited bandwidth.</p>",
      "SVG Shapes": "<h2>SVG Shapes</h2>\n\n<p>WATCHOUT 7 includes a built-in SVG shape editor that lets you create vector-based assets — rectangles, ellipses, and text — directly within the application. These shapes are stored as SVG data and rendered to pixels at a configurable resolution, so they remain crisp at any size.</p>\n\n<h3>Why Use Shapes?</h3>\n\n<p>Shapes are useful for:</p>\n\n<ul>\n<li><strong>Title cards and labels</strong> — create text overlays without leaving WATCHOUT.</li>\n<li><strong>Solid backgrounds</strong> — colored rectangles to place behind content or fill gaps.</li>\n<li><strong>Geometric overlays</strong> — circles, rectangles, and stroked outlines for visual accents.</li>\n<li><strong>Dynamic text</strong> — text content that can be changed during a show (when combined with expressions).</li>\n\n</ul>\nBecause shapes are generated internally, there is no need to round-trip through an external graphics editor for simple visual elements.\n\n<h3>Creating a Shape</h3>\n\n<ol>\n<li>Right-click in the Assets window.</li>\n<li>Choose <strong>New</strong> and select one of:</li>\n</ol>\n<ul>\n<li><strong>New Rectangle Shape</strong></li>\n<li><strong>New Ellipse Shape</strong></li>\n<li><strong>New Text Shape</strong></li>\n</ul>\n<ol>\n<li>Enter a name for the shape asset and click <strong>OK</strong>.</li>\n\n</ol>\n<!-- screenshot: New Shape dialog showing name field and OK/Cancel buttons -->\n\n<p>The new shape asset appears in the Assets window with a default white fill and a canvas size of 1920 × 1080 pixels. You can also create shapes inside folders — if a folder is selected when you create the shape, it is placed in that folder.</p>\n\n<p>> <strong>Note:</strong> Shapes cannot be created inside composition folders or non-visual dynamic asset folders.</p>\n\n<h3>Shape Properties Panel</h3>\n\n<p>Select a shape asset to view its dedicated properties panel. Unlike other asset types, shapes display an interactive editor rather than the standard property fields.</p>\n\n<p><!-- screenshot: Shape Properties panel showing preview, base size, geometry, and color sections --></p>\n\n<h4>Preview</h4>\n\n<p>The top section shows a <strong>live preview</strong> of the shape on a checkerboard background (indicating transparency). The preview updates in real time as you modify properties. When multiple shapes are selected with different values, the preview displays a \"Multiple values\" message.</p>\n\n<h4>Base Size</h4>\n\n<p>The <strong>Base Size</strong> section controls the canvas dimensions:</p>\n\n<ul>\n<li><strong>Width</strong> and <strong>Height</strong> — the SVG canvas size in pixels. Must be positive integers.</li>\n<li>The total pixel area must not exceed approximately 16K (3840 × 2160 × 8 pixels). This prevents creation of shapes that would consume excessive GPU memory.</li>\n\n</ul>\nFor text shapes, a <strong>Crop to Fit</strong> button appears that automatically adjusts the canvas size to tightly fit the rendered text.\n\n<h4>Geometry</h4>\n\n<p>The <strong>Geometry</strong> section lets you switch between shape types and set visual properties:</p>\n\n<ul>\n<li><strong>Kind</strong> — toggle between <strong>Ellipse</strong>, <strong>Rectangle</strong>, and <strong>Text</strong>. Switching the kind preserves the canvas size and colors, but resets type-specific properties.</li>\n<li><strong>Fill</strong> — the fill color, including alpha (transparency). Click to open a color picker with a spectrum view.</li>\n<li><strong>Stroke</strong> — the stroke (outline) color, also with alpha support.</li>\n<li><strong>Stroke Width</strong> — the thickness of the stroke in pixels. Set to 0 for no stroke.</li>\n\n</ul>\nBoth fill and stroke show a reset button when their value differs from the original, allowing you to quickly revert individual properties.\n\n<h4>Text Properties</h4>\n\n<p>When the geometry kind is set to <strong>Text</strong>, an additional section appears:</p>\n\n<ul>\n<li><strong>Text</strong> — a multiline text field for the content to render.</li>\n<li><strong>Alignment</strong> — left, center, or right alignment buttons.</li>\n<li><strong>Line Height</strong> — the spacing multiplier between lines (e.g. 1.0 = normal, 1.5 = 150%).</li>\n<li><strong>Font Size</strong> — the size of the text in pixels.</li>\n<li><strong>Fit Text</strong> — a button that automatically calculates the largest font size that fits the current canvas dimensions.</li>\n<li><strong>Font</strong> — a dropdown listing all available font assets in the show. Each option shows a thumbnail preview of the typeface.</li>\n\n</ul>\n<!-- screenshot: Text shape properties showing text field, alignment buttons, font size, and font dropdown -->\n\n<p>> <strong>Tip:</strong> To use a custom font, first add the font file as an asset in the Assets window. It will then appear in the font dropdown.</p>\n\n<h4>Applying Changes</h4>\n\n<p>Shape property changes are <strong>not</strong> applied automatically. After making edits, click the <strong>Apply Changes</strong> button at the bottom of the properties panel to commit the new shape data. This regenerates the SVG and updates all cues referencing the shape.</p>\n\n<h3>SVG Render Resolution</h3>\n\n<p>When an SVG shape is placed on the timeline as a cue, you can override its render resolution on a per-cue basis. This is configured in the cue's properties:</p>\n\n<ul>\n<li><strong>Width</strong> and <strong>Height</strong> — the rasterization resolution. By default, this matches the shape's base size.</li>\n<li><strong>Lock Aspect Ratio</strong> — keeps the width-to-height ratio constant when adjusting one dimension.</li>\n<li><strong>Reset</strong> — reverts the render resolution to the shape's base size.</li>\n\n</ul>\nIncreasing the render resolution produces sharper output when the cue is scaled up on stage, at the cost of more GPU memory.\n\n<h3>Importing External SVGs</h3>\n\n<p>In addition to creating shapes internally, you can import <code>.svg</code> files as assets by dragging them into the Assets window. Imported SVGs are treated as SVG-type assets and can be placed on the timeline like any other media.</p>\n\n<p>If an imported SVG references fonts, you may need to add matching font assets to the show and map them in the font selector.</p>\n\n<h3>Using Shapes on the Timeline</h3>\n\n<p>Shape assets work like any other visual asset:</p>\n\n<ol>\n<li>Drag the shape from the Assets window onto a timeline layer.</li>\n<li>A media cue is created with the shape as its source.</li>\n<li>Apply position, scale, opacity, and other tweens as usual.</li>\n<li>If the shape content changes (e.g. text is updated), all cues referencing it are updated the next time the shape is applied.</li>\n\n</ol>",
      "Dynamic Assets": "<h2>Dynamic Assets</h2>\n\n<p>A dynamic asset is a named container that holds one or more versions of the same content. Timeline cues reference the dynamic asset by name, and the currently active version determines which actual media file plays. This lets you swap content — different language tracks, updated sponsor logos, seasonal variations — without editing any timelines.</p>\n\n<h3>How It Works</h3>\n\n<p>A dynamic asset appears in the Assets window as a special folder (marked with a recycle icon) containing its version assets. The most recently added version is treated as the <strong>active version</strong> by default. When a cue plays the dynamic asset, the runner loads the active version's media.</p>\n\n<p>If you update the active version — by adding a new file or changing the selection — every cue referencing that dynamic asset picks up the change immediately.</p>\n\n<h3>Categories</h3>\n\n<p>When creating a dynamic asset, you choose a <strong>category</strong> that determines what type of content it holds:</p>\n\n<ul>\n<li><strong>Visual</strong> — images, video, and SVG content.</li>\n<li><strong>Audible</strong> — audio content.</li>\n<li><strong>Display Data</strong> — projection mapping data (MPCDI, etc.).</li>\n\n</ul>\nThe category is shown as a suffix in the asset name (e.g. \"MyContent (Visual)\") and restricts which file types can be added as versions. A visual dynamic asset cannot hold audio files, and vice versa.\n\n<h3>Creating a Dynamic Asset</h3>\n\n<p>There are two ways to create a dynamic asset:</p>\n\n<p><strong>From scratch:</strong></p>\n\n<ol>\n<li>Right-click in the Assets window.</li>\n<li>Choose <strong>New → Create Dynamic Asset</strong>.</li>\n<li>Enter a name and select a category (Visual, Audible, or Display Data).</li>\n<li>Click <strong>Save</strong>.</li>\n\n</ol>\n<!-- screenshot: New Dynamic Asset dialog showing name field and category dropdown -->\n\n<p>An empty dynamic asset folder is created. You can then add versions to it.</p>\n\n<p><strong>From an existing asset:</strong></p>\n\n<ol>\n<li>Select an existing asset (not a folder) in the Assets window.</li>\n<li>Right-click and choose <strong>New → Create Dynamic Asset</strong>.</li>\n<li>The existing asset is converted into the first version of a new dynamic asset. The asset's type determines the category automatically.</li>\n\n</ol>\n> <strong>Tip:</strong> Converting an existing asset preserves all cue references. Cues that pointed to the original asset now point to the dynamic asset, which contains the original file as its first version.\n\n<h3>Adding Versions</h3>\n\n<p>To add a new version to an existing dynamic asset:</p>\n\n<ul>\n<li><strong>Drag and drop</strong> — drag a file from your file manager onto the dynamic asset folder.</li>\n<li><strong>Create Version</strong> — select the dynamic asset or one of its versions, right-click, and choose <strong>New → Create Version</strong>. This opens a dialog where you can set the version name, frame rate (for video), and color space.</li>\n<li><strong>Move into folder</strong> — drag an existing asset into the dynamic asset folder. Because versions must be cloned (not moved) into a dynamic asset, WATCHOUT creates a copy automatically.</li>\n\n</ul>\nVersions within a dynamic asset are sorted by creation date, newest first. The newest version is the active version.\n\n<h3>Version Limits</h3>\n\n<p>Dynamic assets have a maximum revision count of <strong>2</strong> by default. When a new version is added and the limit is exceeded, the oldest version is automatically removed. This keeps the asset folder from growing unbounded during automated update workflows.</p>\n\n<h3>Managing Versions</h3>\n\n<ul>\n<li><strong>Deleting a version</strong> — select the version inside the dynamic asset folder and delete it. If the dynamic asset is used on the timeline, at least one version must remain — WATCHOUT prevents you from deleting the last version of a used dynamic asset.</li>\n<li><strong>The active version</strong> — is always the newest version (by creation time). You can remove newer versions to effectively revert to an older one.</li>\n\n</ul>\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Multi-language shows</strong> — create a visual dynamic asset for each content piece, with one version per language. Swap the language set by replacing the active versions.</li>\n<li><strong>Sponsor updates</strong> — replace sponsor logos without re-editing timelines. Drop a new logo file into the dynamic asset; it becomes the active version.</li>\n<li><strong>Content rotation</strong> — automatically cycle content on a schedule by updating the dynamic asset versions through the Asset Watcher or Web UI.</li>\n<li><strong>A/B testing</strong> — keep two content variations as versions and switch between them during rehearsals.</li>\n\n</ul>\n<h3>Limitations</h3>\n\n<ul>\n<li><strong>Version assets cannot be placed on the timeline directly.</strong> Always use the parent dynamic asset when creating cues. Individual version files are internal to the dynamic asset.</li>\n<li><strong>Category is fixed at creation.</strong> You cannot change a visual dynamic asset to an audible one after creation.</li>\n<li><strong>Folders and compositions cannot be converted</strong> to dynamic assets. Only regular media assets support conversion.</li>\n\n</ul>",
      "Image Sequences": "<h2>Image Sequences</h2>\n\n<p>An image sequence is a series of numbered image files — for example, <code>render_0001.png</code>, <code>render_0002.png</code>, <code>render_0003.png</code> — that WATCHOUT treats as a single video-like asset. Each file represents one frame.</p>\n\n<h3>When to Use Image Sequences</h3>\n\n<p>Image sequences are the preferred delivery format when:</p>\n\n<ul>\n<li><strong>3D rendering</strong> — most render engines (Cinema 4D, Blender, After Effects, etc.) output numbered frames. Importing them directly avoids a separate encoding step.</li>\n<li><strong>HDR workflows</strong> — EXR sequences carry 32-bit floating point data per channel, preserving the full dynamic range from your render pipeline.</li>\n<li><strong>Per-frame quality</strong> — each frame is stored independently, avoiding inter-frame compression artifacts that can appear in highly compressed video codecs.</li>\n<li><strong>Interrupted renders</strong> — if a render crashes, you keep all completed frames. With video encoding, a crash may corrupt the entire file.</li>\n\n</ul>\n<h3>Supported Frame Formats</h3>\n\n<ul>\n<li><strong>JPEG</strong> — lossy, no alpha. Good for photographic content where file size matters.</li>\n<li><strong>PNG</strong> — lossless with alpha support. Best for graphics and rendered content.</li>\n<li><strong>TGA</strong> — lossless with alpha. Legacy format, still common in some pipelines.</li>\n<li><strong>TIFF</strong> — lossless, optional alpha. High-quality archival option.</li>\n<li><strong>EXR</strong> — 32-bit float with HDR support. Recommended for HDR and high-precision color workflows.</li>\n\n</ul>\n<h3>Adding an Image Sequence</h3>\n\n<ol>\n<li>Right-click in the Assets window and choose <strong>New → Add Image Sequence</strong>.</li>\n<li>A folder browser opens. Select the <strong>folder</strong> containing the numbered image files.</li>\n<li>The Asset Manager scans the folder, detects the numbering pattern, and creates a single asset representing the entire sequence.</li>\n\n</ol>\n<!-- screenshot: Add Image Sequence folder browser dialog -->\n\n<p>The resulting asset appears in the Assets window with a video-style icon. Its duration is determined by the number of frames and the configured frame rate.</p>\n\n<p>> <strong>Tip:</strong> Ensure your image files use a consistent numbering scheme with leading zeros (e.g. <code>frame_0001.png</code> through <code>frame_2400.png</code>). The Asset Manager relies on the numbering pattern to determine frame order.</p>\n\n<h3>Frame Rate</h3>\n\n<p>The playback speed of an image sequence is determined by the asset's frame rate setting. You can set or change the frame rate when creating a version of the asset (via the <strong>Create Version</strong> dialog), or it may inherit the show's default frame rate.</p>\n\n<p>For example, a 1200-frame sequence at 30 fps produces a 40-second asset.</p>\n\n<h3>Optimization</h3>\n\n<p>When an image sequence is added, the Asset Manager processes it through the same optimization pipeline as video files:</p>\n\n<ol>\n<li>The individual frames are read in sequence order.</li>\n<li>They are encoded into the configured output codec (typically HAP).</li>\n<li>The result is a single optimized video file that display servers can play back efficiently.</li>\n\n</ol>\nThis means that even though you import individual frames, the display servers receive a standard optimized video — they do not need to read thousands of individual image files during playback.\n\n<p>> <strong>Note:</strong> Image sequences receive a higher optimization priority than standalone video files to ensure they are processed promptly, since the source data (many small files) is less efficient to stream directly.</p>\n\n<h3>Playback Behavior</h3>\n\n<p>Once imported and optimized, an image sequence behaves identically to a video asset:</p>\n\n<ul>\n<li>Place it on the timeline by dragging from the Assets window.</li>\n<li>Set <strong>in/out points</strong>, <strong>loop mode</strong>, and <strong>duration</strong> in the cue properties.</li>\n<li>Apply effects, tweens, and transitions as with any video cue.</li>\n\n</ul>\n<h3>Performance Considerations</h3>\n\n<p>Image sequences can be very large — a 4K EXR sequence at 60 fps can easily produce hundreds of gigabytes of source data. Keep in mind:</p>\n\n<ul>\n<li><strong>Storage</strong> — the source images require significant disk space during import and optimization. The optimized output is typically much smaller (especially when using HAP).</li>\n<li><strong>Optimization time</strong> — encoding thousands of frames takes longer than re-encoding a single video file. Plan for longer optimization times with large sequences.</li>\n<li><strong>When to prefer video</strong> — if you don't need per-frame precision or HDR, it's more efficient to encode to ProRes or HAP in your compositing tool and import the resulting video file directly. This skips the sequence import step entirely.</li>\n\n</ul>",
      "Web User Interface": "<h2>Web User Interface</h2>\n\n<p>The Asset Manager includes a built-in web server that provides a browser-based interface for uploading and managing assets. This allows team members to contribute media from any device on the network without needing the WATCHOUT Producer application.</p>\n\n<h3>Accessing the Web UI</h3>\n\n<ol>\n<li>Ensure the Asset Manager node is running and connected.</li>\n<li>Open a web browser on any device on the same network.</li>\n<li>Navigate to <code>http://<asset-manager-ip>:3023</code>.</li>\n\n</ol>\nThe web interface loads automatically. You can also open it from the Producer by right-clicking in the Assets window and choosing <strong>Asset Web</strong> — this opens your default browser and navigates to the correct address.\n\n<p><!-- screenshot: Web UI landing page showing asset browser and upload area --></p>\n\n<p>> <strong>Note:</strong> The port is <strong>3023</strong> and is fixed. The URL uses the IP address of the node designated as the Asset Manager, not necessarily the Producer machine.</p>\n\n<h3>Features</h3>\n\n<p>The web interface provides:</p>\n\n<ul>\n<li><strong>Upload files</strong> – drag and drop files or use the file browser to upload media. Multiple files can be uploaded simultaneously.</li>\n<li><strong>Browse assets</strong> – view all assets in the current show in a folder tree.</li>\n<li><strong>Create folders</strong> – organize assets into folders.</li>\n<li><strong>Preview media</strong> – view thumbnails for images, video, SVGs, and fonts.</li>\n<li><strong>Monitor status</strong> – check optimization progress and asset states.</li>\n<li><strong>Delete assets</strong> – remove unwanted media.</li>\n\n</ul>\nUploaded files are processed through the same optimization pipeline as files added from the Producer — they appear in the Assets window and are optimized and distributed to display servers automatically.\n\n<h3>Upload Progress</h3>\n\n<p>Large files display upload progress in the web interface. Once the upload completes, optimization begins immediately. The asset appears in the Producer's Assets window as soon as the upload is received.</p>\n\n<h3>Security Considerations</h3>\n\n<p>The web UI has no authentication — it is accessible to anyone who can reach the Asset Manager's IP address and port on the network. For production environments:</p>\n\n<ul>\n<li>Use a <strong>dedicated network</strong> for WATCHOUT systems, separate from general-purpose networks.</li>\n<li>Apply <strong>firewall rules</strong> to restrict access to port 3023 if needed.</li>\n<li>Consider <strong>network segmentation</strong> (VLANs) to isolate the WATCHOUT network.</li>\n\n</ul>\n<h3>Mobile Access</h3>\n\n<p>The web interface is responsive and works on tablets and smartphones, making it convenient for on-the-go asset management during setup and rehearsals.</p>",
      "Asset Watcher": "<h2>Asset Watcher</h2>\n\n<p>The Asset Watcher monitors designated folders on the Asset Manager node’s file system. When new or changed files appear in a watched folder, they are automatically imported into the show and processed through the optimization pipeline.</p>\n\n<h3>Setting Up a Watch Folder</h3>\n\n<p>Watch folders are configured in the Network window, under the Asset Manager node's settings:</p>\n\n<ol>\n<li>In the Network window, locate the node designated as the Asset Manager.</li>\n<li>Click <strong>Add Folder to Watch</strong>.</li>\n<li>In the dialog, configure:</li>\n</ol>\n<ul>\n<li><strong>Folder to Watch</strong> – the path on the Asset Manager’s file system to monitor. Use the file browser or type the path directly.</li>\n<li><strong>Asset Path</strong> – an optional sub-path within the show’s asset tree where imported files should be placed. Leave empty to place them at the root.</li>\n</ul>\n<ol>\n<li>Click <strong>OK</strong> to start watching.</li>\n\n</ol>\n<!-- screenshot: Add Watch Folder dialog showing folder path field and asset path field -->\n\n<p>The folder path is validated before the watcher is created. The system checks that the path exists and is accessible on the Asset Manager node, and that it does not conflict with the Asset Manager’s internal storage directories.</p>\n\n<h3>How It Works</h3>\n\n<p>The Asset Watcher continuously scans the watched folder for changes:</p>\n\n<ol>\n<li><strong>New files</strong> – when a new file appears in the folder, it is automatically imported as an asset. The file is copied into the Asset Manager’s storage and optimization begins.</li>\n<li><strong>Modified files</strong> – if a source file that was previously imported is modified (detected by file system events), the asset is re-imported and re-optimized. The updated content is distributed to display servers.</li>\n<li><strong>Organization</strong> – imported files are placed in the asset path specified when the watch folder was created. If no path was specified, they go to the root of the asset tree.</li>\n\n</ol>\nThe watcher processes files using the same optimization settings (codec mapping, quality, track management) as manually added assets.\n\n<h3>Removing a Watch Folder</h3>\n\n<p>To stop watching a folder, locate it in the Asset Manager node’s settings in the Network window and remove it. Existing assets that were imported from the folder remain in the show.</p>\n\n<h3>Local vs. Remote Configuration</h3>\n\n<p>If the Asset Manager runs on the same machine as the Producer, the folder path is validated as a local disk folder (checking that the directory exists). If the Asset Manager runs on a remote node, the path is validated on that remote machine.</p>\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Collaborative workflows</strong> – content creators drop rendered files into a shared folder. The operator’s show picks them up automatically.</li>\n<li><strong>Live content updates</strong> – update content during a running show by overwriting files in the watched folder. The watcher detects the change and triggers re-optimization.</li>\n<li><strong>Render farm integration</strong> – point the watcher at a render output directory. Completed renders are imported as they finish.</li>\n<li><strong>Dynamic asset updates</strong> – combine the watcher with dynamic assets to automatically rotate content versions. New files dropped into the folder become new versions of the corresponding dynamic asset.</li>\n\n</ul>",
      "Asset Transfer": "<h2>Asset Transfer</h2>\n\n<p>When a show goes online, the Asset Manager distributes optimized assets to every display server (Runner) in the system. WATCHOUT handles this process automatically, but understanding how it works helps you plan for large shows and optimize transfer times.</p>\n\n<h3>Transfer Process</h3>\n\n<p>Asset transfer follows these stages:</p>\n\n<ol>\n<li><strong>Scanning</strong> – the Asset Manager scans the local asset database to determine which files each Runner needs. It compares the local optimized files against what the Runner already has cached.</li>\n<li><strong>Transferring</strong> – new or updated files are sent over the network to each Runner. A progress indicator tracks bytes copied, files copied, and estimated time remaining.</li>\n<li><strong>Success</strong> – when all files have been transferred, the job is marked as complete.</li>\n\n</ol>\nThe transfer system tracks detailed metrics:\n\n<ul>\n<li><strong>Files total / copied / skipped</strong> – total file count, how many were transferred, and how many already existed on the Runner.</li>\n<li><strong>Bytes total / copied / skipped</strong> – the same breakdown by data volume.</li>\n<li><strong>ETA</strong> – after 1 GB of data has been transferred, the system calculates an estimated completion time based on the current transfer rate.</li>\n<li><strong>Errors</strong> – transfer errors are collected and displayed. Up to 100 unique error messages are retained per job.</li>\n\n</ul>\nA transfer can be <strong>cancelled</strong> at any time. Cancelled transfers can be restarted.\n\n<h3>Transfer States</h3>\n\n<p>Each transfer job moves through the following states:</p>\n\n<ul>\n<li><strong>Pending</strong> – the job is queued but has not started.</li>\n<li><strong>Scanning</strong> – the Asset Manager is comparing local and remote assets.</li>\n<li><strong>Transferring</strong> – files are being sent.</li>\n<li><strong>Waiting</strong> – the transfer is paused (e.g. waiting for the Runner to become available).</li>\n<li><strong>Success</strong> – all files transferred successfully.</li>\n<li><strong>Cancelled</strong> – the transfer was stopped by the user.</li>\n\n</ul>\n<h3>Pre-Caching Assets on Runners</h3>\n\n<p>For large shows, you can pre-cache (pre-download) assets onto specific Runners before going fully online:</p>\n\n<ol>\n<li>In the Assets window, select the assets you want to pre-cache.</li>\n<li>Right-click and choose <strong>Transfer Assets → Cache Selected Assets</strong>.</li>\n<li>Select the Runner(s) to cache the assets on.</li>\n<li>Click <strong>OK</strong> to begin the transfer.</li>\n\n</ol>\n<!-- screenshot: Pre-download Runner Assets dialog showing runner selection -->\n\n<p>This is useful when you need to transfer large volumes of media (tens or hundreds of gigabytes) before a show, without waiting for the full online process.</p>\n\n<h3>Optimizing Transfer Speed</h3>\n\n<ul>\n<li><strong>Use high-speed networking</strong> – 1 Gbps minimum, 10 Gbps recommended for large shows.</li>\n<li><strong>Dedicated network</strong> – isolate WATCHOUT traffic from other network data to avoid contention.</li>\n<li><strong>Quality switches</strong> – use managed switches with sufficient backplane bandwidth.</li>\n<li><strong>Bandwidth limit</strong> – the Asset Manager Settings dialog allows you to set a bandwidth limit (in Mbit/s). Set to 0 for unlimited. This is useful when sharing the network with other traffic.</li>\n\n</ul>\n<h3>Managing Disk Space</h3>\n\n<ul>\n<li><strong>Asset Manager cache</strong> – the Asset Manager stores both source and optimized files. The optimized versions can be significantly larger than the source (especially with HAP encoding).</li>\n<li><strong>Runner cache</strong> – each Runner stores optimized assets on its local drive. When a show changes, unused cached files may remain. Consult the WATCHOUT administration guide for cache cleanup procedures.</li>\n<li><strong>Monitoring</strong> – keep an eye on disk space on both the Asset Manager node and each Runner, particularly for shows with many large video assets.</li>\n\n</ul>",
      "Asset Manager Settings": "<h2>Asset Manager Settings</h2>\n\n<p>The Asset Manager Settings dialog controls how assets are optimized, transferred, and managed. Open it by right-clicking in the Assets window and choosing <strong>Asset Manager Settings</strong>.</p>\n\n<p><!-- screenshot: Asset Manager Settings dialog showing all sections --></p>\n\n<h3>Bandwidth Limit</h3>\n\n<p>The <strong>Bandwidth Limit</strong> setting caps the data rate (in Mbit/s) used when transferring optimized assets to display servers.</p>\n\n<ul>\n<li>Set to <strong>0</strong> for unlimited bandwidth (default).</li>\n<li>Set a positive value (e.g. 500) to limit transfers to that rate, useful when sharing the network with other traffic.</li>\n\n</ul>\n<h3>Track Management</h3>\n\n<p>The <strong>Track Management</strong> section controls how the optimizer handles source files that contain both video and audio tracks. The <strong>Composition Logic</strong> dropdown provides four options:</p>\n\n<ul>\n<li><strong>Skip Audio</strong> – only the video track is optimized; audio is discarded.</li>\n<li><strong>Skip Video</strong> – only the audio track is optimized; video is discarded.</li>\n<li><strong>Composition</strong> – both tracks are kept together as a single composition asset.</li>\n<li><strong>Individual Assets</strong> – video and audio are split into separate assets.</li>\n\n</ul>\nThis setting applies globally to all newly imported assets.\n\n<h3>Output Properties</h3>\n\n<p>The <strong>Output Properties</strong> section lists codecs that support quality configuration. For each codec, you can set a <strong>Quality Level</strong>:</p>\n\n<ol>\n<li><strong>Good</strong> – smallest output, lower visual quality.</li>\n<li><strong>Very Good</strong> – balanced.</li>\n<li><strong>Excellent</strong> – higher quality, larger files.</li>\n<li><strong>Optimal</strong> – near-maximum quality.</li>\n<li><strong>Best</strong> – maximum quality, largest files.</li>\n\n</ol>\nNot all codecs expose a quality setting. Codecs that don’t have a configurable quality (e.g. some passthrough formats) appear in the list without a dropdown.\n\n<h3>Codec Mapping</h3>\n\n<p>The <strong>Codecs</strong> section shows the input-to-output codec mapping. Each row maps a source codec (\"in\") to the codec used for the optimized output (\"out\").</p>\n\n<ul>\n<li><strong>Default mapping</strong> – each source codec has a default output target (typically HAP for video).</li>\n<li><strong>Custom mapping</strong> – click the output dropdown to choose a different output codec. Rows with non-default mappings are highlighted with a colored arrow.</li>\n<li><strong>Restore individual row</strong> – hover over the arrow on a non-default row and click the restore icon to revert that row to its default.</li>\n<li><strong>Reset All</strong> – the <strong>Reset All</strong> button at the bottom reverts every row to the default mapping.</li>\n\n</ul>\n> <strong>Tip:</strong> Codec mapping changes take effect for all future optimizations. Assets already optimized are not re-processed unless you manually trigger re-optimization.\n\n<h3>Saving Changes</h3>\n\n<p>Click <strong>Save</strong> to apply the current settings. The <strong>Save</strong> button is only enabled when changes have been made. Click <strong>Cancel</strong> to discard changes and close the dialog.</p>",
      "Import, Export, and Mapping": "<h2>Import, Export, and Mapping</h2>\n\n<p>The Assets window provides workflows for exporting assets to external storage, importing them onto another system, and controlling how the optimizer maps source codecs to output formats.</p>\n\n<h3>Exporting Assets</h3>\n\n<p>Export copies optimized asset files from the Asset Manager to a destination path on any accessible node. Use this to archive a show’s media, transfer it to another system, or prepare a backup.</p>\n\n<p>From the Assets window context menu, choose <strong>Transfer Assets</strong> and then:</p>\n\n<ul>\n<li><strong>Export All</strong> – exports every asset in the show.</li>\n<li><strong>Export Selected</strong> – exports only the currently selected assets.</li>\n\n</ul>\nBoth options open a dialog where you select:\n\n<ol>\n<li><strong>Target node</strong> – the machine to export to (can be the local machine or any connected node).</li>\n<li><strong>Destination path</strong> – the folder on the target node where files will be written.</li>\n\n</ol>\n<!-- screenshot: Export dialog showing node selection and destination path -->\n\n<p>Once started, the export job tracks progress through the standard transfer stages (Scanning → Transferring → Success). You can monitor progress in the Assets window’s activity panel.</p>\n\n<h3>Importing Assets</h3>\n\n<p>Import reads an asset package from a path on a connected node and adds the contents to the current show.</p>\n\n<p>From the Assets context menu, choose <strong>Transfer Assets → Import</strong>.</p>\n\n<ol>\n<li><strong>Source node</strong> – the machine where the asset package resides.</li>\n<li><strong>Source path</strong> – the folder containing the exported assets.</li>\n\n</ol>\nThe import process copies files into the Asset Manager’s storage. If the source node is the local machine but the Asset Manager runs on a remote node, WATCHOUT checks that the path is accessible via the remote file access allowlist. If the path is not permitted, a dialog appears explaining how to configure remote access.\n\n<p>> <strong>Tip:</strong> Importing is a copy operation. The source files are not modified or deleted.</p>\n\n<h3>Pre-Caching on Runners</h3>\n\n<p>For shows with large media libraries, you can pre-cache selected assets onto specific Runners without going fully online:</p>\n\n<ol>\n<li>Select the assets to cache.</li>\n<li>Right-click → <strong>Transfer Assets → Cache Selected Assets</strong>.</li>\n<li>Choose one or more Runners.</li>\n<li>Click <strong>OK</strong>.</li>\n\n</ol>\nThis pushes the optimized files to the selected Runners ahead of time, reducing the time needed when the show goes online.\n\n<h3>Codec Settings (Optimizer Mapping)</h3>\n\n<p>The <strong>Asset Manager Settings</strong> dialog (accessible from the Assets context menu) includes the codec mapping section. This controls how the optimizer converts source codecs to output formats.</p>\n\n<p>Each row in the mapping table shows:</p>\n\n<ul>\n<li><strong>In</strong> – the source codec detected in the imported file.</li>\n<li><strong>Out</strong> – the output codec the optimizer will produce.</li>\n<li><strong>Default</strong> – the system’s recommended output for that source.</li>\n\n</ul>\nYou can override individual mappings by changing the output dropdown. Non-default mappings are highlighted. Use the <strong>Reset All</strong> button to revert all overrides.\n\n<p>For details on quality levels, track management, and bandwidth settings, see [Asset Manager Settings](../11-asset-manager-settings).</p>\n\n<h3>Practical Workflow</h3>\n\n<ol>\n<li><strong>Before migration</strong> – export all assets to a portable drive or network share.</li>\n<li><strong>On the target system</strong> – open the show and import from the export location.</li>\n<li><strong>Verify</strong> – check that all assets appear and are in the correct optimization state.</li>\n<li><strong>Adjust mappings</strong> – if the target system has different hardware capabilities, update codec mappings before re-optimizing.</li>\n<li><strong>Use Find Cues</strong> – before deleting or replacing critical assets, use <strong>Find Cues</strong> to ensure no timeline references will break.</li>\n\n</ol>"
    }
  },
  "6. Timeline and Cues": {
    "overview": "<h1>TIMELINE AND CUES</h1>\n\n<p>The timeline is where your show comes to life. Learn how to arrange media, control timing, and create dynamic presentations.</p>",
    "sections": {
      "Understanding the Timeline": "<h2>Understanding the Timeline</h2>\n\n<p>The Timeline is where show logic is sequenced. Cues on layers define what plays, when it plays, and how it behaves.</p>\n\n<h3>Core Elements</h3>\n\n<ul>\n<li><strong>Time ruler</strong>: visual time scale for navigation and placement</li>\n<li><strong>Play cursor</strong>: current playback/jump position</li>\n<li><strong>Layers</strong>: stacking order for visual priority</li>\n<li><strong>Cues</strong>: media or control objects with start and duration</li>\n<li><strong>Zoom and scroll</strong>: precision editing across long timelines</li>\n\n</ul>\n<h3>Cue Sequences</h3>\n\n<p>A timeline can represent:</p>\n\n<ul>\n<li>A normal timeline</li>\n<li>A composition timeline</li>\n\n</ul>\nBoth use the same editing concepts, but compositions are often used as grouped reusable structures.\n\n<h3>Navigation Patterns</h3>\n\n<ul>\n<li>Click the ruler to move time.</li>\n<li>Use arrow-key navigation to step between cues on active layer.</li>\n<li>Use zoom controls (<code>Numpad +</code> / <code>Numpad -</code>) for fine timing edits.</li>\n\n</ul>\n<h3>Selection Context</h3>\n\n<p>The Timeline has context-sensitive behavior:</p>\n\n<ul>\n<li>Timeline context (global operations)</li>\n<li>Cue context (cue edits)</li>\n<li>Layer context (layer properties)</li>\n\n</ul>\nShortcuts and menu actions can change behavior depending on which context is active.",
      "Adding Media Cues": "<h2>Adding Media Cues</h2>\n\n<p>Media cues are created by placing assets on a timeline.</p>\n\n<h3>Add a Cue</h3>\n\n<ol>\n<li>Import media into <strong>Assets</strong>.</li>\n<li>Drag the asset into the Timeline.</li>\n<li>Drop at the desired start time and layer.</li>\n\n</ol>\n<h3>Placement Behavior</h3>\n\n<p>WATCHOUT supports different placement strategies during drag/drop:</p>\n\n<ul>\n<li><strong>Sequence-oriented</strong> placement</li>\n<li><strong>Layer-oriented</strong> placement</li>\n\n</ul>\nUse modifier behavior (such as <code>Ctrl</code> during drag) when you want to force layer-based placement behavior.\n\n<h3>Initial Cue Values</h3>\n\n<p>A newly created media cue usually gets:</p>\n\n<ul>\n<li>Start time from drop position</li>\n<li>Duration from source media (or default behavior)</li>\n<li>Layer assignment from drop target</li>\n\n</ul>\n<h3>Next Steps After Placement</h3>\n\n<ul>\n<li>Move or trim cue timing</li>\n<li>Add tweens for motion/effects</li>\n<li>Set cue routing/output options if needed</li>\n<li>Test by scrubbing and short playback loops</li>\n\n</ul>",
      "Working with Layers": "<h2>Working with Layers</h2>\n\n<p>Layers determine draw order and help organize complex timelines.</p>\n\n<h3>Layer Basics</h3>\n\n<ul>\n<li>Higher layers visually stack above lower layers.</li>\n<li>Layer names should reflect purpose (for example <code>BG</code>, <code>FX</code>, <code>Titles</code>).</li>\n<li>Keep a clean layer structure early to avoid late-stage confusion.</li>\n\n</ul>\n<h3>Layer Operations</h3>\n\n<table>\n<tr><th>Action</th><th>Shortcut</th></tr>\n<tr><td>Insert layer</td><td><code>Ctrl+I</code></td></tr>\n<tr><td>Delete active layer</td><td><code>Ctrl+Delete</code></td></tr>\n<tr><td>Select all cues on active layer</td><td><em>(menu action)</em></td></tr>\n</table>\n\n<p>You can also append layers and reorder them during timeline editing.</p>\n\n<h3>Layer-Focused Workflow</h3>\n\n<ul>\n<li>Use one layer for each functional category when possible.</li>\n<li>Keep control cues separate from media-heavy layers.</li>\n<li>Lock or minimize edits to stable layers during live programming.</li>\n\n</ul>\n<h3>Key-Layer Considerations</h3>\n\n<p>Some workflows use key/fill logic at layer level. Verify cue compatibility before grouping effects across mixed-purpose layers.</p>",
      "Adjusting Timing": "<h2>Adjusting Timing</h2>\n\n<p>Precise timing is central to show quality. WATCHOUT provides direct manipulation and command-based timing edits.</p>\n\n<h3>Common Timing Edits</h3>\n\n<ul>\n<li>Drag cue body to move start time</li>\n<li>Drag cue edges to trim duration</li>\n<li>Use trim commands for exact operations</li>\n\n</ul>\n<h3>Trim and Reset Actions</h3>\n\n<p>Available timeline actions include:</p>\n\n<ul>\n<li><strong>Trim Start</strong></li>\n<li><strong>Trim End</strong></li>\n<li><strong>Reset Duration</strong></li>\n<li><strong>Reset In-Time</strong></li>\n\n</ul>\nThese are useful when cues need to be quickly normalized after rehearsal changes.\n\n<h3>Snapping</h3>\n\n<p>Snapping helps align edits to meaningful points:</p>\n\n<ul>\n<li>Cue start/end points</li>\n<li>Current play cursor</li>\n<li>Nearby timeline structures</li>\n\n</ul>\nToggle snapping with <code>Ctrl+N</code>.\n\n<h3>Navigation-Assisted Timing</h3>\n\n<p>Use keyboard navigation to jump between cues on active layer, then adjust timing without losing selection context.</p>",
      "Control Cues": "<h2>Control Cues</h2>\n\n<p>Control cues affect playback state instead of rendering media.</p>\n\n<h3>Main Control Cue Types</h3>\n\n<ul>\n<li><strong>Play Control Cue</strong>: starts target timeline/composition</li>\n<li><strong>Pause Control Cue</strong>: pauses target timeline/composition</li>\n<li><strong>Output Cue</strong>: sends external output data</li>\n<li><strong>Variable Cue</strong>: automates show variable values</li>\n\n</ul>\n<h3>Creating Control Cues</h3>\n\n<p>Use the Timeline menu or shortcuts:</p>\n\n<ul>\n<li>Add Play Cue: <code>Ctrl+P</code></li>\n<li>Add Pause Cue: <code>Ctrl+Shift+P</code></li>\n\n</ul>\nOutput and variable cues are available from timeline actions and context menus.\n\n<h3>Targeting Behavior</h3>\n\n<p>Control cues can target:</p>\n\n<ul>\n<li>Enclosing timeline</li>\n<li>Explicit include/exclude lists</li>\n<li>Other timelines or all timelines depending on mode</li>\n\n</ul>\nTargeting modes are typically used as:\n\n<ul>\n<li><strong>All</strong>: broad control across active timeline set</li>\n<li><strong>Others</strong>: affect all timelines except the enclosing timeline</li>\n<li><strong>List</strong>: explicit include list (or exclude list depending on mode)</li>\n<li><strong>Enclosing</strong>: local/self timeline control</li>\n\n</ul>\n<h3>Jump Behavior</h3>\n\n<p>Control cues can also define jump behavior:</p>\n\n<ul>\n<li>No jump</li>\n<li>Jump to target time</li>\n<li>Jump to target cue (forward/search variants)</li>\n\n</ul>\nThis is useful for structured branching and operator-assisted recovery paths.\n\n<h3>Variable Cue Note</h3>\n\n<p>Variable cues are part of control-oriented timeline workflows and are covered in detail in [Variables and Variable Cues](09-variables-and-variable-cues.md).</p>\n\n<p>Use clear naming and color coding so operators can identify control intent quickly.</p>",
      "Marker Cues": "<h2>Marker Cues</h2>\n\n<p>Comment cues (marker cues) provide timeline annotations for operators, programmers, and show callers.</p>\n\n<h3>What Comment Cues Are For</h3>\n\n<ul>\n<li>Scene-change notes</li>\n<li>Technical reminders</li>\n<li>Operator prompts</li>\n<li>Countdown/count-up references</li>\n\n</ul>\n<h3>Creating Comment Cues</h3>\n\n<ul>\n<li>Use <strong>Add Comment/Marker Cue</strong> actions</li>\n<li>Shortcut: <code>Ctrl+Enter</code></li>\n\n</ul>\n<h3>Marker Options</h3>\n\n<p>Comment cues can include:</p>\n\n<ul>\n<li>Description text</li>\n<li>Countdown mode</li>\n<li>Count-up mode</li>\n<li>Marker duration settings</li>\n\n</ul>\n<h3>Best Practices</h3>\n\n<ul>\n<li>Keep marker text short and operational.</li>\n<li>Use consistent prefixes (<code>LX</code>, <code>SFX</code>, <code>VFX</code>, <code>GO</code>) when collaborating with show control teams.</li>\n<li>Place markers slightly ahead of critical moments for operator reaction time.</li>\n\n</ul>",
      "Output Cues": "<h2>Output Cues</h2>\n\n<p>Output cues transmit external control data during timeline playback.</p>\n\n<h3>Output Cue Fields</h3>\n\n<p>Typical output cue properties include:</p>\n\n<ul>\n<li><strong>Protocol</strong></li>\n<li><strong>Address</strong></li>\n<li><strong>Port</strong></li>\n<li><strong>Data payload</strong></li>\n\n</ul>\nThese let you trigger external systems in sync with timeline events.\n\n<h3>Typical Use Cases</h3>\n\n<ul>\n<li>Triggering automation systems</li>\n<li>Sending commands to control middleware</li>\n<li>Driving external effects synchronized with visuals</li>\n\n</ul>\n<h3>Reliability Tips</h3>\n\n<ul>\n<li>Keep payloads deterministic and documented.</li>\n<li>Test cue timing with full show playback speed.</li>\n<li>Validate routing on the same network architecture used in production.</li>\n\n</ul>\n<div class='warning-box'><p>If external systems are safety-critical, include operator confirmation and fallback procedures outside timeline automation.\n</p></div>",
      "Variables and Variable Cues": "<h2>Variables and Variable Cues</h2>\n\n<p>WATCHOUT variables let you drive timeline behavior and runtime values with explicit numeric controls.</p>\n\n<h3>Variables Window Workflow</h3>\n\n<p>Open <strong>Window → Variables</strong> to manage show variables.</p>\n\n<p>Core actions:</p>\n\n<ul>\n<li>Add/remove variables</li>\n<li>Edit live values with sliders</li>\n<li>Save current values as new defaults</li>\n\n</ul>\nEach variable can define:\n\n<ul>\n<li>Name</li>\n<li>External key</li>\n<li>Min/max/default value</li>\n<li>Interpolation mode</li>\n\n</ul>\n<h3>Learning External Keys</h3>\n\n<p>Variable properties include a <strong>Learn</strong> mode for capturing an external key assignment.</p>\n\n<p>Typical workflow:</p>\n\n<ol>\n<li>Select a variable.</li>\n<li>Enable <strong>Learn</strong>.</li>\n<li>Send the external control signal.</li>\n<li>Confirm key assignment and disable learning.</li>\n\n</ol>\n<h3>Adding Variable Cues on the Timeline</h3>\n\n<p>Variable automation can be added in timeline context by using variables as drag sources.</p>\n\n<p>Supported interactions:</p>\n\n<ul>\n<li>Drag variables to a layer area to create a <strong>Variable Cue</strong></li>\n<li>Drop variables on an existing cue to add variable-related tween data</li>\n\n</ul>\n<h3>Good Practice</h3>\n\n<ul>\n<li>Keep variable names stable and descriptive.</li>\n<li>Set realistic min/max bounds before building automation.</li>\n<li>Save known-safe defaults before rehearsals and show runs.</li>\n<li>Use marker/comment cues to document operator-sensitive variable changes.</li>\n\n</ul>",
      "ArtNet Fixture Cues": "<h2>ArtNet Fixture Cues</h2>\n\n<p>WATCHOUT includes an ArtNet fixture workflow spanning Assets and Cue Properties.</p>\n\n<h3>Create Fixture Assets</h3>\n\n<p>In the <strong>Assets</strong> window context menu, use <strong>Add ArtNet Fixture...</strong> and choose a preset.</p>\n\n<p>This creates fixture-oriented assets that can be used in timeline cues.</p>\n\n<h3>Add Fixture Cues to a Timeline</h3>\n\n<p>Add the fixture asset to a timeline as a media cue, then open <strong>Cue Properties</strong>.</p>\n\n<p>When a cue is ArtNet-based, a <strong>Fixture</strong> section is available for addressing and mode selection.</p>\n\n<h3>Fixture Address and Mode</h3>\n\n<p>Fixture properties include:</p>\n\n<ul>\n<li>Universe addressing fields (net/sub-net/universe and absolute universe)</li>\n<li>Start channel</li>\n<li>Fixture mode selection (from available fixture modes)</li>\n\n</ul>\nUse consistent addressing conventions across your control/network team to avoid collisions.\n\n<h3>Recording Source and Channel Mapping</h3>\n\n<p>If a fixture cue uses ArtNet recording data, cue properties include mapping tools to route recorded channels to fixture output channels.</p>\n\n<p>Typical operations:</p>\n\n<ul>\n<li>Choose fixture and recording asset versions</li>\n<li>Map recorded channels to fixture channels</li>\n<li>Clear mappings where needed</li>\n<li>Discard recording linkage when reworking the cue</li>\n\n</ul>\n<h3>Operational Tips</h3>\n\n<ol>\n<li>Lock addressing decisions early in rehearsal.</li>\n<li>Version fixture assets deliberately; avoid last-minute mode swaps.</li>\n<li>Validate channel mapping on the real output network before show operation.</li>\n\n</ol>",
      "Compositions": "<h2>Compositions</h2>\n\n<p>Compositions are nested timeline units that allow you to group multiple cues into a single, self-contained entity. A composition appears on its parent timeline as a single media cue, but internally it contains its own layers, cues, and timing — effectively a timeline within a timeline. This makes compositions ideal for creating reusable visual building blocks that can be placed across multiple timelines or repeated at different points in a show.</p>\n\n<h3>What Compositions Are</h3>\n\n<p>A composition is a special cue sequence with its own internal layers and cue arrangement. When you group cues into a composition, WATCHOUT:</p>\n\n<ol>\n<li>Creates a new composition object with its own cue sequence (layers, cues, and duration)</li>\n<li>Removes the original cues from the parent timeline</li>\n<li>Inserts a single <strong>composition cue</strong> in their place — a media cue whose source is the composition rather than an asset file</li>\n\n</ol>\nThe composition cue inherits position and anchor properties from the grouped cues, so it appears in the same location on the Stage. Internally, the composition preserves the relative timing and layer arrangement of its constituent cues.\n\n<p>Compositions also have a <strong>reference frame</strong> that defines their internal coordinate space, and they can optionally be linked to a source asset (for example, when created from a 3D model import).</p>\n\n<h3>Creating a Composition</h3>\n\n<p>To create a composition:</p>\n\n<ol>\n<li>Select one or more cues on the same timeline</li>\n<li>Go to <strong>Timeline → Group Cues into Composition</strong>, or press <strong>Ctrl+G</strong></li>\n\n</ol>\nThe selected cues must all belong to the same timeline. WATCHOUT collects them, determines the required number of layers, creates a new composition named sequentially (e.g. \"Composition 1\", \"Composition 2\"), and replaces the selected cues with a single composition cue at the position of the first selected cue.\n\n<p>The composition cue's duration matches the span of the grouped cues. Its blend mode, tier mask, and other media options are set to defaults (Normal blend, first tier only, no depth check).</p>\n\n<div class='info-box'><p>When importing 3D models, WATCHOUT automatically creates compositions for multi-mesh models — each mesh surface becomes a separate cue inside the composition, allowing independent texturing while keeping the model as a single unit on the timeline.\n</p></div>\n\n<h3>Ungrouping a Composition</h3>\n\n<p>To dissolve a composition back into individual cues:</p>\n\n<ol>\n<li>Select one or more composition cues on the timeline</li>\n<li>Go to <strong>Timeline → Ungroup Cues</strong>, or press <strong>Ctrl+Shift+G</strong></li>\n\n</ol>\nWhen you ungroup, WATCHOUT:\n\n<ul>\n<li>Extracts all cues from the composition's internal cue sequence</li>\n<li>Adjusts their start times relative to the composition cue's position on the parent timeline</li>\n<li>Adjusts their positions based on the composition cue's position and anchor offset</li>\n<li>Creates any additional layers needed on the parent timeline to accommodate the composition's layer structure</li>\n<li>Removes the composition cue from the parent timeline</li>\n\n</ul>\nThe ungrouped cues appear on the parent timeline at the correct times and positions, as if the composition never existed.\n\n<h3>Editing a Composition</h3>\n\n<p>To edit a composition's internal contents without ungrouping it:</p>\n\n<ul>\n<li><strong>From the Cue List</strong>: Right-click a composition cue and select <strong>Open Composition</strong></li>\n<li><strong>From the Timeline</strong>: Double-click the composition cue, or select it and open it via the context menu</li>\n\n</ul>\nWhen you open a composition for editing, a new Timeline window appears showing the composition's internal cue sequence. The Stage window switches to <strong>composition mode</strong>, indicated by a gantt chart icon in the top bar. While in composition mode:\n\n<ul>\n<li>The Stage shows only the cues belonging to the active composition</li>\n<li><strong>Projector mode is not available</strong> — the Stage automatically exits projector mode when a composition is opened</li>\n<li>The Stage switches to cue edit mode (display editing is disabled)</li>\n<li>Cue selections on the Stage are scoped to the composition's cue sequence</li>\n\n</ul>\nTo exit composition mode, activate a regular timeline window. The Stage will return to its normal display.\n\n<h3>Composition Properties</h3>\n\n<p>Compositions have the following properties, visible in the Properties panel:</p>\n\n<ul>\n<li><strong>Name</strong> — a descriptive name for the composition</li>\n<li><strong>Duration</strong> — the internal duration of the composition's cue sequence</li>\n<li><strong>Reference Frame</strong> — the internal coordinate space (x, y, width, height) used for composition layout</li>\n\n</ul>\nThe composition cue on the parent timeline has its own start time and duration, which determines how much of the composition's internal timeline is played.\n\n<h3>Compositions as Reusable Assets</h3>\n\n<p>Compositions appear in the show's asset statistics alongside other asset types (images, video, audio, etc.) under the <strong>Compositions</strong> category. A composition can be used as the media source for cues on any timeline in the show, making it possible to reuse a single composition in multiple places.</p>\n\n<p>When a composition is referenced by cues on different timelines, editing its internal contents affects all instances simultaneously — the composition is a shared resource, not a copy.</p>\n\n<h3>Nesting Compositions</h3>\n\n<p>Compositions can contain other compositions. There is no explicit depth limit on nesting, so you can build layered hierarchies of grouped content. However, deeply nested compositions increase the complexity of the show and can make debugging visual issues more difficult.</p>\n\n<div class='note-box'><p>Composition cues do not support cue set (variant) assignments. If you need variant-based media switching, the individual cues inside the composition should be assigned to cue sets before grouping, or the composition should be ungrouped first.\n</p></div>\n\n<h3>Blind Editing Compositions</h3>\n\n<p>Compositions participate in the blind edit system. When a blind edit is started on a timeline, a temporary composition is created that mirrors the timeline's content. Edits are made to this temporary composition and can be applied (committed) or discarded without affecting the live show. See the [Blind Edit Mode](../06-timeline-and-cues/15-blind-edit-mode) article for details.</p>\n\n<h3>Best Practices</h3>\n\n<p><strong>Group stable, reusable clusters.</strong> Compositions work best for content that is logically self-contained — a lower-third graphic with multiple layers, a multi-mesh 3D model, or a complex animated sequence that appears in several places.</p>\n\n<p><strong>Name compositions descriptively.</strong> Default names like \"Composition 1\" become hard to distinguish in large shows. Rename compositions to reflect their content (e.g. \"Speaker Intro Lower Third\", \"Stage Left Model\").</p>\n\n<p><strong>Avoid excessive regrouping late in production.</strong> Grouping and ungrouping involves restructuring cue positions and layers. Making major composition changes close to showtime increases the risk of unintended visual shifts.</p>\n\n<p><strong>Use compositions for 3D model management.</strong> When working with multi-surface 3D models, compositions keep all mesh cues organized as a single timeline entity while still allowing independent texture assignment per surface.</p>",
      "Cue Sets and Variants": "<h2>Cue Sets and Variants</h2>\n\n<p>Cue Sets allow you to create multiple named <strong>variants</strong> of media content for the same cue, and switch between them at runtime or during show preparation. This is the core mechanism for building shows that need to display different content depending on context — different languages, different clients, day versus night versions, or rehearsal versus performance configurations.</p>\n\n<h3>What Cue Sets Are</h3>\n\n<p>A <strong>Cue Set</strong> is a named group containing one or more <strong>variants</strong>. Each variant is a named slot that can hold a different media source for any cue assigned to that set. When a cue belongs to a cue set, its displayed content is determined by the currently <strong>active variant</strong> of that set rather than by a fixed media source.</p>\n\n<p>For example, a cue set called \"Language\" might have variants named \"English\", \"German\", and \"French\". A title card cue assigned to this set would display different image files depending on which language variant is active.</p>\n\n<p>Every cue set has a <strong>default variant</strong> — the variant that is automatically activated when no other variant has been explicitly selected. The active variant selection is <strong>transient state</strong>, meaning it is not part of the undo/redo history and behaves like a runtime variable.</p>\n\n<h3>The Cue Sets Panel</h3>\n\n<p>The <strong>Cue Sets</strong> window is the central hub for managing cue sets and variants. It displays:</p>\n\n<ul>\n<li>Each cue set as an expandable section with its name</li>\n<li>Variant columns across the top, with the <strong>active</strong> variant highlighted and the <strong>default</strong> variant marked with a star icon</li>\n<li>A table of all cues assigned to each set, showing the timeline name, layer number, start time, and a thumbnail of the assigned asset for each variant</li>\n\n</ul>\nClicking a variant header <strong>activates</strong> that variant, immediately switching all assigned cues to display the media mapped to that variant.\n\n<p>Clicking a cue row navigates to that cue's timeline and scrolls the Timeline window to its position.</p>\n\n<h3>Creating a Cue Set</h3>\n\n<p>To create a new cue set:</p>\n\n<ol>\n<li>Open the <strong>Cue Sets</strong> window</li>\n<li>Click the window menu and select <strong>New Cue Set</strong></li>\n<li>Enter a <strong>group name</strong> (e.g. \"Language\") and a <strong>variant name</strong> for the initial default variant (e.g. \"English\")</li>\n\n</ol>\nThe new set appears in the panel with one variant. You can then add more variants and assign cues to the set.\n\n<h3>Managing Variants</h3>\n\n<p>Right-click a cue set header or a variant column to access variant management options:</p>\n\n<ul>\n<li><strong>New Variant</strong> — adds a new empty variant to the set</li>\n<li><strong>Duplicate Variant</strong> — creates a copy of an existing variant, inheriting all its media mappings across all assigned cues. This is useful for creating a variant that starts as a clone of an existing one and then diverges.</li>\n<li><strong>Rename Variant</strong> — changes the variant's display name</li>\n<li><strong>Set Default Variant</strong> — designates the variant as the default (shown with a star icon). The default variant is used as the initial active variant.</li>\n<li><strong>Delete Variant</strong> — removes the variant. You cannot delete the default variant or the currently active variant.</li>\n\n</ul>\nVariants are displayed sorted alphabetically by name.\n\n<h3>Assigning Cues to Cue Sets</h3>\n\n<p>To assign a cue to a cue set:</p>\n\n<ol>\n<li>Select one or more media cues</li>\n<li>In the <strong>Cue Properties</strong> panel, find the <strong>Cue Set</strong> field</li>\n<li>Select the desired cue set from the dropdown</li>\n\n</ol>\nWhen you assign a cue to a set, WATCHOUT creates a <strong>media mapping</strong> for that cue — an internal lookup table that maps each variant to a media source. Initially, all variants point to the cue's current media source. You can then change individual variant mappings by dragging different assets onto the cue while a specific variant is active.\n\n<p>To remove a cue from a cue set, set the Cue Set field back to <strong>None</strong>.</p>\n\n<div class='warning-box'><p>Art-Net fixture cues cannot be assigned to cue sets. The assignment will be rejected with an error message.\n</p></div>\n\n<h3>Switching the Active Variant</h3>\n\n<p>You can switch the active variant in several ways:</p>\n\n<ul>\n<li><strong>Click the variant header</strong> in the Cue Sets panel to activate it immediately</li>\n<li><strong>Use the HTTP API</strong> to select a variant programmatically at runtime (e.g. from an external control system)</li>\n\n</ul>\nWhen you switch the active variant, all cues assigned to that cue set immediately update their rendered content to display the media source mapped to the new variant. This switch is atomic — all affected cues change simultaneously.\n\n<p>The active variant state is treated as transient data (like show variables), meaning variant switches are not recorded in the undo history.</p>\n\n<h3>Cue Set Column in the Cue List</h3>\n\n<p>The <strong>Cue List</strong> window includes a <strong>Cue Set</strong> column that displays the name of the cue set each cue belongs to. This provides a quick way to identify which cues are variant-controlled. You can also filter the Cue List by cue sets to show only cues belonging to specific sets.</p>\n\n<h3>Interaction with Asset Deletion</h3>\n\n<p>Assets that are referenced by any variant mapping in any cue set <strong>cannot be deleted</strong> from the Asset Manager. WATCHOUT protects against accidental deletion of assets that are in use by the variant system. The deletion dialog will inform you that assets used in cue sets are protected.</p>\n\n<h3>Use Cases</h3>\n\n<p><strong>Multi-language shows:</strong> Create a \"Language\" cue set with variants for each language. Assign all text-bearing cues (title cards, subtitle overlays, informational graphics) to this set. Switch languages with a single variant activation.</p>\n\n<p><strong>Day/night versions:</strong> Create a \"Time of Day\" set with \"Day\" and \"Night\" variants. Map bright, high-contrast assets to the Day variant and darker, muted versions to the Night variant.</p>\n\n<p><strong>Client-specific branding:</strong> For touring productions that rebrand per venue or sponsor, create a \"Branding\" set with variants for each client. Swap logos, color schemes, and sponsor graphics without restructuring the timeline.</p>\n\n<p><strong>Rehearsal vs. performance:</strong> Use a variant to swap placeholder or low-resolution assets during rehearsal with final production assets for the live show.</p>",
      "Media Snapshots": "<h2>Media Snapshots</h2>\n\n<p>Media Snapshots allow you to save the current property state of selected cues as a named preset, and later recall that state to quickly restore or switch between cue configurations. Think of them as \"bookmarks\" for how your cues are set up at a particular moment — you can save multiple snapshots and toggle between them to compare different looks or instantly recall a known-good configuration.</p>\n\n<h3>What Media Snapshots Are</h3>\n\n<p>A media snapshot captures the current property values of one or more selected cues and stores them under a name. When you apply a snapshot, the stored property values are restored to those cues, overriding their current settings. This is different from cue sets (which swap media sources) — media snapshots save and restore the <strong>property state</strong> of cues, including position, effects, timing parameters, and other configured values.</p>\n\n<p>Snapshots are stored as part of the show and persist across save/load cycles.</p>\n\n<h3>Creating a Snapshot</h3>\n\n<p>To create a new media snapshot:</p>\n\n<ol>\n<li>Select one or more cues on the timeline</li>\n<li>Open the <strong>Media Snapshot</strong> menu (accessible from the toolbar or context menu)</li>\n<li>Select <strong>New...</strong> and enter a name for the snapshot</li>\n\n</ol>\nThe snapshot captures the current property values of all selected cues. You must have at least one cue selected to create a snapshot.\n\n<h3>Applying a Snapshot</h3>\n\n<p>To apply a saved snapshot, select it from the <strong>Media Snapshot</strong> menu. The cues that were included in the snapshot will have their properties restored to the values captured when the snapshot was created.</p>\n\n<p>If a snapshot references cues that are no longer present in the show, those entries are skipped.</p>\n\n<h3>Updating a Snapshot</h3>\n\n<p>To update an existing snapshot with the current state of the selected cues:</p>\n\n<ol>\n<li>Select the cues you want to update</li>\n<li>Open the <strong>Media Snapshot</strong> menu</li>\n<li>Select <strong>Update...</strong> and choose the snapshot to overwrite</li>\n\n</ol>\nThe selected snapshot is replaced with the current property values of the selected cues.\n\n<h3>Deleting Snapshots</h3>\n\n<p>From the <strong>Media Snapshot</strong> menu:</p>\n\n<ul>\n<li><strong>Delete</strong> — removes a specific snapshot</li>\n<li><strong>Delete All</strong> — removes all snapshots from the show</li>\n\n</ul>\n<h3>Visual Indicators</h3>\n\n<p>When a media snapshot is applied to a cue, the cue displays a chip or badge indicator showing the snapshot name. If multiple snapshots overlap on the same cue, the indicator reflects all applied snapshots.</p>\n\n<p>The top bar of the interface also shows chip indicators for each currently applied snapshot, providing a global overview of which snapshots are active.</p>\n\n<div class='note-box'><p>If a cue has multiple media snapshots applied, a tooltip on the indicator lists all applied snapshot names.\n</p></div>\n\n<h3>The \"All\" Toggle</h3>\n\n<p>The <strong>All</strong> toggle in the Media Snapshot menu allows you to apply or remove all snapshots at once. This is useful for quickly returning to a clean state or activating a complete set of saved configurations simultaneously.</p>\n\n<h3>Use Cases</h3>\n\n<p><strong>Preset looks for different show segments:</strong> Save a snapshot for the \"opening\" look and another for the \"finale\" look. Switch between them during rehearsal to compare configurations.</p>\n\n<p><strong>Quick reset to a known-good state:</strong> Before experimenting with cue properties, save a snapshot. If the experiment doesn't work out, apply the snapshot to instantly restore the original settings.</p>\n\n<p><strong>A/B comparison:</strong> Save two snapshots with different visual configurations (e.g. different color corrections, positions, or crop settings) and toggle between them to compare the results side by side.</p>\n\n<p><strong>Show calling reference:</strong> Save snapshots at key cue points so that operators can quickly verify or restore the intended look at specific moments during the show.</p>",
      "Stacking Order": "<h2>Stacking Order</h2>\n\n<p>When multiple cues overlap on the same display area, WATCHOUT needs to determine which content appears in front of (on top of) which other content. This is controlled by <strong>stacking order</strong> — a system that operates at both the cue level and the timeline level to give you precise control over visual layering.</p>\n\n<h3>Per-Cue Stacking Mode</h3>\n\n<p>Every media cue has a <strong>Stacking</strong> property in the Cue Properties panel (under the Presentation page) that determines how it composites relative to other cues on the same timeline. There are two modes:</p>\n\n<h4>By Layer</h4>\n\n<p>The default stacking mode. Cues are composited based on their <strong>layer order</strong> within the timeline. Cues on higher-numbered layers (further down in the Timeline window) render behind cues on lower-numbered layers (higher in the Timeline window). The Z position of the cue has no effect on stacking — only the layer arrangement matters.</p>\n\n<p>This is the most predictable mode and is recommended for most 2D content workflows, where you want explicit control over what appears in front of what.</p>\n\n<h4>By Z</h4>\n\n<p>Cues are composited based on their <strong>Z position</strong> value (depth in 3D space). Cues with smaller Z values (closer to the viewer) render in front of cues with larger Z values (further from the viewer). The layer order is ignored for stacking purposes.</p>\n\n<p>This mode is primarily useful for 3D scenes where you want the natural depth ordering of objects to determine visibility, such as projection mapping onto 3D models or scenes with multiple depth planes.</p>\n\n<div class='info-box'><p>You can mix stacking modes within the same timeline. Some cues can use By Layer while others use By Z. Cues using By Z participate in depth testing against each other, while By Layer cues are composited strictly by their layer position.\n</p></div>\n\n<h3>Per-Timeline Stacking Order</h3>\n\n<p>Timelines also have a <strong>Stacking</strong> property (found in the Timeline Properties panel under General) that controls how the timeline's content composites relative to other timelines. There are two options:</p>\n\n<h4>Timeline Order</h4>\n\n<p>The default setting. Timelines render in the order they appear in the <strong>Timelines panel</strong> — timelines listed lower in the panel render on top of timelines listed higher. You can reorder timelines by dragging them in the panel to change their stacking priority.</p>\n\n<p>This means the visual front-to-back order of timelines matches their top-to-bottom order in the panel, with the <strong>bottom-most timeline rendering on top</strong>.</p>\n\n<h4>Always on Top</h4>\n\n<p>A timeline set to <strong>Always on Top</strong> renders above all other timelines that use the default Timeline Order, regardless of its position in the Timelines panel. If multiple timelines are set to Always on Top, they composite among themselves in their panel order.</p>\n\n<p>This is useful for overlay timelines (e.g. a logo or emergency messaging layer) that must always appear in front of all other content.</p>\n\n<h3>Layer Order Within Timelines</h3>\n\n<p>Within a single timeline, the vertical arrangement of layers determines the default rendering priority for cues using the By Layer stacking mode. Layers are numbered starting from the top of the Timeline window:</p>\n\n<ul>\n<li><strong>Layer 1</strong> (topmost) renders <strong>in front of</strong> all other layers</li>\n<li><strong>Layer 2</strong> renders behind Layer 1 but in front of Layer 3</li>\n<li>And so on, with higher-numbered layers rendering further behind</li>\n\n</ul>\nThis ordering is consistent with common compositing conventions — the topmost layer in the timeline view is the frontmost visual layer.\n\n<h3>Cross-Timeline Compositing</h3>\n\n<p>When multiple timelines contribute content to the same display area, the compositing order is:</p>\n\n<ol>\n<li><strong>Always on Top timelines</strong> render last (in front), in their panel order</li>\n<li><strong>Regular timelines</strong> render in their panel order (bottom of panel = front)</li>\n\n</ol>\nWithin each timeline, cues composite according to their per-cue stacking mode (By Layer or By Z). The result of each timeline's internal compositing is then layered according to the timeline stacking order.\n\n<h3>Practical Implications</h3>\n\n<p><strong>Blend modes and transparency.</strong> Stacking order directly affects how blend modes (Add, Multiply, Screen, etc.) interact between overlapping cues. A cue using the Add blend mode on a higher layer adds its pixel values to whatever is rendered on lower layers. Changing the stacking order changes which content is \"below\" the blended cue.</p>\n\n<p><strong>Opacity and fade effects.</strong> When a cue fades to transparent, the content behind it (as determined by stacking order) becomes visible. Incorrect stacking can result in unexpected content showing through during fades.</p>\n\n<p><strong>Performance considerations.</strong> Stacking order affects the rendering pipeline. Cues using By Z stacking require depth buffer operations, which can be slightly more expensive than By Layer compositing. For purely 2D shows, By Layer is the more efficient choice.</p>\n\n<p><strong>Multi-timeline shows.</strong> In complex productions with many overlapping timelines, use the Always on Top setting sparingly for true overlay layers (emergency messages, persistent logos) and rely on panel ordering for the main content timelines.</p>",
      "Timeline Triggers and Expressions": "<h2>Timeline Triggers and Expressions</h2>\n\n<p>Timelines can react automatically to expression-based trigger rules for play, pause, and stop.</p>\n\n<h3>Where to Configure Triggers</h3>\n\n<ol>\n<li>Open the <strong>Timelines</strong> window.</li>\n<li>Select a timeline (or folder context where applicable).</li>\n<li>Open <strong>Properties</strong>.</li>\n<li>Go to the <strong>Triggers</strong> section.</li>\n<li>Edit:</li>\n</ol>\n<ul>\n<li><strong>Play Expression</strong></li>\n<li><strong>Pause Expression</strong></li>\n<li><strong>Stop Expression</strong></li>\n\n</ul>\n<h3>Validation and Hints</h3>\n\n<p>Trigger fields are validated while editing.</p>\n\n<p>The editor also provides expression hints/autocomplete support based on the current token, helping you reference available inputs correctly.</p>\n\n<p>If an expression references unknown inputs, validation will fail until corrected.</p>\n\n<h3>How to Use This in Practice</h3>\n\n<ul>\n<li>Use trigger expressions for predictable state transitions.</li>\n<li>Keep expressions simple and testable.</li>\n<li>Prefer explicit variable names over implicit assumptions.</li>\n<li>Verify trigger behavior in rehearsal with controlled input changes.</li>\n\n</ul>\n<h3>Scope Notes</h3>\n\n<p>Trigger editing is intended for timeline control contexts and is not shown for composition-only contexts.</p>\n\n<p>Treat trigger rules as show logic: version them, review them, and regression-test them after major timeline edits.</p>",
      "Blind Edit Mode": "<h2>Blind Edit Mode</h2>\n\n<p>Blind Edit mode lets you make changes to a timeline's cues and properties <strong>in isolation</strong>, without those changes immediately affecting live playback. All modifications are staged in a temporary working copy and only applied to the live show when you explicitly commit (\"Take\") them. This allows you to prepare, adjust, and verify changes while the current scene continues to play undisturbed.</p>\n\n<h3>How Blind Edit Works</h3>\n\n<p>When you enter Blind Edit on a timeline, WATCHOUT creates a temporary <strong>composition</strong> that is an exact copy of the timeline's current cue sequence (all cues, layers, and duration). A new Timeline window opens for this composition, and the Stage switches to composition mode to display its contents.</p>\n\n<p>You edit the temporary copy freely — adding, removing, or modifying cues, changing tween data, adjusting timing. None of these changes affect the original timeline or the live output until you explicitly apply them.</p>\n\n<p>Only <strong>one blind edit session</strong> can be active at a time across the entire show. If you attempt to start a second blind edit while one is already open, WATCHOUT will prompt you to apply or discard the existing one first.</p>\n\n<h3>Entering Blind Edit Mode</h3>\n\n<p>There are two ways to enter Blind Edit:</p>\n\n<ul>\n<li><strong>From the Timeline window</strong>: Click the blind edit button (eye-off icon) in the toolbar at the top-right of the timeline. If a blind edit already exists for this timeline, clicking the button navigates to the existing blind edit window instead of creating a new one.</li>\n<li><strong>From the Cue List window</strong>: Right-click a cue and select <strong>Blind Edit Timeline</strong> to enter blind edit on that cue's timeline.</li>\n\n</ul>\nThe Timeline window title appends <strong>(Blind Edit)</strong> to indicate you are working on a blind edit copy. The window's title bar changes to a distinct color (a warm highlight) to provide a clear visual cue that you are in blind edit mode.\n\n<h3>The Blind Edit Toolbar</h3>\n\n<p>When a blind edit is active, the Timeline window displays additional controls in the toolbar area:</p>\n\n<h4>Enter/Exit Button</h4>\nThe eye-off icon button on regular timelines starts a blind edit. On a blind edit composition, discarding the blind edit (closing the window) returns you to normal editing.\n\n<h4>Follow</h4>\nThe <strong>link icon</strong> button synchronizes the blind edit's time position with the parent timeline's live playhead. When you click Follow:\n\n<ul>\n<li>If the parent timeline is <strong>running</strong>, the blind edit jumps to the parent's current time and starts running in sync</li>\n<li>If the parent timeline is <strong>paused</strong>, the blind edit pauses and jumps to the parent's current time</li>\n<li>If the parent timeline is <strong>stopped</strong>, the blind edit stops</li>\n\n</ul>\nThis is useful for previewing how your blind edits look at the same point in the show that is currently playing live.\n\n<h4>Take</h4>\nThe <strong>checkmark icon</strong> button applies all staged changes to the original timeline, replacing its cues, layers, and duration with the contents of the blind edit composition. The blind edit is then closed.\n\n<div class='warning-box'><p>If the parent timeline is currently <strong>playing or paused</strong>, WATCHOUT shows a warning dialog: \"Are you sure you want to edit a [playing/paused] Timeline? Applying changes to a [playing/paused] timeline can yield unexpected results.\" You must confirm before the changes are applied.\n</p></div>\n\n<p>The Take button is <strong>disabled</strong> when the parent timeline is locked, preventing accidental modification of locked content.</p>\n\n<h3>Editing While in Blind Edit</h3>\n\n<p>All standard editing operations work within a blind edit session:</p>\n\n<ul>\n<li>Adding, removing, duplicating, and moving cues</li>\n<li>Modifying cue properties (position, duration, media source, etc.)</li>\n<li>Adding and editing tween effects and keyframes</li>\n<li>Adding and removing layers</li>\n<li>Changing the timeline duration</li>\n\n</ul>\nThese changes are captured in the temporary composition and do not affect the live show output until you Take.\n\n<h3>Discarding a Blind Edit</h3>\n\n<p>To discard all changes and exit blind edit mode without applying anything, simply close the blind edit Timeline window. WATCHOUT removes the temporary composition and the original timeline remains unchanged.</p>\n\n<p>You can also navigate away from the blind edit by activating a different timeline window. The blind edit remains open but inactive — you can return to it later by clicking the blind edit button on the original timeline.</p>\n\n<h3>Visual Indicators</h3>\n\n<p>Several visual cues help you identify when blind edit is active:</p>\n\n<ul>\n<li><strong>Window title</strong> includes \"(Blind Edit)\" suffix</li>\n<li><strong>Title bar color</strong> changes to the blind edit highlight color (distinct from the normal active/locked/inert colors)</li>\n<li><strong>Stage window</strong> shows the composition mode indicator (gantt chart icon) in the top bar</li>\n<li><strong>Stage border</strong> uses the composition mode styling to distinguish blind edit content from live content</li>\n\n</ul>\n<h3>Use Cases</h3>\n\n<p><strong>Live performance adjustments:</strong> During a live show, you need to fix a cue's position or timing for the next scene. Enter blind edit, make the correction, verify it looks right, and Take when the current scene finishes.</p>\n\n<p><strong>Preparing the next look:</strong> While the current scene plays, open a blind edit on the upcoming timeline to set up or refine its content. Take the changes before the timeline is needed.</p>\n\n<p><strong>Error correction without stopping the show:</strong> If you notice a problem with a cue during playback, blind edit lets you fix it without interrupting the live output. The audience sees the current content uninterrupted while you work on corrections.</p>\n\n<p><strong>Safe experimentation:</strong> Use blind edit to try out changes without risk. If the experiment doesn't work, discard the blind edit and the original timeline is untouched.</p>",
      "Insert and Delete Time": "<h2>Insert and Delete Time</h2>\n\n<p>The <strong>Insert/Delete Time</strong> operation shifts cues in bulk by inserting or removing a time range at a specific point on a timeline. This is a powerful tool for restructuring timeline content — adding gaps for new sections, removing dead time, or shifting content to accommodate schedule changes — without needing to manually reposition every cue.</p>\n\n<h3>Accessing the Dialog</h3>\n\n<p>To open the Insert/Delete Time dialog:</p>\n\n<ol>\n<li>Select the target timeline (ensure the Timeline window is active)</li>\n<li>Go to <strong>Timeline → Insert/Delete Time</strong></li>\n\n</ol>\nThe operation is not available if the timeline is locked.\n\n<h3>Parameters</h3>\n\n<p>The dialog presents three controls:</p>\n\n<h4>Time</h4>\nThe amount of time to insert or delete. Enter a <strong>positive value</strong> to insert time (push cues forward), or a <strong>negative value</strong> to delete time (pull cues backward). The value uses the show's standard time expression format.\n\n<p>The operation is applied at the <strong>current playhead position</strong> on the timeline.</p>\n\n<h4>Adjust Duration of Cues</h4>\nWhen enabled, cues that <strong>span the insertion/deletion point</strong> (i.e. start before it and end after it) will have their durations adjusted to account for the time change. Without this option, only the start times of cues after the insertion point are shifted, and spanning cues keep their original duration.\n\n<h4>Adjust Position of Tween Points</h4>\nWhen enabled and cue durations are adjusted, tween keyframe positions (effect points, position keyframes, etc.) within affected cues are shifted to maintain their relative timing within the modified cue. Tween points that fall after the insertion point are moved proportionally.\n\n<h3>Insertion Behavior (Positive Time)</h3>\n\n<p>When you insert time:</p>\n\n<ul>\n<li><strong>Cues starting after the insertion point</strong> are shifted forward by the specified amount</li>\n<li><strong>Cues spanning the insertion point</strong> (start before, end after) have their duration extended by the amount if \"Adjust Duration of Cues\" is enabled</li>\n<li><strong>Cues ending before the insertion point</strong> are not affected</li>\n<li><strong>Tween points</strong> after the insertion point within adjusted cues are shifted forward if \"Adjust Position of Tween Points\" is enabled</li>\n\n</ul>\nThe result is a gap at the insertion point, with all subsequent content pushed later in the timeline.\n\n<h3>Deletion Behavior (Negative Time)</h3>\n\n<p>When you delete time:</p>\n\n<ul>\n<li><strong>Cues entirely within the deleted range</strong> (both start and end fall within the deletion window) are <strong>removed</strong> from the timeline</li>\n<li><strong>Cues starting after the deleted range</strong> are shifted backward. If shifting would place a cue before the deletion point, the cue is pinned to the deletion point and its duration is shortened accordingly</li>\n<li><strong>Cues spanning the deletion point</strong> (start before, end after) have their duration reduced if \"Adjust Duration of Cues\" is enabled. The duration shrinks but the cue's end time is pulled inward, clamped so it does not go below the deletion point</li>\n<li><strong>Tween points</strong> within affected cues that fall after the deletion point are shifted backward. Tween points that would be shifted to before the deletion point are removed</li>\n\n</ul>\n<div class='warning-box'><p>Deletion can <strong>remove cues</strong> that fall entirely within the deleted range. This operation is undoable, but you should verify the result carefully.\n</p></div>\n\n<h3>Effect on Tween Points</h3>\n\n<p>When \"Adjust Position of Tween Points\" is enabled, the operation iterates through all tween types on affected cues — generic tweens (opacity, color corrections, etc.), scale tweens, position tweens, and Art-Net tweens. Each tween point's time is recalculated relative to the new cue start and duration.</p>\n\n<p>Fade placeholder tweens are not affected by the time shift, as they are derived from the cue's fade-in and fade-out settings rather than having independent time positions.</p>\n\n<h3>Use Cases</h3>\n\n<p><strong>Adding a new section mid-show:</strong> Position the playhead where the new section should begin, insert the desired amount of time, and then add new cues into the created gap.</p>\n\n<p><strong>Removing dead time:</strong> If a section of the timeline has an unnecessary pause, position the playhead at the start of the dead time and delete the exact amount of empty time to pull subsequent content closer.</p>\n\n<p><strong>Accommodating schedule changes:</strong> If a speaker segment is extended or shortened, insert or delete time at the transition point to shift all downstream content without manually moving each cue.</p>\n\n<p><strong>Global timeline restructuring:</strong> Use insert/delete time in combination with the duration adjustment option to smoothly reshape the timing of a complex timeline while maintaining the relative structure of effects and animations.</p>\n\n<div class='info-box'><p>After performing an insert or delete operation, preview the affected region of the timeline to verify that cue overlaps, gaps, and tween animations look correct. While the operation handles most cases automatically, complex arrangements with overlapping cues or tightly timed cross-fades may benefit from manual fine-tuning.\n</p></div>",
      "Conditional Cues": "<h2>Conditional Cues</h2>\n\n<p>Any cue in WATCHOUT can have a <strong>condition</strong> attached that controls whether it is active during playback. For media cues, this is called <strong>Conditional Render</strong> — the cue only renders when the condition is true. For control and output cues, this is called <strong>Conditional Trigger</strong> — the cue only fires when the condition is true. This system enables interactive, data-driven shows where content appears, disappears, or triggers based on external inputs and show variables.</p>\n\n<h3>Condition States</h3>\n\n<p>Every cue has a condition property that can be in one of three states:</p>\n\n<ul>\n<li><strong>Enabled</strong> (default) — the cue always renders/triggers normally. No condition is evaluated.</li>\n<li><strong>Disabled</strong> — the cue never renders/triggers, regardless of playback position. This is a simple way to mute a cue without deleting it.</li>\n<li><strong>Expression</strong> — the cue renders/triggers only when the specified expression evaluates to true.</li>\n\n</ul>\n<h3>Setting a Condition</h3>\n\n<p>To add a condition to a cue:</p>\n\n<ol>\n<li>Select one or more cues</li>\n<li>In the <strong>Cue Properties</strong> panel, find the condition section. The label adapts based on the cue types in your selection:</li>\n</ol>\n<ul>\n<li><strong>Conditional Render</strong> — for media cues</li>\n<li><strong>Conditional Trigger</strong> — for control and output cues</li>\n<li><strong>Conditional Render/Trigger</strong> — for mixed selections containing both media and control/output cues</li>\n</ul>\n<ol>\n<li>Change the condition state from <strong>Enabled</strong> to <strong>Expression</strong> (or <strong>Disabled</strong> to simply mute the cue)</li>\n<li>If you selected Expression, enter the condition expression in the <strong>Expression</strong> field</li>\n\n</ol>\n<h3>Condition Expressions</h3>\n\n<p>A condition expression is a mathematical expression that is evaluated against the show's current <strong>variable values</strong> (inputs). The expression follows standard mathematical syntax and can reference any show variable by name.</p>\n\n<p>The expression evaluates to a boolean using a simple rule: <strong>if the result is greater than zero, the condition is true</strong>. If the result is zero or negative, or if the expression contains an error, the condition is false.</p>\n\n<p>Examples:</p>\n\n<ul>\n<li><code>MyVariable</code> — true when the variable \"MyVariable\" is greater than 0</li>\n<li><code>Language</code> — true when the \"Language\" variable is greater than 0</li>\n<li><code>Temperature > 25</code> — true when the \"Temperature\" variable exceeds 25</li>\n<li><code>ButtonA * ButtonB</code> — true only when both \"ButtonA\" and \"ButtonB\" are greater than 0</li>\n<li><code>Mode == 2</code> — true when \"Mode\" equals 2 (evaluates to 1.0 which is > 0)</li>\n\n</ul>\n<div class='note-box'><p>Variable names in expressions are <strong>case-insensitive</strong>. The expression <code>myVar</code> and <code>MYVAR</code> reference the same variable. Variables that are not defined in the show evaluate to 0.\n</p></div>\n\n<h3>Runtime Behavior</h3>\n\n<p>Conditions are evaluated <strong>continuously</strong> during playback, not just at the cue's start time. This means:</p>\n\n<ul>\n<li>A media cue with a conditional render will appear and disappear dynamically as the expression toggles between true and false during the cue's active time range</li>\n<li>A control cue with a conditional trigger will only execute its action (play, pause, stop, jump, etc.) when the condition is true at the moment the playhead reaches the cue's activation time</li>\n<li>An output cue with a conditional trigger will only send its output message (HTTP, TCP, UDP, OSC) when the condition is true at the activation time</li>\n\n</ul>\nIf a media cue's condition becomes false while it is actively rendering, it stops rendering immediately. If the condition becomes true again while the playhead is still within the cue's time range, rendering resumes.\n\n<h3>Interaction with Variables</h3>\n\n<p>Condition expressions are most powerful when combined with <strong>show variables</strong> controlled by external inputs. Variables can be driven by:</p>\n\n<ul>\n<li><strong>OSC</strong> (Open Sound Control) — from lighting consoles, custom apps, or sensor systems</li>\n<li><strong>MIDI</strong> — from MIDI controllers or sequencers</li>\n<li><strong>Art-Net</strong> — from DMX/Art-Net lighting systems</li>\n<li><strong>LTC</strong> (Linear Timecode) — from timecode generators</li>\n<li><strong>HTTP API</strong> — from custom control systems, web interfaces, or automation platforms</li>\n\n</ul>\nFor example, a variable called \"EmergencyMode\" could be set to 1 via an HTTP API call when an emergency occurs. All cues conditioned on <code>EmergencyMode</code> would immediately start rendering emergency messaging across all displays.\n\n<h3>Use Cases</h3>\n\n<p><strong>Show branching based on audience interaction:</strong> Use sensor data (via OSC or MIDI) to set a variable that controls which content path the show follows. Cues on one branch are conditioned on the variable being 1, while cues on the alternative branch are conditioned on it being 0.</p>\n\n<p><strong>Time-of-day content switching:</strong> An external system sets a \"TimeOfDay\" variable (e.g. 1 for morning, 2 for afternoon, 3 for evening). Media cues conditioned on <code>TimeOfDay == 1</code>, <code>TimeOfDay == 2</code>, or <code>TimeOfDay == 3</code> display appropriate content automatically.</p>\n\n<p><strong>Emergency messaging:</strong> A dedicated \"Emergency\" variable is normally 0. When triggered via the HTTP API, it becomes 1, causing conditioned emergency messaging cues to render on all displays instantly. Clearing the variable back to 0 removes the messaging.</p>\n\n<p><strong>Interactive installations:</strong> In museum or exhibition contexts, proximity sensors or touch interfaces can drive variables that show or hide content as visitors approach or interact with displays.</p>\n\n<p><strong>Rehearsal/performance mode:</strong> A \"ShowMode\" variable switches between rehearsal (showing stage directions, timing markers, and debug overlays) and performance mode (clean output only). Cues for each mode are conditioned on the appropriate variable value.</p>"
    }
  },
  "7. Effects and Tweens": {
    "overview": "<h1>EFFECTS AND TWEENS</h1>\n\n<p>Tweens bring your content to life with animation. Learn how to create smooth transitions and dynamic effects.</p>",
    "sections": {
      "Understanding Tweens": "<h2>Understanding Tweens</h2>\n\n<p>Tweens are time-based value changes attached to cues. They define animation curves for motion, opacity, color, crop, and other properties.</p>\n\n<h3>Tween Structure</h3>\n\n<p>A tween consists of:</p>\n\n<ul>\n<li><strong>Type</strong> (for example position, opacity, blur)</li>\n<li><strong>Points</strong> over cue time</li>\n<li><strong>Interpolation</strong> between points</li>\n<li><strong>Value limits/units</strong> depending on tween type</li>\n\n</ul>\n<h3>Supported Categories</h3>\n\n<p>WATCHOUT includes media tweens for:</p>\n\n<ul>\n<li>Position, scale, rotation</li>\n<li>Opacity and fades</li>\n<li>Crop and blur</li>\n<li>Color controls</li>\n<li>Audio volume</li>\n\n</ul>\n<h3>Units and Limits</h3>\n\n<p>Tween values can use different units depending on type:</p>\n\n<ul>\n<li>Percent-based values</li>\n<li>Degree-based values</li>\n<li>Raw numeric ranges</li>\n\n</ul>\nValue limits are defined per tween type and enforced in the editor.\n\n<h3>Practical Advice</h3>\n\n<ul>\n<li>Start with two-point tweens (start/end), then refine.</li>\n<li>Keep easing readable and intentional.</li>\n<li>Avoid unnecessary tween density unless needed for precision.</li>\n\n</ul>",
      "Position and Movement": "<h2>Position and Movement</h2>\n\n<p>Position tweens animate where a cue appears on Stage over time.</p>\n\n<h3>Add Position Animation</h3>\n\n<p>Use <strong>Position</strong> tween actions (menu or shortcut <code>Alt+P</code>) on selected cues.</p>\n\n<h3>Typical Uses</h3>\n\n<ul>\n<li>Slide-ins and exits</li>\n<li>Object tracking across LED canvases</li>\n<li>Camera-like pan effects with layered content</li>\n\n</ul>\n<h3>Precision Tools</h3>\n\n<ul>\n<li>Add points directly on tween curves for key moments.</li>\n<li>Combine with cue start/duration edits for exact synchronization.</li>\n<li>Use nudge commands for fine stage-space adjustments.</li>\n\n</ul>\n<h3>Best Practices</h3>\n\n<ul>\n<li>Animate on one axis first, then add secondary motion.</li>\n<li>Keep movement curves simple for repeatable live operation.</li>\n\n</ul>",
      "Scale and Size": "<h2>Scale and Size</h2>\n\n<p>Scale controls cue size over time and can be driven by tween points or static cue settings.</p>\n\n<h3>Scale Modes</h3>\n\n<p>WATCHOUT supports multiple scaling strategies in cue properties, including:</p>\n\n<ul>\n<li>Scale to explicit size</li>\n<li>Scale by factor</li>\n<li>Media-based scaling behavior</li>\n\n</ul>\n<h3>Scale Tweens</h3>\n\n<p>Use <strong>Scale</strong> tween actions (shortcut <code>Alt+S</code>) to animate growth/shrink effects.</p>\n\n<h3>Common Use Cases</h3>\n\n<ul>\n<li>Pop-in titles</li>\n<li>Slow zoom emphasis</li>\n<li>Scale-matched transitions between scenes</li>\n\n</ul>\n<h3>Tips</h3>\n\n<ul>\n<li>Keep aspect behavior consistent across related cues.</li>\n<li>Check final pixel sharpness on target output, not only in workstation preview.</li>\n\n</ul>",
      "Rotation Effects": "<h2>Rotation Effects</h2>\n\n<p>Rotation tweens control orientation in 2D and 3D contexts.</p>\n\n<h3>Rotation Axes</h3>\n\n<p>WATCHOUT provides:</p>\n\n<ul>\n<li><strong>Rotation Z</strong> (<code>roll</code>) for classic 2D spin</li>\n<li><strong>Rotation Y</strong> (<code>yaw</code>) for horizontal 3D turn</li>\n<li><strong>Rotation X</strong> (<code>pitch</code>) for vertical 3D tilt</li>\n\n</ul>\nShortcuts:\n\n<ul>\n<li><code>Alt+Z</code> for Rotation Z</li>\n<li><code>Alt+Y</code> for Rotation Y</li>\n\n</ul>\n<h3>Practical Uses</h3>\n\n<ul>\n<li>Badge or logo spins</li>\n<li>Card-flip style transitions</li>\n<li>Perspective movement enhancements</li>\n\n</ul>\n<h3>Control Tips</h3>\n\n<ul>\n<li>Keep pivot/anchor placement in mind before animating.</li>\n<li>Large 3D rotations often need complementary position/scale adjustment.</li>\n\n</ul>",
      "Opacity and Fades": "<h2>Opacity and Fades</h2>\n\n<p>Opacity and fade controls define visibility transitions for cues.</p>\n\n<h3>Opacity Tween</h3>\n\n<p>Use <strong>Opacity</strong> tween (<code>Alt+O</code>) for fully custom transparency animation.</p>\n\n<h3>Fade Helpers</h3>\n\n<p>WATCHOUT also supports dedicated fade actions:</p>\n\n<ul>\n<li><strong>Fade In</strong> (<code>Shift+Alt+I</code>)</li>\n<li><strong>Fade Out</strong> (<code>Shift+Alt+O</code>)</li>\n<li><strong>Cross Fade</strong> (<code>Shift+Alt+X</code>)</li>\n\n</ul>\nThese provide fast transition setup with reusable defaults.\n\n<h3>When to Use Which</h3>\n\n<ul>\n<li>Use <strong>fade helpers</strong> for quick standard transitions.</li>\n<li>Use <strong>opacity tween curves</strong> for precise non-linear behavior.</li>\n\n</ul>\n<h3>Common Mistakes</h3>\n\n<ul>\n<li>Overlapping fades without checking final blend result.</li>\n<li>Fades that start/end before cue visibility windows.</li>\n\n</ul>",
      "Cropping": "<h2>Cropping</h2>\n\n<p>Crop tweens animate the visible bounds of a cue and are useful for reveals, wipes, and framing.</p>\n\n<h3>Crop Types</h3>\n\n<ul>\n<li>Crop Top</li>\n<li>Crop Bottom</li>\n<li>Crop Left</li>\n<li>Crop Right</li>\n<li>Crop All (all sides together)</li>\n\n</ul>\nShortcut for crop-all toggle: <code>Alt+C</code>.\n\n<h3>Typical Use Cases</h3>\n\n<ul>\n<li>Directional text/image reveals</li>\n<li>Safe-area adjustments without re-rendering assets</li>\n<li>Dynamic framing across multiple aspect ratios</li>\n\n</ul>\n<h3>Workflow Tips</h3>\n\n<ul>\n<li>Start with one side to define motion intent.</li>\n<li>Combine with opacity for softer reveals.</li>\n<li>Validate crop behavior on real output resolution.</li>\n\n</ul>",
      "Color Adjustments": "<h2>Color Adjustments</h2>\n\n<p>Color tweens let you animate tonal and channel-level color properties directly on cues.</p>\n\n<h3>Available Color Tweens</h3>\n\n<ul>\n<li>Brightness</li>\n<li>Contrast</li>\n<li>Gamma</li>\n<li>Hue</li>\n<li>Saturation</li>\n<li>Invert</li>\n<li>Red/Green/Blue Gain</li>\n<li>Red/Green/Blue Offset</li>\n\n</ul>\n<h3>Use Cases</h3>\n\n<ul>\n<li>Scene mood transitions</li>\n<li>Day/night look shifts</li>\n<li>Corrective matching between mixed media sources</li>\n\n</ul>\n<h3>Quality Notes</h3>\n\n<ul>\n<li>Extreme values can clip highlights or crush shadows.</li>\n<li>Test color tweens on calibrated outputs when possible.</li>\n<li>For show-wide looks, prefer consistent per-scene strategy over ad hoc cue edits.</li>\n\n</ul>",
      "Blur Effects": "<h2>Blur Effects</h2>\n\n<p>WATCHOUT provides a <strong>Gaussian Blur</strong> tween for softening and defocusing content over time.</p>\n\n<h3>Add Blur</h3>\n\n<ul>\n<li>Use Effect menu blur action</li>\n<li>Shortcut: <code>Alt+B</code></li>\n\n</ul>\n<h3>Creative Uses</h3>\n\n<ul>\n<li>Focus pulls between foreground/background layers</li>\n<li>Transition smoothing</li>\n<li>Stylized intro/outro looks</li>\n\n</ul>\n<h3>Performance Guidance</h3>\n\n<p>Blur is GPU-intensive in large compositions. If performance drops:</p>\n\n<ul>\n<li>Reduce overlapping blurred cues</li>\n<li>Shorten blur-heavy sections</li>\n<li>Pre-render where possible for mission-critical playback</li>\n\n</ul>",
      "Audio Volume": "<h2>Audio Volume</h2>\n\n<p>Volume tweens automate cue loudness over time.</p>\n\n<h3>Add Volume Automation</h3>\n\n<p>Use <strong>Volume</strong> tween actions or shortcut <code>Alt+V</code> on cues with audio content.</p>\n\n<h3>Common Scenarios</h3>\n\n<ul>\n<li>Music fade-ins and fade-outs</li>\n<li>Ducking under voice-over or announcements</li>\n<li>Layered ambience balancing</li>\n\n</ul>\n<h3>Practical Workflow</h3>\n\n<ol>\n<li>Set initial cue gain.</li>\n<li>Add volume tween points at scene boundaries.</li>\n<li>Verify transitions on the target audio routing path.</li>\n\n</ol>\n<h3>Notes for Complex Shows</h3>\n\n<p>If you use multiple output buses/channels, validate both cue-level volume and device/channel mapping so automation behaves as expected at the final output.</p>",
      "Corner Pinning": "<h2>Corner Pinning</h2>\n\n<p>Corner pinning is a per-cue distortion effect that lets you independently reposition each of the four corners of a media cue. By moving corners away from their default positions, you can create perspective distortion, trapezoid correction, and arbitrary quadrilateral deformations — all without modifying the source media.</p>\n\n<p>Internally, WATCHOUT computes a <strong>homography projection matrix</strong> from the four corner positions. This matrix maps every pixel from the original rectangular cue into the new quadrilateral shape in a single GPU pass, preserving smooth interpolation across the entire surface.</p>\n\n<h3>Corner Tween Channels</h3>\n\n<p>The Corners effect is controlled through <strong>eight tween channels</strong>, one for each axis of each corner:</p>\n\n<ul>\n<li><strong>Corner Top Left X</strong> / <strong>Corner Top Left Y</strong></li>\n<li><strong>Corner Top Right X</strong> / <strong>Corner Top Right Y</strong></li>\n<li><strong>Corner Bottom Left X</strong> / <strong>Corner Bottom Left Y</strong></li>\n<li><strong>Corner Bottom Right X</strong> / <strong>Corner Bottom Right Y</strong></li>\n\n</ul>\nEach channel represents a <strong>normalized offset</strong> from the corner's default position. A value of <strong>100</strong> (the default) means the corner is at its natural position. A value of <strong>0</strong> moves the corner all the way to the opposite corner of the cue. Values beyond this range are permitted — the channels are unlimited — allowing you to extend corners outside the original cue boundary for exaggerated distortion.\n\n<div class='info-box'><p>Because each axis is independent, you have full control over both horizontal and vertical movement of every corner. This makes it possible to create not just simple trapezoids but complex quadrilateral shapes.\n</p></div>\n\n<h3>Adding Corner Tweens</h3>\n\n<p>To add corner tweens to a cue:</p>\n\n<ol>\n<li>Select one or more media cues in the Timeline.</li>\n<li>Open the <strong>Effect</strong> menu and click <strong>Corners</strong>. This adds all eight corner channels to the cue simultaneously.</li>\n<li>The Corners tween group appears in the tween area beneath the cue, labeled <strong>Corners</strong> in the tween group header.</li>\n\n</ol>\nAlternatively, you can add corner tweens by right-clicking a cue and accessing the effect options from the context menu.\n\n<p>Once added, each channel starts at its default value of 100 (the corner's natural position). You can then adjust individual corner coordinates by editing tween point values in the Properties panel or by adding additional keyframes.</p>\n\n<h3>Animating Corners</h3>\n\n<p>Like all tweens in WATCHOUT, corner channels support multiple <strong>tween points</strong> (keyframes) with configurable easing curves. To animate a corner:</p>\n\n<ol>\n<li>Place the time needle at the desired moment and add a tween point to the corner channel.</li>\n<li>Set the target corner position value.</li>\n<li>Choose a <strong>transition type</strong> (Linear, Quadratic, Cubic, Sinusoidal, etc.) to control the interpolation curve between points.</li>\n\n</ol>\nBy placing keyframes at different times with different corner positions, you can create dynamic perspective shifts — for example, gradually skewing a cue to simulate a turning page or morphing a rectangle into a trapezoid during a transition.\n\n<h3>Convexity Constraint</h3>\n\n<p>WATCHOUT automatically enforces a <strong>convexity constraint</strong> on the resulting quadrilateral. If you move corners into a configuration that would create a concave (self-intersecting) shape, the system subtly adjusts the offending corner to maintain a valid convex quadrilateral. This ensures the homography transform always produces a reasonable, artifact-free result.</p>\n\n<div class='note-box'><p>The convexity adjustment is minimal and designed to be visually imperceptible in most cases. However, extreme corner configurations may result in slightly different positions than the values you entered.\n</p></div>\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Projection mapping</strong> — fit rectangular content onto non-rectangular physical surfaces such as angled screens, building facades, or set pieces.</li>\n<li><strong>Trapezoid correction</strong> — compensate for projector keystoning or physical misalignment by pinning corners to match the actual projection surface.</li>\n<li><strong>Perspective effects</strong> — simulate depth and dimensionality by skewing content to create a vanishing-point illusion.</li>\n<li><strong>Artistic distortion</strong> — animate corners over time for creative transitions, shape morphing, or dynamic visual effects.</li>\n\n</ul>\n<h3>Interaction with Display-Level Warp</h3>\n\n<p>Corner pinning is a <strong>per-cue effect</strong> applied during the rendering of individual cues, before any display-level geometry correction. If your displays also use warp meshes or geometric correction, the two effects are applied in sequence: the cue is first distorted by its corner pinning, then the entire composited output is transformed by the display warp.</p>\n\n<p>This layered approach means you can use corner pinning for cue-specific adjustments (fitting individual content to specific surfaces) while relying on display warp for global projector alignment — and the two will complement each other without conflict.</p>",
      "Linear Wipe": "<h2>Linear Wipe</h2>\n\n<p>Linear Wipe is a transition effect that progressively reveals or hides a cue's content using a straight-line boundary. By animating the wipe's parameters over time, you can create clean reveal and conceal transitions, split-screen effects, and dynamic content boundaries.</p>\n\n<p>The wipe works by defining an invisible edge that divides the cue into a visible region and a transparent region. The edge can be positioned, angled, and softened to produce a wide variety of transition styles.</p>\n\n<h3>Wipe Tween Channels</h3>\n\n<p>The Linear Wipe effect is controlled through four tween channels, all added together as a group:</p>\n\n<ul>\n<li><strong>Angle</strong> — the direction of the wipe edge, expressed in degrees. The range is unlimited (default display range −80° to 180°), so you can rotate the wipe boundary to any orientation. At 0° the edge is vertical; changing the angle rotates it accordingly.</li>\n<li><strong>Location</strong> — the position of the wipe edge along the perpendicular axis, expressed as a percentage from 0 to 100. This determines where along the cue the dividing line sits. The default value is 100 (fully visible).</li>\n<li><strong>Feather</strong> — the softness of the transition zone at the wipe edge, expressed as a percentage. A value of 0 produces a hard, crisp edge. Higher values create a gradual fade from opaque to transparent across the boundary. The minimum is 0; there is no hard upper limit.</li>\n<li><strong>Completion</strong> — the overall progress of the wipe, from 0 (fully hidden) to 100 (fully visible). This is the primary channel you animate to drive a reveal or conceal transition. The default value is 0 (fully hidden).</li>\n\n</ul>\n<div class='info-box'><p>For a simple left-to-right reveal, set the Angle to 0° and animate Completion from 0 to 100. For a top-to-bottom reveal, set the Angle to 90°. Add Feather to soften the transition edge.\n</p></div>\n\n<h3>Creating a Linear Wipe</h3>\n\n<p>To add a Linear Wipe to a cue:</p>\n\n<ol>\n<li>Select one or more media cues in the Timeline.</li>\n<li>Open the <strong>Effect</strong> menu and click <strong>Linear Wipe</strong>. This adds all four wipe channels to the cue simultaneously.</li>\n<li>The wipe channels appear in the tween area beneath the cue, grouped under the <strong>Linear Wipe</strong> header.</li>\n\n</ol>\nOnce added, the cue starts fully hidden (Completion = 0) by default. Add tween points to the Completion channel to animate the reveal.\n\n<h3>Animating the Wipe</h3>\n\n<p>Linear Wipe channels support multiple <strong>tween points</strong> with configurable easing curves, just like any other tween in WATCHOUT:</p>\n\n<ol>\n<li>Place the time needle at the start of the transition and set Completion to 0.</li>\n<li>Move the time needle to the end of the transition and add a tween point with Completion set to 100.</li>\n<li>Choose a <strong>transition type</strong> (Linear, Quadratic, Cubic, Sinusoidal, etc.) to control the speed curve.</li>\n\n</ol>\nYou can also animate the Angle, Location, and Feather channels independently. For example, you might rotate the wipe edge while it sweeps across the cue, or gradually increase feather softness during the transition for a more organic feel.\n\n<h3>Effect Ordering</h3>\n\n<p>Linear Wipe is an <strong>orderable effect</strong>, meaning its position in the tween processing chain relative to other orderable effects (such as keying) matters. Effects are processed in the order they appear in the tween list. You can reorder effects to control how they interact — for example, applying a wipe after or before a color key will produce different visual results.</p>\n\n<h3>Combining with Other Effects</h3>\n\n<p>Linear Wipe works well in combination with other tweens:</p>\n\n<ul>\n<li><strong>Opacity</strong> — combine a wipe with an opacity fade for a reveal that also fades in.</li>\n<li><strong>Position</strong> — slide content into view while simultaneously wiping it on, creating a cinematic entrance.</li>\n<li><strong>Corner Pinning</strong> — distort the cue shape while wiping for perspective-aware transitions.</li>\n<li><strong>Color adjustments</strong> — desaturate or brighten content as it wipes in for dramatic reveals.</li>\n\n</ul>\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Scene transitions</strong> — wipe between content by placing two cues back-to-back and animating their Completion values in opposite directions.</li>\n<li><strong>Progressive reveals</strong> — gradually uncover text, images, or video using an animated Completion value.</li>\n<li><strong>Split-screen effects</strong> — set static Location and Completion values (without animation) to divide the cue into visible and hidden regions, effectively cropping along an angled line.</li>\n<li><strong>Dynamic content boundaries</strong> — animate the Angle or Location over time to create moving borders within a cue.</li>\n\n</ul>",
      "Blend Modes": "<h2>Blend Modes</h2>\n\n<p>Every media cue in WATCHOUT has a <strong>Blend Mode</strong> property that determines how its rendered pixels are composited with the content beneath it. By default, cues use standard alpha compositing (Normal mode), but you can switch to alternative modes to create a variety of visual effects — from additive light simulations to darkening overlays.</p>\n\n<p>Blend modes operate on a per-pixel basis during compositing. The GPU evaluates each pixel of the cue against the corresponding pixel of the content already rendered below it, producing a final combined result according to the selected blending formula.</p>\n\n<h3>Available Blend Modes</h3>\n\n<p>WATCHOUT provides seven blend modes:</p>\n\n<ul>\n<li><strong>Normal</strong> — standard alpha compositing. The cue's pixels replace or blend over underlying content based on their alpha (transparency) values. This is the default mode for all cues.</li>\n<li><strong>Add</strong> (Additive) — the RGB values of the cue are added to the underlying content. This always brightens the result (black pixels have no effect). Useful for light effects, particles, fire, glow, and lens flares.</li>\n<li><strong>Multiply</strong> — the RGB values of both layers are multiplied together, always producing a darker result (white pixels have no effect). Useful for shadows, texture overlays, and blending images with dark backgrounds.</li>\n<li><strong>Screen</strong> — the mathematical inverse of Multiply. The values are inverted, multiplied, then inverted again, always producing a lighter result (black pixels have no effect). Useful for glow effects, light leaks, and brightening composites.</li>\n<li><strong>Lighten</strong> — for each color channel, the brighter of the two pixel values is kept. Only areas brighter than the underlying content show through. Useful for combining multiple light sources.</li>\n<li><strong>Darken</strong> — for each color channel, the darker of the two pixel values is kept. Only areas darker than the underlying content show through. Useful for combining shadow elements.</li>\n<li><strong>Linear Burn</strong> — adds the pixel values of both layers and subtracts white (1.0), producing a result darker than Multiply. Creates high-contrast darkening effects and deep shadow blends.</li>\n\n</ul>\n<h3>Setting the Blend Mode</h3>\n\n<p>To change a cue's blend mode:</p>\n\n<ol>\n<li>Select the cue in the Timeline or on the Stage.</li>\n<li>Open the <strong>Properties</strong> panel.</li>\n<li>In the <strong>Presentation</strong> page, locate the <strong>Blend Mode</strong> dropdown.</li>\n<li>Select the desired mode from the list.</li>\n\n</ol>\nThe change takes effect immediately in the Stage preview.\n\n<div class='info-box'><p>You can set the blend mode on multiple cues simultaneously by selecting them all before changing the property.\n</p></div>\n\n<h3>Interaction with Stacking and Layer Order</h3>\n\n<p>Blend modes are applied during compositing, so they are directly affected by the <strong>rendering order</strong> of cues:</p>\n\n<ul>\n<li>Within a timeline, cues are composited according to their <strong>layer order</strong> (bottom layer renders first, top layer renders last). A cue's blend mode determines how it composites onto everything already rendered below it.</li>\n<li>Across timelines, the <strong>timeline stacking order</strong> (Timeline Order or Always on Top) determines which timeline's content is rendered on top. Blend modes apply within this stacking hierarchy.</li>\n<li>A cue's <strong>per-cue stacking</strong> setting (By Z or By Layer) further influences the order in which overlapping cues are composited, which in turn affects how blend modes interact.</li>\n\n</ul>\n<h3>Common Creative Techniques</h3>\n\n<ul>\n<li><strong>Projection mapping luminance overlays</strong> — use Add mode to layer light effects, moving patterns, or particle systems on top of base content. Black areas in the additive layer are completely transparent.</li>\n<li><strong>Texture and shadow overlays</strong> — use Multiply mode to darken base content with shadow maps, grunge textures, or vignettes without affecting bright areas.</li>\n<li><strong>Atmospheric effects</strong> — use Screen mode to composite fog, haze, or light ray overlays that naturally brighten the scene without obscuring dark areas.</li>\n<li><strong>Selective compositing</strong> — use Lighten or Darken modes to selectively combine the brightest or darkest elements from multiple content sources.</li>\n\n</ul>",
      "Frame Blending": "<h2>Frame Blending</h2>\n\n<p>Frame Blending is a per-cue option that smooths video playback when the source media's native frame rate does not match the show's output frame rate. Instead of repeating or dropping frames to fill the gap, WATCHOUT interpolates between adjacent video frames, producing a crossfade that results in visibly smoother motion.</p>\n\n<h3>How It Works</h3>\n\n<p>When a video plays at a different rate than the show's output (for example, 24 fps content in a 60 fps show), some output frames fall between two source frames. Without frame blending, WATCHOUT displays the nearest available source frame, which can cause stuttering or judder — especially noticeable in panning shots or smooth animations.</p>\n\n<p>With Frame Blending enabled, the renderer blends the two neighboring source frames together for any output frame that falls between them. The blend ratio is determined by the fractional position between the two source frames, producing a smooth temporal crossfade.</p>\n\n<h3>Enabling Frame Blending</h3>\n\n<p>To enable Frame Blending on a cue:</p>\n\n<ol>\n<li>Select the media cue in the Timeline.</li>\n<li>Open the <strong>Properties</strong> panel.</li>\n<li>In the <strong>Playback</strong> page, locate the <strong>Frame Blending</strong> toggle.</li>\n<li>Enable the checkbox.</li>\n\n</ol>\nFrame Blending is disabled by default and must be enabled on each cue individually.\n\n<h3>When to Use It</h3>\n\n<p>Frame Blending is most beneficial in these scenarios:</p>\n\n<ul>\n<li><strong>Mismatched frame rates</strong> — playing 24 fps or 25 fps film content in a 50 fps or 60 fps show. The interpolation eliminates the 3:2 pulldown stutter that would otherwise occur.</li>\n<li><strong>Slow-motion playback</strong> — when slowing down video via playback speed adjustments or tween-controlled playback rate. Frame blending fills in the gaps between source frames to maintain smooth motion.</li>\n<li><strong>Variable-speed tweens</strong> — when a playback rate tween causes the media to play at non-integer speed ratios, frame blending smooths the transitions.</li>\n\n</ul>\n<h3>When to Avoid It</h3>\n\n<p>Frame Blending is not ideal for all content types. Avoid it when:</p>\n\n<ul>\n<li><strong>Text and sharp-edged graphics</strong> — the crossfade between frames can produce visible ghosting on high-contrast edges, making text appear blurry during motion.</li>\n<li><strong>Content already matching the show frame rate</strong> — if the source frame rate matches the output rate, every output frame maps exactly to a source frame and blending provides no benefit.</li>\n<li><strong>Rapid cuts or flash sequences</strong> — frame blending across hard cuts produces brief double-exposure artifacts that may be undesirable.</li>\n\n</ul>\n<div class='note-box'><p>Frame Blending interpolates by crossfading pixel values between frames. It does not perform optical flow or motion-vector interpolation, so very fast motion may still show some ghosting.\n</p></div>\n\n<h3>Performance Considerations</h3>\n\n<p>When Frame Blending is enabled, the renderer must decode and hold <strong>two adjacent frames</strong> in memory simultaneously and perform a per-pixel blend for every output frame. This roughly doubles the texture memory and bandwidth required for that cue compared to non-blended playback. On systems with many simultaneous video cues, enabling Frame Blending on all of them may impact overall GPU performance. Enable it selectively on the cues where smooth motion matters most.</p>",
      "Chroma Key": "<h2>Chroma Key</h2>\n\n<p>Chroma Key is a per-cue compositing technique that removes a specific color from a cue's rendered output, making those areas transparent. This is commonly used to remove green screen or blue screen backgrounds from video footage, allowing the foreground subject to be composited over other content in the show.</p>\n\n<p>WATCHOUT performs chroma keying in the renderer's color pipeline, operating in a wide-gamut color space (Rec. 2020 YCbCr) for accurate color matching regardless of the source media's color standard.</p>\n\n<h3>Enabling Chroma Key</h3>\n\n<p>To enable chroma keying on a cue:</p>\n\n<ol>\n<li>Select the media cue in the Timeline.</li>\n<li>Open the <strong>Properties</strong> panel.</li>\n<li>Locate the <strong>Chroma Key</strong> section.</li>\n<li>Toggle the <strong>Enabled</strong> switch on.</li>\n\n</ol>\nOnce enabled, the cue immediately begins keying out the target color (green by default). You can then fine-tune the parameters to achieve a clean key.\n\n<h3>Presets</h3>\n\n<p>WATCHOUT provides three preset options for quick setup:</p>\n\n<ul>\n<li><strong>Green</strong> — targets a standard chroma green (RGB 0, 177, 64). This is the default preset and the most common choice for green screen footage.</li>\n<li><strong>Blue</strong> — targets a standard chroma blue for blue screen footage.</li>\n<li><strong>Custom</strong> — allows you to specify an arbitrary target color using the color controls.</li>\n\n</ul>\nSelecting a preset immediately updates the target color. You can further refine the color after selecting a preset.\n\n<h3>Target Color</h3>\n\n<p>The target color defines which color will be keyed out of the cue's output. You can specify the color using two sets of controls:</p>\n\n<ul>\n<li><strong>RGB</strong> (Red, Green, Blue) — set exact color component values.</li>\n<li><strong>HSV</strong> (Hue, Saturation, Value) — set the color using the hue/saturation/brightness model, which can be more intuitive for selecting colors visually.</li>\n\n</ul>\nA <strong>Change</strong> button opens a color picker for visual target selection. Both RGB and HSV controls update together — changing one set automatically reflects in the other.\n\n<h3>Tolerance</h3>\n\n<p>The tolerance parameters control how closely a pixel's color must match the target color to be keyed out:</p>\n\n<ul>\n<li><strong>Min</strong> (default: 0.4) — defines the inner boundary. Pixels whose color distance from the target is less than or equal to Min are made <strong>fully transparent</strong>.</li>\n<li><strong>Max</strong> (default: 0.5) — defines the outer boundary. Pixels whose color distance falls between Min and Max receive <strong>partial transparency</strong>, creating a smooth falloff at the edges of the keyed region.</li>\n\n</ul>\nPixels with a color distance greater than Max are left fully opaque.\n\n<div class='info-box'><p>Start with the default tolerance values and adjust gradually. Increasing Min expands the fully transparent region; increasing Max softens the transition between transparent and opaque areas. The goal is to fully remove the background while preserving fine edge details like hair or translucent materials.\n</p></div>\n\n<h3>Spill Removal</h3>\n\n<p>The <strong>Spill Removal</strong> control (default: 0.5) reduces color contamination — the colored fringe that often appears on foreground edges when the key color reflects onto the subject. Higher values apply more aggressive spill suppression, neutralizing the color cast on edge pixels.</p>\n\n<h3>Visualize Mask</h3>\n\n<p>The <strong>Visualize Mask</strong> toggle switches the cue's output to a diagnostic view that displays the generated alpha mask directly. In this mode:</p>\n\n<ul>\n<li><strong>White areas</strong> represent fully opaque pixels (foreground).</li>\n<li><strong>Black areas</strong> represent fully transparent pixels (keyed out).</li>\n<li><strong>Gray areas</strong> represent partially transparent pixels (the tolerance falloff zone).</li>\n\n</ul>\nThis is invaluable for fine-tuning tolerance and spill removal settings. Turn off Visualize Mask when you are satisfied with the key to return to normal composited output.\n\n<h3>Reset</h3>\n\n<p>The <strong>Reset</strong> button restores all chroma key parameters to their default values (green target, Min tolerance 0.4, Max tolerance 0.5, spill removal 0.5, Visualize Mask off). Use this to quickly return to a clean starting point if your adjustments have become difficult to manage.</p>\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Live camera feeds</strong> — composite real-time camera input over show content by keying out the green or blue screen backdrop.</li>\n<li><strong>Pre-recorded keyed footage</strong> — remove backgrounds from video content shot against a chroma backdrop.</li>\n<li><strong>Removing uniform backgrounds</strong> — key out any solid-color background, not just green or blue, using the Custom preset with an appropriate target color.</li>\n\n</ul>\n<h3>Tips for Clean Keys</h3>\n\n<ul>\n<li><strong>Even lighting</strong> — ensure the chroma backdrop is lit uniformly without hotspots or shadows. Uneven lighting creates color variations that make consistent keying difficult.</li>\n<li><strong>Avoid shadows on the backdrop</strong> — shadows darken the key color, pushing it outside the tolerance range and leaving residual background visible.</li>\n<li><strong>Subject separation</strong> — keep the subject far enough from the backdrop to minimize spill and shadow contamination.</li>\n<li><strong>Combine with opacity tweens</strong> — use an Opacity tween alongside chroma key to fade keyed content in or out smoothly during transitions.</li>\n\n</ul>",
      "Key and Fill": "<h2>Key and Fill</h2>\n\n<p>Key & Fill is a <strong>layer-level</strong> compositing feature that uses the content of one layer (the <strong>key</strong> layer) to generate a transparency mask that is applied to another layer (the <strong>fill</strong> layer). This enables sophisticated compositing effects — such as masking content through animated shapes, text cutouts, or grayscale mattes — without modifying the source media.</p>\n\n<p>Unlike Chroma Key, which operates on a single cue's own pixel colors, Key & Fill uses a separate layer as the mask source. This gives you the flexibility to use any content — video, images, text, or generated graphics — as a transparency mask for other content.</p>\n\n<h3>How It Works</h3>\n\n<p>Key & Fill involves two layers working together:</p>\n\n<ul>\n<li>The <strong>key layer</strong> contains the content that defines the mask. Its visual output (luminance or alpha) is converted into transparency values.</li>\n<li>The <strong>fill layer</strong> contains the content you want to display. The transparency mask from the key layer is applied to it, making portions of the fill layer transparent or opaque based on the key.</li>\n\n</ul>\nThe key layer provides the mask signal, and the fill layer is where the mask is consumed. The key layer itself is not rendered to the output — it exists solely to generate the transparency mask.\n\n<h3>Keying Modes</h3>\n\n<p>WATCHOUT supports four keying modes that determine how the key layer's content is interpreted as a mask:</p>\n\n<ul>\n<li><strong>Luma Key</strong> — uses the luminance (brightness) of the key layer to define transparency. Bright areas of the key make the fill opaque; dark areas make it transparent.</li>\n<li><strong>Luma Key (Inverted)</strong> — inverts the luminance mask. Dark areas of the key make the fill opaque; bright areas make it transparent.</li>\n<li><strong>Alpha Key</strong> — uses the alpha channel of the key layer to define transparency. Opaque areas of the key make the fill opaque; transparent areas make it transparent.</li>\n<li><strong>Alpha Key (Inverted)</strong> — inverts the alpha mask, reversing which areas are opaque and transparent.</li>\n\n</ul>\n<div class='info-box'><p>Luma Key is the most versatile mode because any content — including video without an alpha channel — can serve as a mask based on its brightness values. Alpha Key is useful when working with content that has a pre-defined transparency channel, such as PNG images or ProRes 4444 video.\n</p></div>\n\n<h3>Configuring Key & Fill</h3>\n\n<p>Key & Fill is configured in two places — once on the key layer and once on the fill layer:</p>\n\n<p><strong>On the key layer (providing the mask):</strong></p>\n\n<ol>\n<li>Select a layer in the Timeline.</li>\n<li>In the <strong>Layer Properties</strong>, enable the <strong>Key & Fill</strong> option for this layer.</li>\n<li>Select the <strong>keying mode</strong> (Luma, Luma Inverted, Alpha, or Alpha Inverted).</li>\n\n</ol>\nOnce a layer is designated as a key source, a visual indicator appears on the layer header in the Timeline showing its keying role (e.g., \"This layer is used as Luma Key\").\n\n<p><strong>On the fill layer (receiving the mask):</strong></p>\n\n<ol>\n<li>Select the cue(s) on the fill layer.</li>\n<li>In the cue's <strong>Properties</strong> panel, locate the <strong>Key & Fill</strong> section.</li>\n<li>Toggle <strong>Enabled</strong> on.</li>\n<li>The fill cue will receive the mask from the key layer.</li>\n\n</ol>\n<h3>Invert Toggle</h3>\n\n<p>The fill-side <strong>Invert</strong> toggle provides an additional way to flip the mask behavior at the cue level. This is independent of the key mode selection and allows you to invert the mask on specific fill cues without changing the key layer's mode.</p>\n\n<h3>Visualize Key</h3>\n\n<p>The <strong>Visualize Key</strong> toggle on the fill cue switches the output to a diagnostic view that displays the generated mask directly:</p>\n\n<ul>\n<li><strong>White areas</strong> represent opaque regions of the fill.</li>\n<li><strong>Black areas</strong> represent transparent regions.</li>\n<li><strong>Gray areas</strong> represent partially transparent regions.</li>\n\n</ul>\nThis is useful for verifying that the key layer is producing the expected mask shape before viewing the final composited result. Disable Visualize Key to return to normal output.\n\n<h3>Layer Indicators</h3>\n\n<p>When a layer is configured as a key source, WATCHOUT displays a tooltip indicator on the layer header in the Timeline. The indicator describes the layer's keying role:</p>\n\n<ul>\n<li>\"This layer is used as Alpha Key\"</li>\n<li>\"This layer is used as Luma Key\"</li>\n<li>\"This layer is used as Inverted Alpha Key\"</li>\n<li>\"This layer is used as Inverted Luma Key\"</li>\n\n</ul>\nThese indicators help you quickly identify which layers are participating in Key & Fill relationships without opening the properties panel.\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Dynamic text reveals</strong> — place text or animated typography on the key layer and video content on the fill layer. The text shape cuts through the video, revealing it only where the text appears.</li>\n<li><strong>Shaped content windows</strong> — use a grayscale matte (a white shape on a black background) as the key to display fill content only within the shape boundary.</li>\n<li><strong>Graphic overlays with custom transparency</strong> — use a pre-rendered alpha matte video as the key to create complex, animated transparency patterns on the fill layer.</li>\n<li><strong>Creative transitions</strong> — animate the key layer content (e.g., an expanding circle or a moving gradient) to progressively reveal or hide the fill layer over time.</li>\n\n</ul>\n<h3>Relationship to Chroma Key</h3>\n\n<p>Key & Fill and Chroma Key are complementary but distinct features:</p>\n\n<ul>\n<li><strong>Chroma Key</strong> operates <strong>per-cue</strong> on the cue's own pixel colors, removing a specific color (typically green or blue) to create transparency.</li>\n<li><strong>Key & Fill</strong> operates at the <strong>layer level</strong>, using a completely separate layer's content as the transparency source.</li>\n\n</ul>\nYou can use both features simultaneously — for example, chroma-keying a green screen subject on the fill layer while also applying a Key & Fill mask from a matte on the key layer.",
      "Tween Expressions": "<h2>Tween Expressions</h2>\n\n<p>Tween expressions allow any tween property — position, opacity, scale, color adjustments, and more — to be driven dynamically by a mathematical expression instead of relying solely on static keyframe values. Expressions are evaluated at runtime on every frame, making tween values responsive to show variables, external inputs, and mathematical functions.</p>\n\n<p>This is one of the most powerful features in WATCHOUT for creating interactive, data-driven, and externally controllable presentations.</p>\n\n<h3>How Expressions Work</h3>\n\n<p>Every tween in WATCHOUT has an <strong>expression field</strong> alongside its keyframe data. At runtime, the system first interpolates the keyframe curve at the current time to produce a base value called <code>tweenValue</code>. This value is then passed into the expression, which can transform, replace, or augment it.</p>\n\n<p>The expression language is a mathematical formula evaluator (powered by the [fasteval](https://crates.io/crates/fasteval) library) that supports standard arithmetic, mathematical functions, and variable references. The expression must resolve to a single numeric value, which becomes the final tween output for that frame.</p>\n\n<h3>Setting an Expression</h3>\n\n<p>To add an expression to a tween:</p>\n\n<ol>\n<li>Select a cue that has the desired tween applied.</li>\n<li>In the <strong>Properties</strong> panel, expand the tween's properties.</li>\n<li>Locate the <strong>Expression</strong> field.</li>\n\n</ol>\nThe expression field varies depending on the tween type:\n\n<ul>\n<li><strong>Single-value tweens</strong> (Opacity, Blur, Crop, Color adjustments, Volume, etc.) have one <strong>Expression</strong> field.</li>\n<li><strong>Scale tweens</strong> have separate <strong>X Expression</strong> and <strong>Y Expression</strong> fields.</li>\n<li><strong>Position tweens</strong> have separate <strong>X Expression</strong>, <strong>Y Expression</strong>, and <strong>Z Expression</strong> fields.</li>\n\n</ul>\nLeave the expression field at its default value (<code>tweenValue</code>) to pass the keyframe-interpolated value through unmodified.\n\n<h3>The <code>tweenValue</code> Variable</h3>\n\n<p>The built-in variable <code>tweenValue</code> represents the keyframe-interpolated value at the current point in time. This is the default expression for all tweens — when the expression field contains <code>tweenValue</code> (or is empty), the tween behaves as if no expression is set, outputting the pure keyframe value.</p>\n\n<p>You can use <code>tweenValue</code> in more complex expressions to modify the keyframed animation:</p>\n\n<ul>\n<li><code>tweenValue * 2</code> — doubles the keyframed value</li>\n<li><code>tweenValue + 10</code> — offsets the keyframed value by 10</li>\n<li><code>tweenValue * myVariable / 100</code> — scales the keyframed value by an external variable</li>\n\n</ul>\nFor position tweens, the same concept applies per axis: the X expression receives the X component of the interpolated position as <code>tweenValue</code>, the Y expression receives the Y component, and so on.\n\n<h3>Expression Syntax</h3>\n\n<p>Expressions support standard mathematical syntax:</p>\n\n<p><strong>Arithmetic operators:</strong> <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code> (modulo), <code>^</code> (power)</p>\n\n<p><strong>Comparison and logic:</strong> <code><</code>, <code>></code>, <code><=</code>, <code>>=</code>, <code>==</code>, <code>!=</code>, <code>and</code>, <code>or</code>, <code>not</code></p>\n\n<p><strong>Built-in math functions:</strong> <code>sin()</code>, <code>cos()</code>, <code>tan()</code>, <code>asin()</code>, <code>acos()</code>, <code>atan()</code>, <code>sqrt()</code>, <code>abs()</code>, <code>log()</code>, <code>log10()</code>, <code>ceil()</code>, <code>floor()</code>, <code>round()</code>, <code>min()</code>, <code>max()</code></p>\n\n<p><strong>Constants:</strong> <code>pi</code>, <code>e</code></p>\n\n<p><strong>Conditional expressions:</strong> <code>if(condition, then_value, else_value)</code></p>\n\n<div class='note-box'><p>Expression evaluation is case-insensitive. <code>TweenValue</code>, <code>tweenvalue</code>, and <code>TWEENVALUE</code> all refer to the same variable.\n</p></div>\n\n<h3>Variable References</h3>\n\n<p>Expressions can reference <strong>show variables</strong> (defined in the Variables panel) by name. This is what makes expressions truly powerful: you can bind any tween property to an external input.</p>\n\n<p>For example, if you have a show variable called <code>faderLevel</code> that is controlled by an OSC input, you could write:</p>\n\n<ul>\n<li><strong>Opacity expression:</strong> <code>faderLevel</code> — directly maps the fader to opacity</li>\n<li><strong>Position X expression:</strong> <code>tweenValue + trackerX</code> — offsets the keyframed position by a tracking variable</li>\n<li><strong>Scale X expression:</strong> <code>max(tweenValue, minScale)</code> — clamps the scale to never go below a variable-defined minimum</li>\n\n</ul>\nWhen a variable referenced in an expression changes (because an external system sent a new value via OSC, ArtNet, MIDI, etc.), the tween output updates immediately on the next frame. This enables real-time interactive control without modifying the show's timeline.\n\n<div class='warning-box'><p>All variables referenced in an expression must exist in the show's Variables panel. If an expression references an unknown variable, it will produce an error. WATCHOUT validates expressions when they are entered and reports any unknown references.\n</p></div>\n\n<h3>Interaction with Keyframes</h3>\n\n<p>Expressions and keyframes are not mutually exclusive — they work together:</p>\n\n<ul>\n<li>The keyframe curve is evaluated first to produce <code>tweenValue</code>.</li>\n<li>The expression is then evaluated with <code>tweenValue</code> available as a variable.</li>\n<li>The expression's result becomes the final output.</li>\n\n</ul>\nThis means you can use keyframes to define the base animation and an expression to modulate it. For instance, keyframes might define a smooth opacity fade from 0 to 100, while the expression <code>tweenValue * masterDim / 100</code> allows an external dimmer to scale the entire animation.\n\n<p>If you want the expression to completely replace the keyframe value, simply write an expression that doesn't reference <code>tweenValue</code> (e.g., just <code>myVariable</code>). In this case, the keyframe curve is still computed but its value is ignored.</p>\n\n<h3>Practical Examples</h3>\n\n<p><strong>Externally controlled opacity:</strong> Set the Opacity tween expression to <code>oscFader1</code> where <code>oscFader1</code> is a show variable mapped to an OSC input. A lighting console or control surface can now directly control the cue's opacity in real time.</p>\n\n<p><strong>Position tracking:</strong> Set the Position X expression to <code>trackerX</code> and Y expression to <code>trackerY</code>, where these variables come from a tracking system (via OSC or similar protocol). The cue follows the tracked object in real time.</p>\n\n<p><strong>Scaled animation:</strong> Keyframe a position animation along a path, then set the expression to <code>tweenValue * intensity / 100</code> where <code>intensity</code> is a variable. The animation plays its keyframed path but the displacement is scaled by the external value.</p>\n\n<h3>Relationship to Timeline Expressions</h3>\n\n<p>Tween expressions and <strong>timeline trigger expressions</strong> are different features that serve different purposes:</p>\n\n<ul>\n<li><strong>Tween expressions</strong> (this article) control the <strong>value</strong> of a tween property. They are evaluated continuously on every frame and produce a numeric result that drives a visual property (position, opacity, color, etc.).</li>\n<li><strong>Timeline trigger expressions</strong> (covered in the Timeline Triggers and Expressions article) control the <strong>playback state</strong> of a timeline. They are evaluated as boolean conditions that trigger play, pause, or stop actions on timelines.</li>\n\n</ul>\nBoth systems use the same expression language and can reference the same show variables, but they operate at different levels of the system."
    }
  },
  "8. Playback": {
    "overview": "<h1>PLAYBACK</h1>\n\n<p>Learn how to preview your show, connect to display servers, and run your presentation live.</p>",
    "sections": {
      "Starting and Stopping": "<h2>Starting and Stopping</h2>\n\n<p>Playback is controlled per timeline (or composition timeline) using run, pause, and stop states.</p>\n\n<h3>Primary Controls</h3>\n\n<table>\n<tr><th>Action</th><th>Shortcut</th></tr>\n<tr><td>Toggle play/pause</td><td><code>Spacebar</code></td></tr>\n<tr><td>Run timeline</td><td><code>Numpad 0</code> (or Numpad Insert)</td></tr>\n<tr><td>Pause timeline</td><td><code>Escape</code></td></tr>\n<tr><td>Jump to current/last start</td><td><code>Numpad *</code></td></tr>\n</table>\n\n<h3>UI Controls</h3>\n\n<p>Timeline windows provide explicit <strong>Play / Pause / Stop</strong> buttons. The active state is visually highlighted.</p>\n\n<h3>Operational Behavior</h3>\n\n<ul>\n<li><strong>Run</strong> starts playback from current timeline time (or defined start behavior).</li>\n<li><strong>Pause</strong> freezes at current position.</li>\n<li><strong>Stop</strong> ends playback and resets active state.</li>\n\n</ul>\n<h3>Good Practice</h3>\n\n<p>Before running live:</p>\n\n<ol>\n<li>Move play cursor to known start point.</li>\n<li>Confirm target timeline/composition is selected.</li>\n<li>Check that connected nodes/services are healthy.</li>\n\n</ol>",
      "Preview Mode": "<h2>Preview Mode</h2>\n\n<p>Preview mode lets you validate timing, transitions, and composition flow directly in Producer before committing to full system output.</p>\n\n<h3>What to Preview Locally</h3>\n\n<ul>\n<li>Cue timing and transitions</li>\n<li>Tween behavior and motion paths</li>\n<li>Layer and composition logic</li>\n<li>Basic content framing</li>\n\n</ul>\n<h3>Display Previews</h3>\n\n<p>WATCHOUT can fetch display preview images for subscribed displays while playback state updates, helping you verify remote output behavior from Producer.</p>\n\n<h3>Preview Limits</h3>\n\n<p>Preview is excellent for structure and timing, but final quality checks should still happen on target hardware for:</p>\n\n<ul>\n<li>Color accuracy</li>\n<li>Brightness/contrast</li>\n<li>Frame pacing under full show load</li>\n\n</ul>\n<h3>Recommended Process</h3>\n\n<ul>\n<li>Use local preview during programming.</li>\n<li>Rehearse on the real network/output path before showtime.</li>\n\n</ul>",
      "Connecting to Display Servers": "<h2>Connecting to Display Servers</h2>\n\n<p>In WATCHOUT 7, display servers are discovered nodes running Runner/renderer services. Producer uses discovered node metadata to route displays and monitor service health.</p>\n\n<h3>Discovery and Visibility</h3>\n\n<p>Nodes are discovered automatically over multicast and shown in the <strong>Network</strong> window with:</p>\n\n<ul>\n<li>Host alias</li>\n<li>Address</li>\n<li>Running services</li>\n<li>Version and status indicators</li>\n\n</ul>\n<h3>Typical Connection Workflow</h3>\n\n<ol>\n<li>Open <strong>Network</strong> window.</li>\n<li>Confirm target nodes are visible and not stale.</li>\n<li>Assign display devices to correct host aliases.</li>\n<li>Connect Producer to the intended Director.</li>\n\n</ol>\n<h3>If a Node Is Missing</h3>\n\n<ul>\n<li>Verify subnet/routing and multicast handling.</li>\n<li>Check local firewall policy.</li>\n<li>Confirm process-manager services are running on the node.</li>\n<li>Ensure host aliases are unique (except planned fallback scenarios).</li>\n\n</ul>",
      "Going Online": "<h2>Going Online</h2>\n\n<p>Operationally, going online means your show is actively controlled through a Director with reachable Runner and Asset Manager services.</p>\n\n<h3>Online Readiness Checklist</h3>\n\n<ul>\n<li>Producer is connected to the correct <strong>Director</strong></li>\n<li>Required nodes are discovered and healthy</li>\n<li>Asset Manager is reachable</li>\n<li>Displays are routed to expected hosts/channels</li>\n<li>Show state is saved</li>\n\n</ul>\n<h3>First Online Pass</h3>\n\n<p>Use a short verification pass:</p>\n\n<ol>\n<li>Run a known test timeline.</li>\n<li>Confirm visual outputs on all critical displays.</li>\n<li>Confirm audio/device-trigger behavior.</li>\n<li>Check for warnings in activity/log views.</li>\n\n</ol>\n<h3>Common Online Risks</h3>\n\n<ul>\n<li>Director/Runner mismatch (different loaded shows)</li>\n<li>Stale node aliases or duplicate names</li>\n<li>Asset transfer not complete before playback</li>\n\n</ul>\n<div class='warning-box'><p>Never assume online readiness from a single green indicator. Verify end-to-end output behavior.\n</p></div>",
      "Running Your Show": "<h2>Running Your Show</h2>\n\n<p>Running a show reliably is mostly about repeatable procedure. Build a fixed preflight and execution rhythm.</p>\n\n<h3>Preflight (Before Audience)</h3>\n\n<ul>\n<li>Confirm show file/version</li>\n<li>Confirm Director and Asset Manager hosts</li>\n<li>Confirm display routing and test image pass</li>\n<li>Confirm timeline start points and cue logic</li>\n<li>Confirm critical external outputs (if used)</li>\n\n</ul>\n<h3>Live Operation Pattern</h3>\n\n<ol>\n<li>Place play cursor at planned start.</li>\n<li>Run timeline.</li>\n<li>Monitor cue progression and node status.</li>\n<li>Use pause/jump controls only at rehearsed decision points.</li>\n\n</ol>\n<h3>During-Show Recovery Tactics</h3>\n\n<ul>\n<li>If timing drifts: pause, reposition cursor, and re-run from cue-safe point.</li>\n<li>If one node fails: continue if design allows, then recover during a planned hold.</li>\n<li>If output commands fail: verify network route and cue target settings.</li>\n\n</ul>\n<h3>Post-Show</h3>\n\n<ul>\n<li>Save an archival copy of the final show state.</li>\n<li>Export diagnostics/logs if any incident occurred.</li>\n<li>Document timeline or routing changes made during operation.</li>\n\n</ul>"
    }
  },
  "9. Network Setup": {
    "overview": "<h1>NETWORK SETUP</h1>\n\n<p>Configure your network for optimal WATCHOUT performance. Proper network setup is essential for synchronized multi-display playback.</p>",
    "sections": {
      "Network Overview": "<h2>Network Overview</h2>\n\n<p>WATCHOUT 7 is a distributed system where Producer coordinates Director, Runner, and Asset Manager services across the network.</p>\n\n<h3>Core Service Groups</h3>\n\n<p>From the process-manager architecture:</p>\n\n<ul>\n<li><strong>Director group</strong>: Director, Operative, Loki</li>\n<li><strong>Runner group</strong>: Runner, Visual Renderer, Audio Renderer</li>\n<li><strong>Asset Manager group</strong>: Asset services for media distribution</li>\n\n</ul>\n<h3>Discovery Model</h3>\n\n<p>Nodes discover each other automatically over multicast.</p>\n\n<p>Key details:</p>\n\n<ul>\n<li>Multicast group: <code>239.2.2.2</code></li>\n<li>Discovery port: <code>3012/UDP</code></li>\n<li>Nodes announce on startup and on service/show changes</li>\n\n</ul>\n<h3>Network Design Recommendations</h3>\n\n<ul>\n<li>Keep show-critical nodes on a stable wired network.</li>\n<li>Use predictable host aliases.</li>\n<li>Avoid duplicate host names unless implementing intentional fallback patterns.</li>\n<li>Keep network latency and jitter low for synchronized playback.</li>\n\n</ul>",
      "Display Servers": "<h2>Display Servers</h2>\n\n<p>A display server node is typically a Runner system responsible for rendering and output.</p>\n\n<h3>Runner Responsibilities</h3>\n\n<p>Runner-side services typically include:</p>\n\n<ul>\n<li>Visual rendering</li>\n<li>Audio rendering</li>\n<li>Runtime show execution received from Director</li>\n\n</ul>\n<h3>Setup Checklist</h3>\n\n<ol>\n<li>Install WATCHOUT node software.</li>\n<li>Confirm node appears in Network discovery.</li>\n<li>Verify required services are running.</li>\n<li>Route display devices to that node via host alias.</li>\n\n</ol>\n<h3>Operational Notes</h3>\n\n<ul>\n<li>If Director changes, runners can be reassigned by host reference.</li>\n<li>Keep one active show context per runner for predictable behavior.</li>\n<li>Mixed-show states between Director and Runner should be treated as warnings.</li>\n<li>Use host <strong>Actions</strong> for maintenance workflows such as startup action, sync mode, update, and restart.</li>\n\n</ul>",
      "Connecting Devices": "<h2>Connecting Devices</h2>\n\n<p>In WATCHOUT, devices (displays, audio devices, capture sources) are bound to discovered node aliases.</p>\n\n<h3>Connection Principles</h3>\n\n<ul>\n<li>Device routing uses <strong>host references/aliases</strong> rather than fixed IP assumptions.</li>\n<li>Discovery updates dynamically as nodes appear/disappear.</li>\n<li>Producer can assign Director and Asset Manager roles to selected nodes.</li>\n\n</ul>\n<h3>Best Practices</h3>\n\n<ul>\n<li>Give each node a unique, descriptive alias.</li>\n<li>Keep aliases stable across rehearsals and show days.</li>\n<li>Reserve duplicate aliases only for intentional failover strategy.</li>\n\n</ul>\n<h3>Validation Workflow</h3>\n\n<ol>\n<li>Confirm node visible in Network view.</li>\n<li>Assign device host alias.</li>\n<li>Verify service state on that node.</li>\n<li>Run test cue and confirm physical output.</li>\n\n</ol>",
      "Firewall Configuration": "<h2>Firewall Configuration</h2>\n\n<p>WATCHOUT installer scripts create inbound firewall rules for required network behavior and executables.</p>\n\n<h3>Important UDP Ports</h3>\n\n<table>\n<tr><th>Port</th><th>Purpose</th></tr>\n<tr><td><code>123</code></td><td>NTP time sync</td></tr>\n<tr><td><code>3011</code></td><td>Multicast query channel</td></tr>\n<tr><td><code>3012</code></td><td>Multicast/discovery channel</td></tr>\n</table>\n\n<h3>Service Port Reference</h3>\n\n<p>Protocol definitions include service ports such as:</p>\n\n<ul>\n<li><code>3017</code> Process Manager</li>\n<li><code>3018</code> Runner</li>\n<li><code>3019</code> Operative External</li>\n<li><code>3020</code> Operative Internal</li>\n<li><code>3021</code> Director</li>\n<li><code>3022</code> Loki</li>\n<li><code>3023</code> Asset Server</li>\n<li><code>8000</code> OSC</li>\n\n</ul>\n<h3>Program-Based Rules</h3>\n\n<p>The installer also allows inbound traffic for core executables, including:</p>\n\n<ul>\n<li><code>producer.exe</code></li>\n<li><code>director.exe</code></li>\n<li><code>runner.exe</code></li>\n<li><code>visualrenderer.exe</code></li>\n<li><code>audiorenderer.exe</code></li>\n<li><code>asset-server.exe</code></li>\n<li><code>ptp.exe</code></li>\n<li><code>mDNSResponder.exe</code></li>\n\n</ul>\n<h3>Deployment Advice</h3>\n\n<ul>\n<li>Prefer installer-created rules first.</li>\n<li>If using strict enterprise policy, mirror both UDP port rules and program rules.</li>\n<li>Re-validate after upgrades or path changes.</li>\n\n</ul>\n<div class='warning-box'><p>Partial firewall openings often cause intermittent discovery or sync failures that are hard to diagnose during live operation.\n</p></div>",
      "NDI Video Sources": "<h2>NDI Video Sources</h2>\n\n<p>WATCHOUT 7 supports NDI for both ingest and output workflows.</p>\n\n<h3>NDI Input Workflow</h3>\n\n<ul>\n<li>Add an NDI capture/source in Producer.</li>\n<li>Select the stream by discovered NDI source name.</li>\n<li>Use it like other media cues in timeline and stage workflows.</li>\n\n</ul>\n<h3>NDI Output Workflow</h3>\n\n<p>Displays can use <strong>NDI</strong> as output type, enabling network video feeds to downstream systems.</p>\n\n<h3>Calibration and Integration</h3>\n\n<p>Display properties include an <strong>NDI calibration stream</strong> field for specific calibration and workflow integrations.</p>\n\n<h3>Reliability Tips</h3>\n\n<ul>\n<li>Keep NDI traffic on robust switched infrastructure.</li>\n<li>Avoid saturated links on mixed control/media VLANs.</li>\n<li>Validate source frame format and timing before show-critical use.</li>\n\n</ul>",
      "Dante Audio": "<h2>Dante Audio</h2>\n\n<p>WATCHOUT supports Dante as an audio device type for networked professional audio routing.</p>\n\n<h3>Dante Device Configuration</h3>\n\n<p>In audio device properties, choose:</p>\n\n<ul>\n<li><strong>Device Type</strong>: <code>Dante</code></li>\n<li><strong>Adapter</strong>: selected Dante interface</li>\n<li><strong>Channel count</strong>: based on design requirements</li>\n<li><strong>Sample format / latency</strong> as needed</li>\n\n</ul>\n<h3>Infrastructure Considerations</h3>\n\n<p>Dante workflows rely on stable timing and discovery services.</p>\n\n<p>In WATCHOUT deployments, related components include:</p>\n\n<ul>\n<li>PTP service (<code>ptp.exe</code>)</li>\n<li>mDNS responder (<code>mDNSResponder.exe</code>)</li>\n\n</ul>\n<h3>Recommended Practice</h3>\n\n<ul>\n<li>Keep Dante on deterministic wired networking.</li>\n<li>Validate adapter/channel mapping during preflight.</li>\n<li>Perform full audio-path checks after any node or switch change.</li>\n\n</ul>",
      "Node Management and Maintenance": "<h2>Node Management and Maintenance</h2>\n\n<p>Node maintenance actions are available in host/device properties under <strong>Network Actions</strong>.</p>\n\n<h3>Accessing Node Actions</h3>\n\n<ol>\n<li>Open <strong>Window → Devices</strong>.</li>\n<li>Select a host in the Network pane.</li>\n<li>Open <strong>Properties</strong>.</li>\n<li>Use the <strong>Actions</strong> section.</li>\n\n</ol>\nSome actions are restricted to single-node selection.\n\n<h3>Service and Startup Actions</h3>\n\n<p>Available workflows include:</p>\n\n<ul>\n<li><strong>Restart Services</strong> (resets WATCHOUT services and returns to splash-ready state)</li>\n<li><strong>Startup Action</strong> configuration</li>\n<li>Upload/remove local startup show entries</li>\n\n</ul>\nStartup action modes:\n\n<table>\n<tr><th>Mode</th><th>Behavior</th></tr>\n<tr><td><strong>No Show</strong></td><td>Node starts without loading a local show</td></tr>\n<tr><td><strong>Last Show</strong></td><td>Node starts with the most recently active local show</td></tr>\n<tr><td><strong>Specific Show</strong></td><td>Node starts with a selected uploaded show</td></tr>\n</table>\n\n<h3>Asset Cache Maintenance</h3>\n\n<p>Use <strong>Local Asset Cache</strong> to:</p>\n\n<ul>\n<li>Inspect cached local asset copies on a node</li>\n<li>Remove assets not used by the current show (<strong>Remove Unused Local Assets</strong>)</li>\n\n</ul>\nUse cleanup carefully in multi-show environments to avoid breaking other productions sharing the same node.\n\n<h3>Sync and Software Operations</h3>\n\n<p>Node actions also include:</p>\n\n<ul>\n<li><strong>Sync Settings</strong> (WATCHOUT-managed vs user-managed sync mode)</li>\n<li><strong>Update Software</strong> to match Producer version</li>\n<li><strong>Restart</strong> / <strong>Shutdown</strong></li>\n<li><strong>Switch to WATCHOUT 6</strong> (where supported)</li>\n\n</ul>\n<h3>Identity and Storage Actions</h3>\n\n<p>Maintenance tools include:</p>\n\n<ul>\n<li><strong>Rename</strong> node alias</li>\n<li><strong>Change Working Directory</strong></li>\n\n</ul>\nChanging working directory can invalidate local asset availability until assets are redistributed.\n\n<h3>Recommended Maintenance Sequence</h3>\n\n<ol>\n<li>Confirm node identity and version.</li>\n<li>Apply startup action and sync policy.</li>\n<li>Clean cache only when safe for all shows on the node.</li>\n<li>Perform updates/restarts during controlled downtime.</li>\n<li>Re-check node status and show assignment after reboot.</li>\n\n</ol>",
      "Remote File Access": "<h2>Remote File Access</h2>\n\n<p>WATCHOUT allows Producer to browse, upload, and manage files on remote nodes across the network. This enables centralized management of distributed playback systems — you can push assets, configure watch folders, and browse directories on Runner machines directly from the Producer interface.</p>\n\n<p>For security, remote file access is controlled by an <strong>allow list</strong> that explicitly defines which directories on each node can be accessed remotely. Without this configuration, remote file browsing is blocked.</p>\n\n<h3>File Browser</h3>\n\n<p>The file browser dialog opens whenever a feature requires selecting a path on a remote node — for example, configuring an Asset Watcher folder or choosing an export destination. The dialog provides:</p>\n\n<ul>\n<li>A <strong>Roots</strong> view showing the top-level allowed directories on the remote node.</li>\n<li><strong>Navigation controls</strong> — an up-arrow button to navigate to the parent directory, a refresh button to reload the current listing, and a folder-plus button to create new folders.</li>\n<li>A <strong>table</strong> listing files and folders in the current directory, with double-click to open folders.</li>\n<li><strong>Select</strong> and <strong>Cancel</strong> buttons to confirm or dismiss the selection.</li>\n\n</ul>\nFolders that are listed in the allow list but do not actually exist on disk are shown with a disabled appearance and a \"Does not exist\" tooltip. These cannot be selected or navigated into.\n\n<h3>Allow List Configuration</h3>\n\n<p>The allow list is a JSON file that specifies which directories on a node are accessible for remote file operations.</p>\n\n<p><strong>File location:</strong> The file is named <code>allow_list.json</code> and is located in the same directory as the WATCHOUT Manager settings file (typically the WATCHOUT installation's settings directory).</p>\n\n<p><strong>File format:</strong> The file contains a JSON object with a <code>folders</code> array listing the permitted root paths:</p>\n\n<pre><code class=\"language-json\">{\n  &quot;folders&quot;: [\n    &quot;C:/shared/watchout/&quot;,\n    &quot;D:/shows/&quot;\n  ]\n}</code></pre>\n\n<p><strong>Subfolder access:</strong> Access is automatically granted to all subfolders of the specified paths. For example, if <code>D:/shows/</code> is in the allow list, then <code>D:/shows/my-project/assets/</code> is also accessible.</p>\n\n<p><strong>Path format:</strong> Paths can use either forward slashes (<code>/</code>) or backslashes (<code>\\</code>). The system normalizes paths internally.</p>\n\n<div class='warning-box'><p>After creating or modifying the <code>allow_list.json</code> file, you must <strong>restart Producer</strong> (including WATCHOUT Manager) for the changes to take effect. The allow list is read at startup and cached.\n</p></div>\n\n<h3>Setting Up Remote Access</h3>\n\n<p>When you attempt to access a remote node that has no allow list configured (or the requested path is not covered), WATCHOUT displays a <strong>Remote access needed</strong> dialog that walks you through the setup:</p>\n\n<ol>\n<li>Click <strong>Open allow list directory</strong> to navigate to the settings folder on the target node.</li>\n<li>Open the file named <code>allow_list.json</code> in a text editor, or create it if it doesn't exist.</li>\n<li>Add the required folder paths to the <code>folders</code> array.</li>\n<li>Save the file and restart Producer (including WATCHOUT Manager).</li>\n\n</ol>\nThe dialog also shows a pre-populated example JSON based on the path you tried to access.\n\n<div class='note-box'><p>On WATCHPAX hardware, a default allow list is automatically created with common drive letters (W:\\, D:\\ through H:\\), so remote file browsing works out of the box.\n</p></div>\n\n<h3>When Remote Access Is Required</h3>\n\n<p>Remote file access is needed for several operations:</p>\n\n<ul>\n<li><strong>Uploading assets</strong> — transferring media files from Producer to a remote node's storage.</li>\n<li><strong>Configuring Asset Watcher paths</strong> — selecting watch folders on remote Runner machines.</li>\n<li><strong>Browsing for startup show files</strong> — selecting a show file on a remote node for the auto-start feature.</li>\n<li><strong>Exporting and importing assets</strong> — selecting source or destination directories on remote nodes.</li>\n\n</ul>\n<h3>Error Handling</h3>\n\n<p>If you attempt to browse a node that does not permit remote access, you will see the error:</p>\n\n<p>> \"Remote file browsing is not allowed on [node name]\"</p>\n\n<p>This means either the <code>allow_list.json</code> file does not exist on the target node, or the requested path is not covered by any entry in the allow list. Follow the setup steps above to resolve it.</p>\n\n<p>If a path was allowed but the directory has since been removed from disk, the file browser shows it with a \"Does not exist\" indicator and prevents navigation.</p>\n\n<h3>Security Considerations</h3>\n\n<p>The allow list exists to prevent unintended exposure of a node's file system over the network. Best practices:</p>\n\n<ul>\n<li><strong>Limit access to necessary directories only</strong> — only add paths that WATCHOUT actually needs to access, such as show data directories and asset storage locations.</li>\n<li><strong>Avoid listing the root of system drives</strong> (e.g., <code>C:/</code>) unless absolutely necessary. Prefer more specific paths like <code>C:/shows/</code> or <code>D:/watchout-assets/</code>.</li>\n<li><strong>Review the allow list periodically</strong> — remove paths that are no longer needed after a project concludes.</li>\n\n</ul>",
      "Working Directory Management": "<h2>Working Directory Management</h2>\n\n<p>Every WATCHOUT node has a <strong>working directory</strong> — the location on disk where the node stores essential runtime data, including cached media assets, show files, and internal state. By default, WATCHOUT creates this directory automatically in a system-managed location relative to the installation path (a <code>.wo</code> subfolder).</p>\n\n<p>You can change the working directory on any node to redirect data storage to a different drive or partition — for example, a faster SSD or a larger data volume.</p>\n\n<h3>What the Working Directory Contains</h3>\n\n<p>The working directory stores:</p>\n\n<ul>\n<li><strong>Cached assets</strong> — local copies of media files downloaded from the Asset Manager for playback.</li>\n<li><strong>Show data</strong> — show files that have been loaded or uploaded to the node.</li>\n<li><strong>Runtime files</strong> — internal state and temporary data used by WATCHOUT services.</li>\n\n</ul>\nAll of this data is tied to the working directory's location. If the directory changes, the node loses access to previously stored data at the old path.\n\n<h3>Changing the Working Directory</h3>\n\n<p>To change a node's working directory:</p>\n\n<ol>\n<li>Open the <strong>Nodes</strong> window and select the target node.</li>\n<li>In <strong>Node Properties</strong>, locate the <strong>Working Directory</strong> section.</li>\n<li>Click the change button to open the <strong>Change Working Directory</strong> dialog.</li>\n<li>Enter the new path or browse to select it.</li>\n<li>Confirm the change.</li>\n\n</ol>\nThe dialog displays the following important warnings:\n\n<ul>\n<li>The specified path must be an <strong>existing directory</strong> on the selected node. WATCHOUT validates that the path exists before accepting it.</li>\n<li><strong>All assets used in the show will no longer be available.</strong> The cached asset copies at the old location are not moved — they remain on disk but are no longer referenced.</li>\n<li><strong>Some error messages will appear</strong> temporarily as the connection to the old asset manager storage is lost and re-established at the new location.</li>\n\n</ul>\n<div class='warning-box'><p>Changing the working directory means all previously cached assets must be <strong>re-transferred</strong> from the Asset Manager. This can take significant time depending on the size of your asset library and network speed. Plan this operation for a maintenance window, not during a live show.\n</p></div>\n\n<h3>Resetting to Default</h3>\n\n<p>To reset a node's working directory to the default system-managed location, click the <strong>Reset to Default</strong> button in the Working Directory section of Node Properties. The default location is a <code>.wo</code> subfolder relative to the WATCHOUT installation path.</p>\n\n<p>The same warnings about asset availability apply when resetting to default — assets cached at the custom location will need to be re-transferred.</p>\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Moving to a faster or larger drive</strong> — if the default system drive has limited space or slower I/O, point the working directory to a dedicated high-performance SSD or a larger data volume.</li>\n<li><strong>Separating show data across storage volumes</strong> — keep the operating system and WATCHOUT installation on one drive, and all show/asset data on a separate data drive for easier backup and management.</li>\n<li><strong>Standardizing paths across a fleet</strong> — in multi-node installations, set the same working directory path (e.g., <code>D:\\watchout-data</code>) on all Runner machines for consistency.</li>\n\n</ul>\n<h3>Troubleshooting</h3>\n\n<p>If the working directory path becomes invalid (e.g., the target drive is removed), WATCHOUT will attempt to fall back to the default location. If neither the configured path nor the default path is available, the Process Manager will log an error and may be unable to start services.</p>\n\n<p>To recover, either restore the target drive or reset the working directory by editing the WATCHOUT Manager settings file directly on the affected node.</p>",
      "Software Updates": "<h2>Software Updates</h2>\n\n<p>WATCHOUT provides a built-in mechanism for pushing software updates from Producer to remote nodes over the network. This ensures all nodes in a production run the same software version, which is essential for protocol compatibility and consistent behavior across the system.</p>\n\n<h3>Why Version Alignment Matters</h3>\n\n<p>All WATCHOUT nodes (Runners, Director, Operative, Asset Manager) communicate using internal protocols that evolve with each software release. When nodes run different versions, protocol mismatches can cause communication failures, missing features, or unexpected behavior. Keeping all nodes at the same version eliminates these risks.</p>\n\n<h3>Version Mismatch Indicators</h3>\n\n<p>WATCHOUT displays a visual warning indicator on any node in the <strong>Nodes</strong> window that is running a different software version than your Producer. The tooltip reads: \"Warning: Not the same software version as your Producer.\" This makes it easy to identify nodes that need updating at a glance.</p>\n\n<p>Each node's current version is reported in its <strong>Node Properties</strong> panel under the <strong>Info</strong> section.</p>\n\n<h3>Initiating an Update</h3>\n\n<p>To push an update to one or more nodes:</p>\n\n<ol>\n<li>Open the <strong>Nodes</strong> window.</li>\n<li>Select the target node(s) you want to update.</li>\n<li>Click <strong>Update Software</strong> in the Node Properties panel (or use the corresponding action in the node context menu).</li>\n<li>A confirmation dialog appears asking: \"Would you like to update the WATCHOUT version of the selected nodes?\"</li>\n<li>Confirm to begin the update.</li>\n\n</ol>\n<div class='warning-box'><p>The node will <strong>restart</strong> after a successful installation. During the restart, the node is temporarily inaccessible and any active playback on that node will be interrupted. Additionally, manual actions may be required to start WATCHOUT Manager on the node after the update.\n</p></div>\n\n<h3>Update Process</h3>\n\n<p>When you confirm the update, the following occurs:</p>\n\n<ol>\n<li><strong>File transfer</strong> — Producer transfers the update package to the target node over the network.</li>\n<li><strong>Installation</strong> — the update is installed on the target node, replacing the existing WATCHOUT software.</li>\n<li><strong>Automatic restart</strong> — the node restarts its services (or the entire machine, depending on the update).</li>\n<li><strong>Reconnection</strong> — after the restart, the node reappears in the Nodes window. Verify that it now reports the same version as your Producer.</li>\n\n</ol>\n<h3>Switching to WATCHOUT 6</h3>\n\n<p>For installations that need to revert to WATCHOUT 6 operation, WATCHOUT provides a <strong>Switch to WATCHOUT 6</strong> option:</p>\n\n<ol>\n<li>Select the target node(s) in the Nodes window.</li>\n<li>Click <strong>Switch to WATCHOUT 6</strong> in the Node Properties actions.</li>\n<li>Confirm the dialog: \"Do you want to switch the selected nodes to use WATCHOUT 6? This will restart the machine(s).\"</li>\n<li>The node will reconfigure its NTP settings and perform a <strong>full machine restart</strong> to activate WATCHOUT 6.</li>\n\n</ol>\n<div class='note-box'><p>Switching to WATCHOUT 6 is a machine-level operation that triggers a full reboot, not just a service restart. The machine must have WATCHOUT 6 software already installed.\n</p></div>\n\n<h3>Best Practices</h3>\n\n<ul>\n<li><strong>Update during controlled downtime</strong> — never update nodes during a live show. Schedule updates for maintenance windows when playback interruption is acceptable.</li>\n<li><strong>Update all nodes at once</strong> — select all nodes that need updating and push the update simultaneously to minimize the window of version mismatch.</li>\n<li><strong>Verify after update</strong> — after all nodes restart, check the Nodes window to confirm every node reports the same version and no version mismatch warnings remain.</li>\n<li><strong>Keep a backup installer</strong> — retain a copy of the previous version's installer in case you need to roll back.</li>\n\n</ul>",
      "Time Synchronization": "<h2>Time Synchronization</h2>\n\n<p>Frame-accurate multi-display playback is one of WATCHOUT's core capabilities, and it depends on all nodes sharing a precisely aligned clock. Without proper time synchronization, content on different Runner machines drifts apart — even a few milliseconds of offset can produce visible misalignment across adjacent displays.</p>\n\n<p>WATCHOUT uses <strong>NTP (Network Time Protocol)</strong> to synchronize the system clocks of all nodes in the network. The Windows Time Service (<code>w32time</code>) on each machine handles the actual clock adjustment.</p>\n\n<h3>Synchronization Modes</h3>\n\n<p>WATCHOUT offers two approaches to time sync management:</p>\n\n<p><strong>WATCHOUT-managed (default):</strong> WATCHOUT automatically configures the NTP settings on each node. One node acts as the NTP server (the time reference), and all other nodes are configured as NTP clients that synchronize to it. This is the simplest and recommended mode for most installations.</p>\n\n<p><strong>User-managed (Advanced):</strong> The operator manages NTP configuration externally, outside of WATCHOUT. In this mode, WATCHOUT does not modify the node's NTP settings. This is useful when the nodes are part of a larger infrastructure with its own time synchronization policy (e.g., a facility-wide NTP server).</p>\n\n<div class='warning-box'><p>User-managed mode includes a warning about potential synchronization issues. If your external NTP configuration is incorrect or if nodes synchronize to different time sources, playback drift will occur. Only use this mode if you are confident in your NTP setup.\n</p></div>\n\n<h3>Configuring Sync Mode</h3>\n\n<p>To change the synchronization mode:</p>\n\n<ol>\n<li>Open the <strong>Nodes</strong> window and select one or more nodes.</li>\n<li>In <strong>Node Properties</strong>, look for the <strong>Sync Settings</strong> option.</li>\n<li>The <strong>Sync Settings</strong> dialog presents two choices:</li>\n</ol>\n<ul>\n<li><strong>WATCHOUT</strong> — WATCHOUT controls time synchronization.</li>\n<li><strong>User</strong> — the operator controls time synchronization externally.</li>\n</ul>\n<ol>\n<li>Confirm your selection.</li>\n\n</ol>\nChanging the sync mode may require a <strong>service restart</strong> on the affected nodes.\n\n<h3>NTP Server Configuration</h3>\n\n<p>In Node Properties, the <strong>NTP Server</strong> field allows you to specify which NTP server the node should synchronize to.</p>\n\n<div class='info-box'><p>Leave the NTP Server field blank to keep the node's current NTP server configuration unchanged. This is useful when you want WATCHOUT to manage the sync mode but not override an existing NTP server setting.\n</p></div>\n\n<h3>Designating a Time Server</h3>\n\n<p>In a WATCHOUT-managed setup, one node should act as the authoritative time reference. When a node is designated as the WATCHOUT time source, its NTP diff display shows <strong>\"N/A (is WATCHOUT time source)\"</strong> instead of a numeric offset — because it is the reference against which all other nodes are measured.</p>\n\n<p>The time server node can itself synchronize to an external NTP source (such as <code>pool.ntp.org</code> or a facility GPS clock) for absolute time accuracy, or it can run as a free-running local clock.</p>\n\n<h3>Monitoring NTP Status</h3>\n\n<p>Each node displays an <strong>NTP Diff</strong> indicator in its node information, showing the time offset (in seconds) between that node's clock and the NTP reference. This is visible in:</p>\n\n<ul>\n<li>The <strong>Nodes</strong> window overview (as a compact status indicator).</li>\n<li>The <strong>Node Properties</strong> panel under the <strong>NTP</strong> section, which also shows the configured NTP server address.</li>\n\n</ul>\nUnder normal operation, the NTP diff should be very small (a few milliseconds or less). Larger offsets indicate synchronization problems.\n\n<h3>Automatic Resync</h3>\n\n<p>When the time offset on a node exceeds a safety threshold, WATCHOUT logs a warning: <strong>\"NTP offset is too high — resyncing.\"</strong> The system then triggers an automatic resynchronization to bring the node's clock back in line with the reference.</p>\n\n<p>This typically happens when a node has been offline for an extended period, when a network interruption delays NTP packets, or when the system clock has drifted due to hardware issues.</p>\n\n<h3>Multiple Producer Warning</h3>\n\n<p>Running multiple Producer instances on the same machine can affect time synchronization. When this condition is detected, WATCHOUT displays a warning:</p>\n\n<p>> \"Multiple Producer instances are running on this machine. This may affect time synchronization. For best results, run only one Producer per machine, or ensure all machines share the same NTP settings.\"</p>\n\n<p>The warning notes that delays may occur between time needle changes and updates when multiple instances compete for the same system clock.</p>\n\n<h3>Troubleshooting Sync Issues</h3>\n\n<p><strong>Symptom:</strong> Content on different displays appears offset by a consistent number of frames.</p>\n\n<p><strong>Diagnostic steps:</strong></p>\n\n<ol>\n<li>Open the <strong>Nodes</strong> window and check the <strong>NTP Diff</strong> value for each node. Values significantly above zero (e.g., more than 10ms) indicate a sync problem.</li>\n<li>Verify that all nodes are configured to synchronize to the <strong>same NTP server</strong>.</li>\n<li>Check that the NTP server node is reachable on <strong>UDP port 123</strong> from all client nodes.</li>\n<li>Ensure the Windows Time Service (<code>w32time</code>) is running on all nodes.</li>\n\n</ol>\n<strong>Resolutions:</strong>\n\n<ul>\n<li>If nodes show high NTP diff values, try restarting the Windows Time Service or triggering a manual resync.</li>\n<li>If using User-managed mode, verify your external NTP configuration is correct and that all nodes point to the same reference.</li>\n<li>Switch to WATCHOUT-managed mode for automatic configuration if your external NTP setup is unreliable.</li>\n<li>For hardware-level frame accuracy across multiple displays, consider using <strong>NVIDIA Quadro Sync</strong> (genlock/framelock) in addition to NTP synchronization.</li>\n\n</ul>"
    }
  },
  "10. External Control": {
    "overview": "<h1>EXTERNAL CONTROL</h1>\n\n<p>WATCHOUT 7 can be controlled by a wide range of external protocols and devices. This chapter covers all supported input protocols, bridge services, and API integrations for real-time show control.</p>",
    "sections": {
      "External Control Overview": "<h2>External Control Overview</h2>\n\n<p>WATCHOUT can be controlled by a wide range of external devices and systems — lighting consoles, show controllers, tracking systems, MIDI devices, timecode generators, and custom software. This chapter covers the external control architecture, the protocols WATCHOUT supports, and how they all connect to the show through a unified variable system.</p>\n\n<h3>Control Architecture</h3>\n\n<p>External control in WATCHOUT follows a layered architecture where signals from the outside world are received, converted into variable updates, and then distributed to all rendering nodes for real-time effect.</p>\n\n<p>The <strong>Operative</strong> is the central receiving point for most external protocols. It runs on the same machine as the Director and listens for incoming ArtNet, OSC, PosiStageNet, HTTP, and WATCHOUT 6 protocol messages. When a message arrives, the Operative converts it into a standardized internal format and forwards it to the Director.</p>\n\n<p>The <strong>Director</strong> is the authoritative coordinator. It receives variable updates from the Operative (and in some cases directly from bridge services like MIDI and LTC), validates values against variable definitions in the show, and broadcasts the updated state to all connected Runners via Server-Sent Events (SSE). Runners then apply the new values atomically to their rendering pipeline.</p>\n\n<p>Some protocols bypass the Operative and communicate directly with the Director. The <strong>MIDI Bridge</strong> and <strong>LTC Bridge</strong> are standalone services that each have their own connection to the Director — MIDI for variable input and show control, and LTC for timeline synchronization.</p>\n\n<h3>Variables as the Bridge</h3>\n\n<p>All external control ultimately maps to <strong>WATCHOUT variables</strong>. Variables are defined in the show file with properties like name, external key, value range, and interpolation mode. When an external signal arrives — whether it's a DMX channel value from ArtNet, an OSC float, or a position coordinate from a tracking system — it is matched to a variable by its <strong>external key</strong>, clamped to the variable's min/max range, and then made available for use throughout the show.</p>\n\n<p>Variables feed into <strong>tween expressions</strong> (allowing external values to drive visual properties like position, opacity, and rotation), <strong>conditional cues</strong> (enabling or disabling cues based on variable values), and <strong>timeline triggers</strong> (starting or stopping timelines in response to variable changes).</p>\n\n<p>This design means you don't need to learn different APIs for different protocols — every protocol writes to the same pool of variables, and you choose which protocol to use based on your production environment.</p>\n\n<h3>Supported Protocols</h3>\n\n<p>WATCHOUT supports the following external control protocols:</p>\n\n<ul>\n<li><strong>ArtNet</strong> — DMX-over-IP protocol for lighting console integration. Map DMX channel values from any ArtNet universe to WATCHOUT variables.</li>\n<li><strong>OSC (Open Sound Control)</strong> — A flexible, address-based protocol commonly used in media servers and show controllers. Supports both variable input and timeline playback control.</li>\n<li><strong>HTTP REST API</strong> — Programmatic control via standard HTTP requests. Includes endpoints for playback control, variable input, show management, hit testing, and real-time event streams (SSE).</li>\n<li><strong>MIDI Bridge</strong> — A standalone service that receives MIDI Control Change, Note, and Pitch Wheel messages and forwards them as variable updates. Also handles MIDI Show Control (MSC) messages.</li>\n<li><strong>LTC Bridge</strong> — A standalone service that decodes Linear Time Code from an audio input and synchronizes WATCHOUT timeline playback to the external timecode.</li>\n<li><strong>PosiStageNet (PSN)</strong> — A position tracking protocol that receives 3D spatial data (position, speed, orientation, acceleration) from tracking systems and maps it to variables.</li>\n<li><strong>MIDI Show Control (MSC)</strong> — An industry-standard protocol for show equipment control, supporting GO, STOP, GO OFF, and RESET commands for timeline management.</li>\n<li><strong>WATCHOUT 6 Protocol</strong> — A backward-compatible TCP control interface that accepts commands in the WATCHOUT 6 format, allowing existing integrations to work without modification.</li>\n\n</ul>\n<h3>Enabling and Disabling Protocols</h3>\n\n<p>Individual protocols can be enabled or disabled from the <strong>Network</strong> window in Producer. The available toggles include:</p>\n\n<ul>\n<li><strong>ArtNet</strong> — Enables/disables the ArtNet listener on the Operative.</li>\n<li><strong>OSC</strong> — Enables/disables the OSC listener (both UDP and TCP).</li>\n<li><strong>PosiStageNet</strong> — Enables/disables the PSN forwarder.</li>\n<li><strong>Web UI</strong> — Enables/disables the HTTP REST API and its built-in documentation interface.</li>\n<li><strong>WATCHOUT 7 Protocol</strong> — Enables/disables the native HTTP API endpoints.</li>\n<li><strong>WATCHOUT 6 Protocol</strong> — Enables/disables the backward-compatible TCP protocol.</li>\n\n</ul>\nThe MIDI Bridge and LTC Bridge are managed separately as individual services — they can be started or stopped from the Network window's node management.\n\n<div class='info-box'><p>Disable protocols you are not using to reduce network traffic and minimize the system's attack surface on public or shared networks.\n</p></div>\n\n<h3>Input Interpolation</h3>\n\n<p>To prevent visual glitches from sudden value changes, all external inputs pass through a <strong>50-millisecond interpolation window</strong> by default. This means that when a new value arrives, renderers smoothly transition from the old value to the new value over 50ms rather than jumping instantly.</p>\n\n<p>This interpolation happens transparently for all protocols:</p>\n\n<ul>\n<li><strong>ArtNet and OSC</strong> add the interpolation timestamp at the Operative before forwarding to the Director.</li>\n<li><strong>MIDI and other bridge services</strong> rely on the Director to apply the default 50ms interpolation.</li>\n<li><strong>HTTP REST API</strong> supports an optional <code>duration</code> parameter that lets you specify a custom interpolation time — from instant (0ms) to multi-second fades.</li>\n\n</ul>\nThe 50ms default provides smooth transitions without noticeable latency, striking a good balance for real-time control scenarios like fader movements and tracking data.\n\n<h3>Choosing a Protocol</h3>\n\n<p>The best protocol depends on your production environment:</p>\n\n<ul>\n<li><strong>Lighting desk integration</strong> → <strong>ArtNet</strong>. Lighting consoles natively speak DMX/ArtNet, making this the most natural choice for controlling WATCHOUT from a lighting desk.</li>\n<li><strong>Show controller or media server</strong> → <strong>OSC</strong> or <strong>HTTP REST API</strong>. OSC is ideal for systems like QLab, TouchOSC, or other show controllers. HTTP is better for custom software, web-based control panels, and scripted automation.</li>\n<li><strong>External timecode synchronization</strong> → <strong>LTC Bridge</strong>. When WATCHOUT playback must lock to an external SMPTE timecode source (audio/video playback, broadcast, multi-system sync), the LTC Bridge provides frame-accurate timeline synchronization.</li>\n<li><strong>Position tracking</strong> → <strong>PosiStageNet</strong>. For content that follows performers or objects on stage, PSN receives real-time position data from tracking systems like BlackTrax.</li>\n<li><strong>Existing WATCHOUT 6 integration</strong> → <strong>WATCHOUT 6 Protocol</strong>. If you have an existing Crestron, AMX, or other control system programmed for WATCHOUT 6, the backward-compatible TCP protocol lets it work with WATCHOUT 7 without changes.</li>\n<li><strong>Manual fader control</strong> → <strong>MIDI Bridge</strong>. Physical MIDI controllers with faders and knobs provide tactile, hands-on control of WATCHOUT variables.</li>\n<li><strong>Theatrical cue triggering</strong> → <strong>MIDI Show Control</strong>. MSC is the industry standard for triggering cues across multiple show control devices in theater and live event environments.</li>\n\n</ul>",
      "Variables and Inputs": "<h2>Variables and Inputs</h2>\n\n<p>Variables are the central mechanism through which all external control reaches WATCHOUT's rendering engine. Every external protocol — whether ArtNet, OSC, MIDI, HTTP, or any other — ultimately writes values to the same pool of show variables. These variables then drive tween expressions, conditional cues, and timeline triggers, making them the bridge between the outside world and what appears on screen.</p>\n\n<h3>The Variables Window</h3>\n\n<p>The <strong>Variables</strong> window in Producer is where you manage all show variables. From here you can:</p>\n\n<ul>\n<li><strong>Add</strong> new variables to the show.</li>\n<li><strong>Remove</strong> variables that are no longer needed.</li>\n<li><strong>Edit live values</strong> using sliders or direct numeric entry, allowing real-time preview of how a variable affects the show.</li>\n<li><strong>Save current values as defaults</strong> so that when the show is loaded or variables are reset, they return to a known state.</li>\n\n</ul>\nEach variable in the list displays its current value, external key assignment, and configured range.\n\n<h3>Variable Properties</h3>\n\n<p>Each variable has the following properties:</p>\n\n<ul>\n<li><strong>Name</strong> — The display name of the variable as it appears in the Variables window and in expression references. This is also the name used internally when matching render inputs.</li>\n<li><strong>External Key</strong> — The identifier that external protocols use to address this variable. For example, an OSC message sent to <code>/brightness/0</code> would match a variable whose external key is <code>osc.addr(/brightness/0)</code>. Each protocol has its own key format (described in the individual protocol articles).</li>\n<li><strong>Minimum Value</strong> — The lower bound of the variable's range. Incoming values below this are clamped.</li>\n<li><strong>Maximum Value</strong> — The upper bound of the variable's range. Incoming values above this are clamped.</li>\n<li><strong>Default Value</strong> — The value the variable takes when the show is first loaded or when variables are reset.</li>\n<li><strong>Interpolation Mode</strong> — How the variable transitions between values (see below).</li>\n\n</ul>\n<h3>External Keys and Learn Mode</h3>\n\n<p>The <strong>external key</strong> is what connects an incoming protocol message to a specific WATCHOUT variable. Different protocols generate keys in different formats:</p>\n\n<ul>\n<li><strong>OSC:</strong> <code>osc.addr(/your/address/0)</code> — derived from the OSC address pattern and argument index.</li>\n<li><strong>ArtNet:</strong> <code>artnet.net(0).subnet(0).uv(1).ch(10)</code> — specifies the DMX universe and channel.</li>\n<li><strong>MIDI:</strong> <code>midi.ch(0).cc(7)</code> — specifies the MIDI channel and control change number.</li>\n<li><strong>PosiStageNet:</strong> <code>psn.1.pos.x</code> — specifies the tracker ID and data field.</li>\n\n</ul>\nRather than manually typing these key strings, WATCHOUT provides a <strong>Learn</strong> mode. When Learn mode is active, you select a variable in the Variables window and then send a signal from your external device (move a fader, send an OSC message, etc.). WATCHOUT captures the incoming key and automatically assigns it to the selected variable. This eliminates guesswork about key format and ensures the mapping is correct.\n\n<h3>Input Flow</h3>\n\n<p>When an external signal arrives at WATCHOUT, it goes through the following processing chain:</p>\n\n<ol>\n<li><strong>Reception</strong> — The protocol handler (in the Operative or a bridge service) receives the raw message.</li>\n<li><strong>Key extraction</strong> — The handler converts the protocol-specific address into an external key string.</li>\n<li><strong>Matching</strong> — The Director matches the external key against all variables defined in the current show.</li>\n<li><strong>Clamping</strong> — The incoming value is clamped to the variable's configured min/max range.</li>\n<li><strong>Interpolation</strong> — The value is interpolated over the configured interpolation window (typically 50ms) to produce a smooth transition.</li>\n<li><strong>Distribution</strong> — The interpolated value is broadcast to all Runners, where it becomes available to tween expressions, conditional cue evaluations, and other variable consumers.</li>\n\n</ol>\nThis entire chain happens in real time with minimal latency, allowing responsive control of live visual content.\n\n<h3>Interpolation Modes</h3>\n\n<p>The interpolation mode determines how a variable transitions from its current value to a new incoming value:</p>\n\n<p><strong>None</strong> — The value jumps instantly to the new value with no transition. Use this for discrete state changes (e.g., switching between scenes, toggling visibility).</p>\n\n<p><strong>Linear</strong> — The value transitions linearly from the old value to the new value over the interpolation period. This is the most common mode and is suitable for most continuous parameters like opacity, position, and volume. A fader moving from 0 to 100 will produce a smooth, even ramp.</p>\n\n<p><strong>Circular</strong> — The value wraps around the min/max range, always taking the shortest path. This is designed for cyclic parameters like hue (0–360°) or rotation angles. For example, if a circular variable with range 0–360 transitions from 350 to 10, it will go forward through 360/0 (a 20-degree change) rather than backward through 180 (a 340-degree change).</p>\n\n<div class='info-box'><p>For most use cases, <strong>Linear</strong> interpolation is the best default. Use <strong>None</strong> only when you need instantaneous changes, and <strong>Circular</strong> specifically for angular or cyclic values.\n</p></div>\n\n<h3>Default Values</h3>\n\n<p>Each variable has a configurable default value. Defaults are applied in two situations:</p>\n\n<ul>\n<li><strong>Show load</strong> — When a show file is opened, all variables start at their default values.</li>\n<li><strong>Variable reset</strong> — When variables are explicitly reset (e.g., through a control command).</li>\n\n</ul>\nYou can update defaults at any time by adjusting variables to the desired values in the Variables window and then saving the current values as the new defaults. This is useful for establishing a known starting state for a show — for example, setting all opacity variables to 100% and all position offsets to 0.\n\n<h3>Using Variables in the Show</h3>\n\n<p>Once a variable receives a value from an external source, that value can be referenced throughout the show:</p>\n\n<ul>\n<li><strong>Tween expressions</strong> — Bind a cue's position, opacity, scale, rotation, or any other tweenable property to a variable. The property value updates in real time as the variable changes.</li>\n<li><strong>Conditional cues</strong> — Set a cue's visibility condition to depend on a variable value (e.g., show a cue only when <code>brightness > 50</code>).</li>\n<li><strong>Variable cues</strong> — Timeline-based automation that sets variable values at specific points during playback. See the Variable Cues section in Chapter 6 for details on driving variables from the timeline rather than from external input.</li>\n\n</ul>",
      "OSC Protocol": "<h2>OSC Protocol</h2>\n\n<p>Open Sound Control (OSC) is a flexible, message-based protocol widely used in media servers, show controllers, and creative applications. WATCHOUT's OSC integration allows you to send variable values and timeline playback commands from any OSC-capable device or software.</p>\n\n<h3>Enabling OSC</h3>\n\n<p>OSC support is enabled or disabled from the <strong>Network</strong> window in Producer using the <strong>OSC</strong> toggle. When enabled, the Operative listens for incoming OSC messages on both UDP and TCP.</p>\n\n<h3>Connection Details</h3>\n\n<p>WATCHOUT listens for OSC on two ports simultaneously:</p>\n\n<ul>\n<li><strong>UDP port 8000</strong> — Standard OSC over UDP. Most OSC controllers use this transport by default.</li>\n<li><strong>TCP port 8001</strong> — OSC over TCP with length-prefixed framing. Useful for reliable delivery over congested or lossy networks.</li>\n\n</ul>\nBoth ports bind to all network interfaces (<code>0.0.0.0</code>), so the Operative accepts OSC messages from any reachable device on the network.\n\n<h3>Variable Input via OSC</h3>\n\n<p>Any OSC message that does not match a playback control pattern (described below) is treated as a variable input. The OSC address and argument index are combined to form the external key that maps to a WATCHOUT variable.</p>\n\n<p>The key format is:</p>\n\n<p><code>osc.addr({address}/{argument_index})</code></p>\n\n<p>For example, sending an OSC message to address <code>/stage/brightness</code> with a single float argument produces the key:</p>\n\n<p><code>osc.addr(/stage/brightness/0)</code></p>\n\n<p>If the message carries multiple arguments, each argument gets its own key with an incrementing index:</p>\n\n<ul>\n<li>Argument 0: <code>osc.addr(/stage/color/0)</code></li>\n<li>Argument 1: <code>osc.addr(/stage/color/1)</code></li>\n<li>Argument 2: <code>osc.addr(/stage/color/2)</code></li>\n\n</ul>\n<h3>Supported Value Types</h3>\n\n<p>WATCHOUT accepts the following OSC argument types:</p>\n\n<ul>\n<li><strong>Float</strong> (<code>f</code>) — Used directly as the variable value.</li>\n<li><strong>Int</strong> (<code>i</code>) — Converted to a floating-point value.</li>\n\n</ul>\nOther OSC types (string, blob, etc.) are not supported and will produce an error if received.\n\n<h3>Playback Control via OSC</h3>\n\n<p>In addition to variable input, WATCHOUT supports timeline playback control through OSC messages with the <code>/wo/</code> address prefix. The supported patterns are:</p>\n\n<ul>\n<li><code>/wo/play/{timeline_id}</code> — Start playback of the specified timeline.</li>\n<li><code>/wo/run/{timeline_id}</code> — Same as play.</li>\n<li><code>/wo/pause/{timeline_id}</code> — Pause the specified timeline.</li>\n<li><code>/wo/stop/{timeline_id}</code> — Stop the specified timeline and reset to the beginning.</li>\n\n</ul>\nThe <code>timeline_id</code> is a numeric identifier (e.g., <code>1</code>, <code>2</code>).\n\n<p><strong>Jumping to a cue:</strong> Add a cue ID as an additional path segment:</p>\n\n<p><code>/wo/play/{timeline_id}/{cue_id}</code></p>\n\n<p>This starts playback from the specified cue's position.</p>\n\n<p><strong>Jumping to a time:</strong> Instead of a cue ID, you can include a time position as an OSC argument:</p>\n\n<ul>\n<li><strong>Float argument</strong> — Interpreted as seconds (e.g., <code>10.5</code> = 10 seconds 500 milliseconds).</li>\n<li><strong>Int argument</strong> — Interpreted as milliseconds (e.g., <code>10500</code> = 10 seconds 500 milliseconds).</li>\n\n</ul>\nFor example, sending <code>/wo/play/1</code> with a float argument of <code>5.0</code> starts timeline 1 at the 5-second mark.\n\n<div class='note-box'><p>OSC Bundles are not currently supported. Each message must be sent as an individual OSC message.\n</p></div>\n\n<h3>Interpolation</h3>\n\n<p>All OSC variable inputs are interpolated with the default <strong>50ms interpolation window</strong>. The Operative timestamps each incoming OSC message and includes a 50ms interpolation deadline when forwarding it to the Director. This ensures smooth, glitch-free transitions even when OSC messages arrive at irregular intervals.</p>\n\n<h3>Testing OSC</h3>\n\n<p>During development, you can test WATCHOUT's OSC input using tools such as:</p>\n\n<ul>\n<li><strong>TouchOSC</strong> — A mobile app for building custom OSC control surfaces.</li>\n<li><strong>Protokol</strong> — A monitoring tool that can also send OSC messages.</li>\n<li><strong>oscsend</strong> (command line) — A simple command-line utility for sending test messages.</li>\n<li>Any programming language with an OSC library (Python's <code>python-osc</code>, Node.js's <code>osc-js</code>, etc.).</li>\n\n</ul>\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>QLab integration</strong> — Send OSC cues from QLab to control WATCHOUT variables and trigger timeline playback.</li>\n<li><strong>TouchOSC / Lemur</strong> — Build custom tablet-based control interfaces with faders, buttons, and XY pads mapped to WATCHOUT variables.</li>\n<li><strong>Show control systems</strong> — Integrate with Medialon, Pharos, or other automation systems that output OSC.</li>\n<li><strong>Custom software</strong> — Control WATCHOUT from any application using standard OSC libraries.</li>\n\n</ul>",
      "MIDI Bridge": "<h2>MIDI Bridge</h2>\n\n<p>The MIDI Bridge is a standalone service that receives MIDI messages from a connected MIDI device and forwards them as variable updates to the WATCHOUT Director. It provides a straightforward way to use physical MIDI controllers — faders, knobs, buttons, and pitch wheels — for real-time control of show parameters.</p>\n\n<h3>Enabling the MIDI Bridge</h3>\n\n<p>The MIDI Bridge is managed as a service from the <strong>Network</strong> window in Producer. It can be started and stopped on any node that has MIDI input hardware (or a virtual MIDI driver) available.</p>\n\n<p>When the MIDI Bridge starts, it opens a configuration window where you can select the MIDI device, configure the Director target, and adjust settings.</p>\n\n<h3>Configuration</h3>\n\n<p>The MIDI Bridge configuration window provides the following settings:</p>\n\n<ul>\n<li><strong>MIDI Device</strong> — A dropdown listing all available MIDI input ports on the machine. Select the device you want to receive messages from. The selected device is saved in the bridge's settings file and restored automatically on restart.</li>\n<li><strong>Director IP</strong> — The IP address of the Director to send variable updates to. Defaults to <code>127.0.0.1</code> (localhost) for single-machine setups. Change this when the Director runs on a different machine.</li>\n<li><strong>Normalize</strong> — When enabled, MIDI values are normalized to a 0.0–1.0 range. When disabled, raw MIDI values are forwarded (e.g., 0–127 for Control Change, 0–16383 for Pitch Wheel). Normalization is convenient when your variables use a 0–1 range.</li>\n<li><strong>MSC Device ID</strong> — The MIDI Show Control Device ID used to filter incoming MSC messages. Only messages matching this Device ID (or the all-call ID <code>127</code>) are processed. See the MIDI Show Control article for details.</li>\n\n</ul>\n<h3>Supported Message Types</h3>\n\n<p>The MIDI Bridge handles the following MIDI message types:</p>\n\n<p><strong>Control Change (CC)</strong> — The most common type for faders and knobs. Each CC message generates a variable key in the format:</p>\n\n<p><code>midi.ch({channel}).cc({control_number})</code></p>\n\n<p>For example, moving CC #7 on MIDI channel 0 produces the key <code>midi.ch(0).cc(7)</code>.</p>\n\n<p><strong>Note On</strong> — Key presses on a MIDI keyboard or button pad. The velocity value is used as the variable value. Key format:</p>\n\n<p><code>midi.ch({channel}).note({note_number})</code></p>\n\n<p><strong>Note Off</strong> — Key releases. These produce a value of <code>0</code> for the same key as the corresponding Note On.</p>\n\n<p><strong>Pitch Wheel</strong> — The pitch bend wheel. A 14-bit value (0–16383) is generated with the key:</p>\n\n<p><code>midi.ch({channel}).pitch</code></p>\n\n<p><strong>MIDI Show Control (MSC)</strong> — SysEx messages conforming to the MSC specification are parsed and forwarded as show control commands (GO, STOP, GO OFF, RESET) rather than variable values. See the MIDI Show Control article for details.</p>\n\n<div class='note-box'><p>Other MIDI message types (Program Change, Aftertouch, System Exclusive other than MSC) are not processed by the MIDI Bridge.\n</p></div>\n\n<h3>How It Works</h3>\n\n<p>The MIDI Bridge operates independently from the Operative. When a MIDI message is received:</p>\n\n<ol>\n<li>The message is parsed and converted into the appropriate key/value format.</li>\n<li>For <strong>Control Change, Note, and Pitch Wheel</strong> messages: The bridge posts the values directly to the Director's <code>/v0/inputs</code> endpoint as JSON. The Director applies the default 50ms interpolation for smooth transitions.</li>\n<li>For <strong>MSC messages</strong>: The bridge posts the parsed MSC command to the Operative's <code>/v0/msc</code> endpoint, which handles timeline control.</li>\n\n</ol>\nMessages are batched and sent at a maximum rate of approximately 100 updates per second (10ms interval) to avoid overwhelming the Director with rapid MIDI changes.\n\n<h3>Hardware Requirements</h3>\n\n<p>The machine running the MIDI Bridge must have:</p>\n\n<ul>\n<li>A <strong>MIDI input device</strong> connected (USB MIDI interface, MIDI controller, or MIDI keyboard).</li>\n<li>Alternatively, a <strong>virtual MIDI driver</strong> (such as loopMIDI or IAC Driver) for receiving MIDI from software applications.</li>\n\n</ul>\nThe MIDI Bridge lists all available MIDI input ports on the system. If no ports appear, check that your MIDI device drivers are correctly installed.\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Fader-based control</strong> — Map physical faders on a MIDI controller to opacity, volume, or position variables for hands-on show control.</li>\n<li><strong>Button-triggered scenes</strong> — Use MIDI note buttons to switch between variable presets or trigger timeline actions.</li>\n<li><strong>DJ controller integration</strong> — Repurpose DJ MIDI controllers with their knobs, faders, and jog wheels to control visual parameters in real time.</li>\n<li><strong>Show control via MSC</strong> — Receive GO/STOP/RESET commands from a theatrical show control system that outputs MSC.</li>\n\n</ul>",
      "LTC Bridge": "<h2>LTC Bridge</h2>\n\n<p>The LTC Bridge is a standalone service that decodes Linear Time Code (LTC) from an audio input and uses it to synchronize WATCHOUT timeline playback to an external timecode source. This enables frame-accurate synchronization with external audio/video systems, broadcast workflows, and multi-system show environments.</p>\n\n<h3>What Is LTC?</h3>\n\n<p>Linear Time Code is a SMPTE timecode format encoded as an audio signal. It carries hours, minutes, seconds, and frames (HH:MM:SS:FF) information in a continuous audio stream, typically on a dedicated audio channel. LTC is widely used in broadcast, film, and live event production to synchronize multiple systems to a common time reference.</p>\n\n<h3>Enabling the LTC Bridge</h3>\n\n<p>The LTC Bridge is managed as a service from the <strong>Network</strong> window in Producer. It can be started and stopped on any node that has an audio input device available. When started, it opens a configuration window.</p>\n\n<h3>Configuration</h3>\n\n<p>The LTC Bridge configuration window provides the following settings:</p>\n\n<p><strong>Audio Host</strong> — Select the audio driver type: <ul> <li><strong>ASIO</strong> — Low-latency professional audio driver. Recommended for best performance.</li> <li><strong>WASAPI</strong> — Windows Audio Session API (shared mode).</li> <li><strong>WASAPI Exclusive</strong> — WASAPI in exclusive mode for lower latency.</li></p>\n\n</ul>\n<strong>Audio Device</strong> — Select the audio input device from the list of available devices for the chosen host type.\n\n<p><strong>Channel</strong> — Select which audio input channel carries the LTC signal. Most setups dedicate a specific channel (e.g., channel 1 or 2) to timecode.</p>\n\n<p><strong>Director IP</strong> — The IP address of the Director to send synchronization commands to. Defaults to localhost.</p>\n\n<p><strong>Timeline Selection</strong> — Select one or more timelines that should be synchronized to the incoming LTC. The bridge fetches the available timelines from the Director and presents them in a list. You can select multiple timelines to drive them all from the same timecode source.</p>\n\n<h3>How It Works</h3>\n\n<p>The LTC Bridge continuously decodes the audio stream from the selected input channel. When valid timecode frames are detected:</p>\n\n<ol>\n<li><strong>Timeline playback control</strong> — The bridge sends play/pause commands to the Director to start or stop the selected timelines. When the LTC signal is present and running, timelines play. When the signal stops or becomes invalid for more than 100ms, timelines are paused.</li>\n<li><strong>Continuous synchronization</strong> — Every second, the bridge sends a timeline sync message to the Director containing the current timecode position and the time dilation (speed relationship between the LTC source and WATCHOUT's internal clock). This keeps WATCHOUT's playback position locked to the external timecode even if clocks drift slightly.</li>\n<li><strong>State change detection</strong> — The bridge detects LTC state changes (new sequences, pauses, stops) and responds appropriately — starting playback when timecode begins, pausing when it stops, and resyncing when a new sequence is detected.</li>\n\n</ol>\nThe configuration window displays real-time feedback:\n\n<ul>\n<li><strong>Timecode display</strong> — Shows the current decoded timecode in HH:MM:SS.FF format.</li>\n<li><strong>FPS indicator</strong> — Shows the detected frame rate (e.g., 24, 25, 29.97, 30 fps).</li>\n<li><strong>Drop frame flag</strong> — Indicates whether drop-frame timecode is detected.</li>\n<li><strong>Volume meter</strong> — Shows the audio input level, helping you verify that the LTC signal is reaching the decoder at an adequate level.</li>\n<li><strong>Valid indicator</strong> — Shows whether the decoder is currently receiving valid LTC frames.</li>\n\n</ul>\n<div class='warning-box'><p>If the volume meter shows no signal or very low levels, the LTC decoder will not be able to extract timecode. Ensure the audio input is correctly routed and the signal level is adequate.\n</p></div>\n\n<h3>Multiple Instances</h3>\n\n<p>You can run multiple LTC Bridge instances with different instance names, each listening to a different audio input and driving different timelines. This is useful in complex setups where different parts of a show are synchronized to different timecode sources.</p>\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Broadcast synchronization</strong> — Lock WATCHOUT playback to the master timecode from a broadcast facility's timecode generator.</li>\n<li><strong>Multi-system synchronization</strong> — Synchronize WATCHOUT with other media servers, lighting consoles, or audio systems that all share a common SMPTE timecode source.</li>\n<li><strong>Pre-recorded show playback</strong> — Play back a show in sync with a pre-recorded audio track that carries LTC on one channel.</li>\n<li><strong>Film and video post-production</strong> — Synchronize visual content with video editing systems using timecode.</li>\n\n</ul>\n<h3>Troubleshooting</h3>\n\n<p><strong>No timecode detected:</strong> <ul> <li>Verify the correct audio device and channel are selected.</li> <li>Check the volume meter — ensure the LTC signal is present and at an adequate level.</li> <li>Try switching between ASIO and WASAPI if one driver type doesn't detect the signal.</li></p>\n\n</ul>\n<strong>Timecode detected but playback doesn't start:</strong>\n<ul>\n<li>Ensure at least one timeline is selected in the Timeline Selection list.</li>\n<li>Verify the Director IP is correct and the Director is running.</li>\n\n</ul>\n<strong>Playback drifts over time:</strong>\n<ul>\n<li>This is usually caused by clock differences. The bridge compensates with periodic sync messages, but very large drift may indicate an unreliable audio clock. Using ASIO drivers typically provides the most stable timing.</li>\n\n</ul>",
      "HTTP REST API": "<h2>HTTP REST API</h2>\n\n<p>WATCHOUT exposes a comprehensive HTTP REST API for programmatic control from external systems. The API provides endpoints for timeline playback control, variable input, show management, hit testing, cue set state management, and real-time event streams. It is the most feature-complete external control interface available in WATCHOUT.</p>\n\n<h3>Base URL and Port</h3>\n\n<p>The API is served by the Operative on <strong>port 3019</strong>. The base URL is:</p>\n\n<p><code>http://{host}:3019</code></p>\n\n<p>Replace <code>{host}</code> with the IP address or hostname of the machine running the Operative. For local access, use <code>localhost</code> or <code>127.0.0.1</code>.</p>\n\n<p>The API is enabled or disabled from the <strong>Network</strong> window using the <strong>WATCHOUT 7 Protocol</strong> and <strong>Web UI</strong> toggles.</p>\n\n<h3>Interactive API Documentation</h3>\n\n<p>WATCHOUT includes built-in interactive API documentation powered by RapiDoc. Access it at:</p>\n\n<p><code>http://{host}:3019/test</code></p>\n\n<p>This page provides a browsable interface for all endpoints, including request/response schemas, example payloads, and the ability to send test requests directly from the browser. The underlying OpenAPI specification is available at <code>/api-docs/openapi.json</code>.</p>\n\n<h3>Playback Control</h3>\n\n<p><strong>Play a timeline:</strong> <code>POST /v0/play/{timeline_id}</code></p>\n\n<p><strong>Pause a timeline:</strong> <code>POST /v0/pause/{timeline_id}</code></p>\n\n<p><strong>Stop a timeline</strong> (resets to beginning): <code>POST /v0/stop/{timeline_id}</code></p>\n\n<p><strong>Jump to a specific time:</strong> <code>POST /v0/jump-to-time/{timeline_id}?time={ms}&state={play|pause}</code></p>\n\n<p>The <code>time</code> parameter is in milliseconds. The optional <code>state</code> parameter controls whether the timeline plays or pauses after jumping (default: <code>pause</code>).</p>\n\n<p><strong>Jump to a specific cue:</strong> <code>POST /v0/jump-to-cue/{timeline_id}/{cue_id}?state={play|pause}</code></p>\n\n<p>Jumps to the start time of the specified cue. The optional <code>state</code> parameter works the same as jump-to-time.</p>\n\n<p><strong>Get playback state:</strong> <code>GET /v0/state</code></p>\n\n<p>Returns the current playback state for all timelines, including positions and play/pause status.</p>\n\n<h3>Variable Input</h3>\n\n<p><strong>Set multiple variables (batch):</strong> <code>POST /v0/inputs</code></p>\n\n<p>Request body is a JSON array of input objects:</p>\n\n<p>``<code>json path=null start=null [   {\"key\": \"brightness\", \"value\": 100.0, \"duration\": 2000},   {\"key\": \"volume\", \"value\": 0.5} ] <pre><code class=\"language-text\">Each object has:\n- `key` (string, required) — The external key matching a WATCHOUT variable.\n- `value` (number, required) — The numeric value to set.\n- `duration` (number, optional) — Interpolation duration in milliseconds. If omitted, the default 50ms interpolation is used.\n\n**Set a single variable:**\n`POST /v0/input/{key}?value={number}&amp;duration={ms}`\n\nA simpler endpoint for setting one variable at a time via URL parameters.\n\n**Get all variables:**\n`GET /v0/inputs`\n\nReturns a map of all input variable specifications including their external keys, value ranges, and defaults.\n\n### Show Management\n\n**Get current show:**\n`GET /v0/show`\n\nReturns the complete show data including timelines, cues, inputs, and revision information.\n\n**Upload show (JSON):**\n`POST /v0/show`\n\nUpload a new show in JSON format. Replaces the currently loaded show.\n\n**Upload show (binary):**\n`POST /v0/showfile`\n\nUpload a complete show file in WATCHOUT binary format.\n\n**Get timelines:**\n`GET /v0/timelines`\n\nReturns all timelines with their names and IDs.\n\n**Get cues for a timeline:**\n`GET /v0/cues/{timeline_id}`\n\nReturns all cues for a specific timeline including names and IDs.\n\n### Cue Set State Management\n\nCue sets (also called cue groups) can be switched via the API:\n\n**By ID:**\n- `POST /v0/cue-group-state/by-id/{group_id}/{variant_id}` — Set a single group.\n- `POST /v0/cue-group-state/by-id` — Set multiple groups (JSON body mapping group IDs to variant IDs).\n- `GET /v0/cue-group-state/by-id` — Get current states.\n\n**By name:**\n- `POST /v0/cue-group-state/by-name/{group_name}/{variant_name}` — Set a single group.\n- `POST /v0/cue-group-state/by-name` — Set multiple groups (JSON body mapping group names to variant names).\n- `GET /v0/cue-group-state/by-name` — Get current states.\n\n### Hit Testing\n\n`POST /v0/hittest`\n\nTests whether a coordinate point hits any of the specified cues. This is useful for interactive installations where user input (touch, pointer, etc.) needs to determine which visual element was selected.\n\nRequest body:</code></pre>json path=null start=null {   \"cues\": [\"1/42\", \"1/43\"],   \"x\": 960.0,   \"y\": 540.0 } </code>`<code></p>\n\n<p>The response lists which cues contain the point. Hit testing evaluates all tweens (position, scale, rotation, corner pinning) at the current playback time for accurate results with animated content.</p>\n\n<div class='note-box'><p>Hit testing only supports visual media cues on timelines. Audio, control, output, variable, and comment cues are not supported. Cues with conditional rendering are also rejected.\n</p></div>\n\n<h3>Real-Time Event Streams</h3>\n\n<p>WATCHOUT provides Server-Sent Events (SSE) and Newline-Delimited JSON (NDJSON) streams for receiving real-time updates:</p>\n\n<p><strong>SSE endpoints:</strong> <ul> <li></code>/v0/sse<code> — Legacy event stream.</li> <li></code>/v1/sse<code> — Includes initial state on connect, excludes countdown and diff events.</li> <li></code>/v2/sse<code> — Optimized stream with diff-based playback updates and interpolated variable values.</li></p>\n\n</ul>\n<strong>NDJSON endpoints:</strong>\n<ul>\n<li></code>/v0/ndjson<code>, </code>/v1/ndjson<code>, </code>/v2/ndjson<code> — Same event data as their SSE counterparts, delivered as newline-delimited JSON.</li>\n\n</ul>\nThe event streams emit the following event types:\n<ul>\n<li><strong>PlaybackState</strong> — Current playback state for all timelines.</li>\n<li><strong>Inputs</strong> — Variable value changes.</li>\n<li><strong>ShowRevision</strong> — Notifications when the show is updated.</li>\n<li><strong>TimelineCountdowns</strong> — Countdown information for upcoming cues.</li>\n<li><strong>CueVisibility</strong> — Cue enter/exit events.</li>\n\n</ul>\nThe v1 and v2 streams include the initial show state when a client connects, making them suitable for dashboards and monitoring applications.\n\n<h3>System Information</h3>\n\n<p></code>GET /info<code></p>\n\n<p>Returns build information about the WATCHOUT system.</p>\n\n<h3>Authentication</h3>\n\n<p>The HTTP API does not require authentication by default. All endpoints are accessible to any client that can reach the Operative's port. If the API is exposed on an untrusted network, consider using firewall rules to restrict access.</p>\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Web-based control panels</strong> — Build browser-based dashboards that monitor and control WATCHOUT playback using the REST API and SSE streams.</li>\n<li><strong>Custom automation scripts</strong> — Use </code>curl<code>, Python </code>requests`, or any HTTP client to script show control sequences.</li>\n<li><strong>Interactive installations</strong> — Combine hit testing with variable input to create touch-reactive or pointer-reactive experiences.</li>\n<li><strong>Third-party integration</strong> — Connect show control systems, building management systems, or IoT platforms that speak HTTP/JSON.</li>\n\n</ul>",
      "ArtNet Input": "<h2>ArtNet Input</h2>\n\n<p>WATCHOUT can receive ArtNet DMX data over the network and map incoming DMX channel values to show variables. This allows lighting consoles, DMX controllers, and other ArtNet-capable devices to directly control media server parameters like opacity, position, color, and any other variable-driven property.</p>\n\n<h3>Enabling ArtNet</h3>\n\n<p>ArtNet input is enabled or disabled from the <strong>Network</strong> window in Producer using the <strong>ArtNet</strong> toggle. When enabled, the Operative listens for ArtNet packets on the standard ArtNet port.</p>\n\n<h3>External Key Format</h3>\n\n<p>ArtNet variables use a structured external key format that specifies the DMX universe and channel address:</p>\n\n<p><code>artnet.net({net}).subnet({subnet}).uv({universe}).ch({channels})</code></p>\n\n<p><strong>Universe addressing</strong> can be specified in two ways:</p>\n\n<ul>\n<li><strong>Full address:</strong> <code>artnet.net(1).subnet(2).uv(3).ch(10)</code> — Specifies the ArtNet net, subnet, and universe individually.</li>\n<li><strong>Absolute universe:</strong> <code>artnet.uv(5).ch(10)</code> — When only <code>uv</code> is specified (without <code>net</code> and <code>subnet</code>), it is treated as an absolute universe number. Universe 0 maps to net 0, subnet 0, universe 0; universe 18 (= 1×16 + 2) maps to net 0, subnet 1, universe 2; and so on.</li>\n\n</ul>\n<h3>Channel Resolutions</h3>\n\n<p>WATCHOUT supports multiple DMX channel resolutions for different precision requirements:</p>\n\n<p><strong>Coarse (8-bit)</strong> — A single DMX channel. Range: 0–255.</p>\n\n<p><code>artnet.uv(0).ch(1)</code></p>\n\n<p><strong>Fine (16-bit)</strong> — Two DMX channels combined for higher precision. Range: 0–65,535.</p>\n\n<p><code>artnet.uv(0).ch(1, 2)</code></p>\n\n<p><strong>Ultra (24-bit)</strong> — Three DMX channels. Range: 0–16,777,215.</p>\n\n<p><code>artnet.uv(0).ch(1, 2, 3)</code></p>\n\n<p><strong>Uber (32-bit)</strong> — Four DMX channels for maximum precision. Range: 0–4,294,967,295.</p>\n\n<p><code>artnet.uv(0).ch(1, 2, 3, 4)</code></p>\n\n<p>For multi-channel resolutions, channels are listed in order from most significant (coarse) to least significant. The values are combined in big-endian byte order.</p>\n\n<div class='note-box'><p>DMX channels are 1-indexed in the key format — channel 1 corresponds to the first channel in the DMX universe.\n</p></div>\n\n<h3>Normalization</h3>\n\n<p>Append <code>.normalize()</code> to the key to receive normalized values (0.0–1.0) instead of raw DMX values:</p>\n\n<p><code>artnet.uv(0).ch(1).normalize()</code></p>\n\n<p>Normalization divides the raw value by the maximum for the channel resolution (255 for 8-bit, 65535 for 16-bit, etc.). This is useful when your variable range is 0–1 or when you want consistent scaling regardless of resolution.</p>\n\n<h3>Update Frequency and Interpolation</h3>\n\n<p>ArtNet typically operates at approximately <strong>44 Hz</strong> (roughly every 22ms). Each incoming ArtNet packet is timestamped with a <strong>50ms interpolation window</strong> by the Operative before forwarding to the Director. This provides smooth transitions between DMX value updates.</p>\n\n<p>The Operative subscribes only to the ArtNet universes that are actually referenced by variables in the current show. If no variables reference a particular universe, that universe's traffic is ignored, keeping processing efficient.</p>\n\n<h3>ArtNet Fixtures and Output</h3>\n\n<p>In addition to receiving ArtNet input, WATCHOUT supports ArtNet output through <strong>fixture cues</strong> on timelines. Fixture cues allow you to drive external DMX devices (lights, fog machines, motors, etc.) from the WATCHOUT timeline with keyframed values. ArtNet output runs at 44 FPS.</p>\n\n<p>Fixture cues support: <ul> <li>Multiple channel resolutions (8-bit through 32-bit).</li> <li>Channel relationships (multiply and override) for master/slave dimmer configurations.</li> <li>ArtNet recording — recording incoming ArtNet data for later playback as timeline content.</li></p>\n\n</ul>\nSee the ArtNet Fixture Cues section in Chapter 6 for details on fixture configuration and output.\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Lighting desk integration</strong> — Control WATCHOUT opacity, position, and blend parameters from a grandMA, ETC Eos, or any ArtNet-capable lighting console.</li>\n<li><strong>DMX show control</strong> — Use a DMX-based automation system to drive WATCHOUT variables alongside lighting and mechanical effects.</li>\n<li><strong>Recording and playback</strong> — Record incoming ArtNet data from a lighting desk rehearsal and play it back as part of the show, ensuring consistent lighting-to-video synchronization.</li>\n\n</ul>",
      "PosiStageNet": "<h2>PosiStageNet</h2>\n\n<p>PosiStageNet (PSN) is an open protocol for transmitting real-time 3D position data from tracking systems over a network. WATCHOUT receives PSN data and maps tracker coordinates to show variables, enabling content that dynamically follows performers, objects, or other tracked elements on stage.</p>\n\n<h3>Enabling PSN</h3>\n\n<p>PSN support is enabled or disabled from the <strong>Network</strong> window in Producer using the <strong>PosiStageNet</strong> toggle. When enabled, the Operative starts a PSN forwarder that listens for incoming tracking data.</p>\n\n<h3>Network Details</h3>\n\n<p>PSN uses <strong>UDP multicast</strong> for data transmission. The WATCHOUT PSN forwarder listens on:</p>\n\n<ul>\n<li><strong>Multicast group:</strong> <code>236.10.10.10</code></li>\n<li><strong>Port:</strong> <code>56565</code></li>\n\n</ul>\nThe forwarder joins the multicast group on all available network interfaces. Ensure your tracking system is sending PSN data to this standard multicast address and that multicast routing is properly configured on your network.\n\n<h3>Data Mapping</h3>\n\n<p>Each PSN tracker exposes multiple data fields as WATCHOUT variables. The external key format is:</p>\n\n<p><code>psn.{tracker_id}.{field}</code></p>\n\n<p>Where <code>{tracker_id}</code> is the numeric ID assigned to the tracker by the tracking system, and <code>{field}</code> is one of the following:</p>\n\n<p><strong>Position:</strong> <ul> <li><code>psn.{id}.pos.x</code> — X position</li> <li><code>psn.{id}.pos.y</code> — Y position</li> <li><code>psn.{id}.pos.z</code> — Z position</li></p>\n\n</ul>\n<strong>Speed:</strong>\n<ul>\n<li><code>psn.{id}.speed.x</code> — X velocity</li>\n<li><code>psn.{id}.speed.y</code> — Y velocity</li>\n<li><code>psn.{id}.speed.z</code> — Z velocity</li>\n\n</ul>\n<strong>Orientation:</strong>\n<ul>\n<li><code>psn.{id}.ori.x</code> — X rotation</li>\n<li><code>psn.{id}.ori.y</code> — Y rotation</li>\n<li><code>psn.{id}.ori.z</code> — Z rotation</li>\n\n</ul>\n<strong>Acceleration:</strong>\n<ul>\n<li><code>psn.{id}.accel.x</code> — X acceleration</li>\n<li><code>psn.{id}.accel.y</code> — Y acceleration</li>\n<li><code>psn.{id}.accel.z</code> — Z acceleration</li>\n\n</ul>\n<strong>Target position:</strong>\n<ul>\n<li><code>psn.{id}.trgtpos.x</code> — Target X position</li>\n<li><code>psn.{id}.trgtpos.y</code> — Target Y position</li>\n<li><code>psn.{id}.trgtpos.z</code> — Target Z position</li>\n\n</ul>\n<strong>Status and timestamp:</strong>\n<ul>\n<li><code>psn.{id}.status</code> — Tracker status value</li>\n<li><code>psn.{id}.timestamp</code> — Frame timestamp</li>\n\n</ul>\nNot all fields are present in every PSN frame — the forwarder only forwards fields that the tracking system actually sends.\n\n<h3>How It Works</h3>\n\n<p>The PSN forwarder operates as follows:</p>\n\n<ol>\n<li><strong>Packet reception</strong> — UDP packets are received on the multicast address. PSN supports packet fragmentation for large frames; the forwarder automatically reassembles fragmented packets.</li>\n<li><strong>Frame parsing</strong> — DATA packets are parsed to extract tracker positions and other fields. INFO packets (containing system and tracker names) are received but not forwarded.</li>\n<li><strong>Change detection</strong> — The forwarder compares each tracker's current values against the previous frame. Only values that have actually changed are queued for transmission, reducing unnecessary network traffic to the Director.</li>\n<li><strong>Batched forwarding</strong> — Changed values are batched and sent to the Director's input endpoint with a <strong>25ms interpolation window</strong>. This shorter interpolation (compared to the 50ms default for other protocols) reflects the high update rate typical of tracking systems.</li>\n\n</ol>\n<div class='info-box'><p>Coordinate systems vary between tracking systems. You may need to use WATCHOUT's variable min/max range and tween expressions to remap PSN coordinates to your stage coordinate system.\n</p></div>\n\n<h3>Requirements</h3>\n\n<ul>\n<li>A <strong>tracking system</strong> that outputs PosiStageNet data (e.g., BlackTrax, Mo-Sys, Augmenta, or custom PSN senders).</li>\n<li><strong>Network multicast support</strong> between the tracking system and the WATCHOUT Operative. Both must be on the same network segment or have multicast routing configured.</li>\n<li>Variables defined in the show with external keys matching the PSN key format for the trackers you want to use.</li>\n\n</ul>\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Performer tracking</strong> — Content (spotlights, graphics, text) that follows performers as they move across the stage.</li>\n<li><strong>Interactive projection mapping</strong> — Projected visuals that react to the position of physical objects.</li>\n<li><strong>Position-reactive show elements</strong> — Trigger content changes or transitions based on where tracked elements are in the performance space.</li>\n<li><strong>Multi-axis control</strong> — Use tracker orientation and speed data to drive rotation, scale, or animation speed of visual elements.</li>\n\n</ul>",
      "MIDI Show Control": "<h2>MIDI Show Control</h2>\n\n<p>MIDI Show Control (MSC) is an industry-standard protocol for controlling show equipment using a defined set of commands within the MIDI System Exclusive (SysEx) specification. It is widely used in theatrical productions, theme parks, and live events to coordinate cue triggering across multiple devices from different vendors.</p>\n\n<p>WATCHOUT receives MSC messages through the <strong>MIDI Bridge</strong> and translates them into timeline playback commands.</p>\n\n<h3>How MSC Reaches WATCHOUT</h3>\n\n<p>MSC messages are received by the <strong>MIDI Bridge</strong> service alongside regular MIDI Control Change messages. When the MIDI Bridge detects an MSC SysEx message on the connected MIDI input, it:</p>\n\n<ol>\n<li>Parses the MSC message fields (device ID, command, Q-number, list number).</li>\n<li>Checks whether the message's device ID matches the configured <strong>MSC Device ID</strong> (or the all-call ID <code>127</code>).</li>\n<li>Forwards matching messages to the Operative's MSC endpoint, which executes the corresponding timeline command.</li>\n\n</ol>\nThe MSC Device ID is configured in the MIDI Bridge settings dialog. This allows multiple WATCHOUT systems on the same MIDI network to respond to different MSC messages.\n\n<h3>Supported Commands</h3>\n\n<p>WATCHOUT supports the following MSC commands:</p>\n\n<p><strong>GO</strong> — Starts playback of a timeline. If a Q-number is provided, playback jumps to the cue matching that name and begins playing. If a list number is provided, it identifies the target timeline by name.</p>\n\n<p><strong>STOP</strong> — Pauses the timeline at its current position. If a Q-number is provided, the timeline jumps to that cue's position and pauses.</p>\n\n<p><strong>GO OFF</strong> — Stops the timeline and resets it to the beginning. If a Q-number is provided, the timeline jumps to that cue's position and stops.</p>\n\n<p><strong>RESET</strong> — Stops all timelines in the show and resets them to their beginning positions. This command takes no Q-number or list number parameters.</p>\n\n<h3>Q-Number and List Number Mapping</h3>\n\n<p>MSC commands can include optional Q-number and list number fields that determine which cue and timeline are targeted:</p>\n\n<ul>\n<li><strong>Q-number</strong> — Matched against <strong>cue names</strong> in the show. WATCHOUT searches for the first cue whose name matches the Q-number string and uses that cue's timeline position as the target time.</li>\n<li><strong>List number</strong> — Matched against <strong>timeline names</strong> in the show. If provided, the command targets the timeline with the matching name.</li>\n<li><strong>No list number</strong> — When the list number is omitted, the command targets the timeline with the lowest ID (typically the first timeline in the show).</li>\n\n</ul>\n<div class='info-box'><p>To issue a play or pause command that uses the timeline's current position (without jumping to a cue), send Q-number <code>0</code>. This is a special bypass value inherited from WATCHOUT 6 behavior.\n</p></div>\n\n<h3>MSC Message Format</h3>\n\n<p>For reference, WATCHOUT processes standard MSC SysEx messages with the following structure:</p>\n\n<p><code>F0 7F {device_id} 02 {command_format} {command} {data} F7</code></p>\n\n<ul>\n<li><code>F0</code> — SysEx start byte</li>\n<li><code>7F</code> — Universal System Exclusive (real-time)</li>\n<li><code>{device_id}</code> — 0–126 for specific devices, 127 (<code>0x7F</code>) for all-call (broadcast to all devices)</li>\n<li><code>02</code> — MSC sub-ID</li>\n<li><code>{command_format}</code> — Specifies the device type being controlled</li>\n<li><code>{command}</code> — <code>0x01</code> (GO), <code>0x02</code> (STOP), <code>0x03</code> (GO OFF), <code>0x04</code> (RESET)</li>\n<li><code>{data}</code> — Optional Q-number, list number, and path fields, separated by <code>0x00</code> delimiter bytes</li>\n<li><code>F7</code> — SysEx end byte</li>\n\n</ul>\n<h3>Configuration</h3>\n\n<p>To receive MSC messages in WATCHOUT:</p>\n\n<ol>\n<li>Start the <strong>MIDI Bridge</strong> on a node with a MIDI input device.</li>\n<li>Select the MIDI input port that receives MSC messages.</li>\n<li>Set the <strong>MSC Device ID</strong> in the MIDI Bridge settings to match the device ID your show control system sends to (or leave it at <code>0</code> and ensure your controller sends to device <code>0</code> or all-call <code>127</code>).</li>\n\n</ol>\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Theatrical show control</strong> — Trigger WATCHOUT cues from a stage manager's MSC-capable console (e.g., QLab, SFX, Medialon, Dataton PICKUP).</li>\n<li><strong>Multi-vendor coordination</strong> — Synchronize WATCHOUT with lighting, sound, and automation systems that all listen to the same MSC cue stream.</li>\n<li><strong>Theme park automation</strong> — Integrate WATCHOUT playback into complex ride and attraction control systems that use MSC for sequencing.</li>\n\n</ul>",
      "WATCHOUT 6 Protocol": "<h2>WATCHOUT 6 Protocol</h2>\n\n<p>WATCHOUT 7 includes a backward-compatible TCP control interface that accepts commands in the WATCHOUT 6 protocol format. This allows existing integrations — Crestron modules, AMX programs, Extron scripts, and other control system code written for WATCHOUT 6 — to work with WATCHOUT 7 without modification.</p>\n\n<h3>Enabling the WO6 Protocol</h3>\n\n<p>The WATCHOUT 6 protocol is enabled or disabled from the <strong>Network</strong> window in Producer using the <strong>WATCHOUT 6 Protocol</strong> toggle. This toggle is independent of the <strong>WATCHOUT 7 Protocol</strong> toggle — you can run both simultaneously, only one, or neither.</p>\n\n<p>When enabled, the Operative starts a TCP server that accepts connections in the WATCHOUT 6 text-based command format.</p>\n\n<h3>Connection Details</h3>\n\n<p>The WO6 compatibility layer listens on:</p>\n\n<ul>\n<li><strong>TCP port 3040</strong> — The production control port (equivalent to the WATCHOUT 6 \"watchmaker\" port).</li>\n<li><strong>TCP port 3039</strong> — The display computer port (equivalent to the WATCHOUT 6 \"watchpoint\" port).</li>\n\n</ul>\nConnections use the same text-based, newline-delimited command/response protocol as WATCHOUT 6. Commands are sent as ASCII text terminated by a newline, and responses follow the same format.\n\n<h3>The Main Timeline</h3>\n\n<p>Several WO6 commands operate on the \"main timeline\" by default. In WATCHOUT 7, this requires a timeline named <strong>\"Main Timeline\"</strong> to exist in the show. Commands that reference no specific timeline (like <code>run</code>, <code>halt</code>, and <code>getStatus</code>) will target this timeline.</p>\n\n<div class='note-box'><p>If your show does not have a timeline named \"Main Timeline\", commands that default to the main timeline will fail. Either create a timeline with this name or use commands that explicitly specify a timeline name.\n</p></div>\n\n<h3>Supported Commands</h3>\n\n<p>The following WATCHOUT 6 commands are supported in the compatibility layer:</p>\n\n<p><strong>Authentication and status:</strong> <ul> <li><strong>authenticate</strong> — Authenticates the connection. WATCHOUT 7 always accepts authentication (license check is not enforced at this level).</li> <li><strong>ping</strong> — Returns the system's ready status and version string.</li> <li><strong>getStatus</strong> — Returns the current show status (loaded show name, busy state, timeline information).</li></p>\n\n</ul>\n<strong>Timeline playback:</strong>\n<ul>\n<li><strong>run</strong> — Starts playback of the main timeline or a named auxiliary timeline.</li>\n<li><strong>halt</strong> — Pauses the main timeline or a named auxiliary timeline.</li>\n<li><strong>kill</strong> — Stops a named timeline (resets to beginning).</li>\n<li><strong>gotoTime</strong> — Jumps to a specific time position on the main timeline or a named timeline. Maintains the current play/pause state.</li>\n<li><strong>gotoControlCue</strong> — Jumps to a named control cue, searching forward from the current position (or backward if not found ahead). Maintains the current play/pause state.</li>\n<li><strong>reset</strong> — Stops all auxiliary timelines and resets the main timeline to the beginning in a paused state.</li>\n\n</ul>\n<strong>Timeline information:</strong>\n<ul>\n<li><strong>getAuxTimelines</strong> / <strong>getAuxTimelinesTree</strong> — Returns a list of all auxiliary timelines with names and durations.</li>\n<li><strong>getTimelineStatus</strong> — Returns the current playback status for a named timeline.</li>\n<li><strong>subscribeStatus</strong> / <strong>unsubscribeStatus</strong> — Subscribe to or unsubscribe from real-time status updates for the show.</li>\n<li><strong>subscribeTimelineStatus</strong> / <strong>unsubscribeTimelineStatus</strong> — Subscribe to or unsubscribe from real-time status updates for a specific timeline.</li>\n<li><strong>getControlCues</strong> — Returns a list of control cues for a timeline.</li>\n\n</ul>\n<strong>Variable/input control:</strong>\n<ul>\n<li><strong>getInputs</strong> — Returns the current value of one or all input variables.</li>\n<li><strong>setInput</strong> — Sets a single input variable to a value, optionally with a transition rate for smooth fading.</li>\n<li><strong>setInputs</strong> — Sets multiple input variables simultaneously with a shared transition rate. When a transition rate is specified, values are smoothly interpolated at the show's frame rate.</li>\n\n</ul>\n<strong>Show management:</strong>\n<ul>\n<li><strong>loadShow</strong> — Loads a show file by path. Relative paths are resolved against the configured show directory.</li>\n<li><strong>online</strong> — Accepted but has no effect (WATCHOUT 7 is always \"online\").</li>\n\n</ul>\n<strong>Not supported:</strong>\n<ul>\n<li><strong>hitTest</strong> — Returns an \"unimplemented\" error. Use the HTTP REST API's <code>/v0/hittest</code> endpoint instead for hit testing.</li>\n\n</ul>\n<h3>Differences from WATCHOUT 6</h3>\n\n<p>While the compatibility layer aims to be transparent, there are some behavioral differences:</p>\n\n<ul>\n<li>WATCHOUT 7 is always online — the <code>online</code> command is accepted but ignored.</li>\n<li>Timeline identification uses names rather than numeric indices. Ensure timeline names match what your control system expects.</li>\n<li>The main timeline must be explicitly named \"Main Timeline\".</li>\n<li>Input variable fading (via <code>setInput</code> with a transition rate) is implemented by streaming interpolated values at the show's frame rate, which closely mimics WO6 behavior.</li>\n\n</ul>\n<h3>Migration Guidance</h3>\n\n<p>The WO6 protocol is ideal for maintaining compatibility with existing control system integrations during a transition to WATCHOUT 7. However, for new integrations, consider using:</p>\n\n<ul>\n<li><strong>HTTP REST API</strong> — For the most complete feature set, including cue set management, hit testing, show upload, and real-time event streams.</li>\n<li><strong>OSC</strong> — For show controllers and creative applications that natively support OSC.</li>\n\n</ul>\nThe WO6 protocol does not expose WATCHOUT 7-specific features like cue sets, SSE event streams, or the extended input API with custom interpolation durations.\n\n<h3>Use Cases</h3>\n\n<ul>\n<li><strong>Crestron / AMX / Extron integration</strong> — Existing control system programs written for WATCHOUT 6 continue to work without reprogramming.</li>\n<li><strong>Legacy show control</strong> — Third-party show control systems that have WATCHOUT 6 drivers or modules can control WATCHOUT 7 without updates.</li>\n<li><strong>Gradual migration</strong> — Run the WO6 and WO7 protocols simultaneously while transitioning control systems to the newer HTTP API.</li>\n\n</ul>"
    }
  },
  "11. Keyboard Shortcuts": {
    "overview": "<h1>KEYBOARD SHORTCUTS</h1>\n\n<p>Master these keyboard shortcuts to speed up your workflow.</p>",
    "sections": {
      "File Operations": "<h2>File Operations</h2>\n\n<p>These are the primary default shortcuts for show-file work.</p>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Ctrl+O</code></td><td>Open show</td></tr>\n<tr><td><code>Ctrl+S</code></td><td>Save</td></tr>\n<tr><td><code>Ctrl+Shift+S</code></td><td>Save As</td></tr>\n</table>\n\n<h3>Notes</h3>\n\n<ul>\n<li>Some file actions (for example <strong>Save Copy</strong>, <strong>Open from Director</strong>) are menu-only.</li>\n<li>On macOS builds, <code>Cmd</code> is used where <code>Ctrl</code> is shown.</li>\n\n</ul>",
      "Edit Commands": "<h2>Edit Commands</h2>\n\n<p>These shortcuts are context-sensitive and operate on the active edit target.</p>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Ctrl+Z</code></td><td>Undo</td></tr>\n<tr><td><code>Ctrl+Y</code></td><td>Redo</td></tr>\n<tr><td><code>Ctrl+Shift+Z</code></td><td>Redo (alternate)</td></tr>\n<tr><td><code>Ctrl+X</code></td><td>Cut</td></tr>\n<tr><td><code>Ctrl+C</code></td><td>Copy</td></tr>\n<tr><td><code>Ctrl+V</code></td><td>Paste</td></tr>\n<tr><td><code>Delete</code> / <code>Backspace</code></td><td>Delete selection</td></tr>\n<tr><td><code>Ctrl+A</code></td><td>Select all</td></tr>\n<tr><td><code>Ctrl+E</code></td><td>Select to end</td></tr>\n<tr><td><code>Ctrl+F</code></td><td>Find</td></tr>\n<tr><td><code>Ctrl+M</code></td><td>Move</td></tr>\n<tr><td><code>Ctrl+N</code></td><td>Toggle snapping</td></tr>\n<tr><td><code>Enter</code></td><td>Open/activate properties</td></tr>\n</table>\n\n<h3>Tip</h3>\n\n<p>If a shortcut appears to do nothing, check which window has focus and whether the current selection context allows that operation.</p>",
      "Stage Navigation": "<h2>Stage Navigation</h2>\n\n<p>Use these shortcuts to frame, scale, and nudge content quickly in Stage workflows.</p>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Ctrl+Shift+D</code></td><td>Frame all displays</td></tr>\n<tr><td><code>Ctrl+Shift+O</code></td><td>Scroll stage to origin</td></tr>\n<tr><td><code>Ctrl+1</code></td><td>Stage scale 16x</td></tr>\n<tr><td><code>Ctrl+2</code></td><td>Stage scale 8x</td></tr>\n<tr><td><code>Ctrl+3</code></td><td>Stage scale 4x</td></tr>\n<tr><td><code>Ctrl+4</code></td><td>Stage scale 2x</td></tr>\n<tr><td><code>Ctrl+5</code></td><td>Stage scale 1x</td></tr>\n<tr><td><code>Arrow keys</code></td><td>Navigate selection/time context</td></tr>\n<tr><td><code>Home</code></td><td>Navigate to beginning</td></tr>\n<tr><td><code>End</code></td><td>Navigate to end</td></tr>\n<tr><td><code>Ctrl+Arrow</code></td><td>Nudge 1 unit</td></tr>\n<tr><td><code>Ctrl+Shift+Arrow</code></td><td>Nudge 10 units</td></tr>\n</table>\n\n<h3>Practical Use</h3>\n\n<p>Combine framing and scale shortcuts before precision edits so coordinate changes are easier to read.</p>",
      "Timeline Controls": "<h2>Timeline Controls</h2>\n\n<p>These shortcuts are central to timeline operation and cue management.</p>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Spacebar</code></td><td>Toggle play/pause</td></tr>\n<tr><td><code>Numpad 0</code></td><td>Run timeline</td></tr>\n<tr><td><code>Numpad Insert</code></td><td>Run timeline (alternate)</td></tr>\n<tr><td><code>Escape</code></td><td>Pause timeline</td></tr>\n<tr><td><code>Numpad *</code></td><td>Jump to current or last start</td></tr>\n<tr><td><code>Numpad +</code></td><td>Zoom in timeline</td></tr>\n<tr><td><code>Numpad -</code></td><td>Zoom out timeline</td></tr>\n<tr><td><code>Ctrl+T</code></td><td>Toggle \"Click Jumps to Time\"</td></tr>\n<tr><td><code>Ctrl+I</code></td><td>Insert layer</td></tr>\n<tr><td><code>Ctrl+Delete</code></td><td>Delete active layer</td></tr>\n<tr><td><code>Ctrl+P</code></td><td>Add play control cue</td></tr>\n<tr><td><code>Ctrl+Shift+P</code></td><td>Add pause control cue</td></tr>\n<tr><td><code>Ctrl+Enter</code></td><td>Add comment/marker cue</td></tr>\n<tr><td><code>Ctrl+G</code></td><td>Group cues</td></tr>\n<tr><td><code>Ctrl+Shift+G</code></td><td>Ungroup cues</td></tr>\n</table>\n\n<h3>Note</h3>\n\n<p>Several timeline actions require a valid active cue sequence and layer context.</p>",
      "Tween Shortcuts": "<h2>Tween Shortcuts</h2>\n\n<p>Tween shortcuts toggle common animation/effect tracks on selected cues.</p>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Alt+P</code></td><td>Position tween</td></tr>\n<tr><td><code>Alt+S</code></td><td>Scale tween</td></tr>\n<tr><td><code>Alt+O</code></td><td>Opacity tween</td></tr>\n<tr><td><code>Alt+C</code></td><td>Crop all sides</td></tr>\n<tr><td><code>Alt+B</code></td><td>Gaussian blur</td></tr>\n<tr><td><code>Alt+Z</code></td><td>Rotation Z</td></tr>\n<tr><td><code>Alt+Y</code></td><td>Rotation Y</td></tr>\n<tr><td><code>Alt+V</code></td><td>Volume tween</td></tr>\n<tr><td><code>Shift+Alt+I</code></td><td>Fade in</td></tr>\n<tr><td><code>Shift+Alt+O</code></td><td>Fade out</td></tr>\n<tr><td><code>Shift+Alt+X</code></td><td>Cross-fade</td></tr>\n</table>\n\n<h3>Note</h3>\n\n<p>Additional tween types (color, per-side crop, rotation X, etc.) are available via menus and properties even when no direct shortcut is assigned.</p>",
      "Window Management": "<h2>Window Management</h2>\n\n<p>These shortcuts help you move quickly between WATCHOUT windows and layout presets.</p>\n\n<table>\n<tr><th>Shortcut</th><th>Action</th></tr>\n<tr><td><code>Ctrl+F4</code></td><td>Close focused window</td></tr>\n<tr><td><code>Ctrl+Tab</code></td><td>Next window</td></tr>\n<tr><td><code>Ctrl+Shift+Tab</code></td><td>Previous window</td></tr>\n<tr><td><code>Ctrl+F6</code></td><td>Next window</td></tr>\n<tr><td><code>Ctrl+Shift+F6</code></td><td>Previous window</td></tr>\n<tr><td><code>Alt+Left</code></td><td>Previous window of same type</td></tr>\n<tr><td><code>Alt+Right</code></td><td>Next window of same type</td></tr>\n<tr><td><code>Alt+0</code></td><td>Reset layout</td></tr>\n<tr><td><code>Alt+1</code> ... <code>Alt+9</code></td><td>Load layout preset 1-9</td></tr>\n<tr><td><code>Ctrl+Alt+1</code> ... <code>Ctrl+Alt+9</code></td><td>Save layout preset 1-9</td></tr>\n</table>\n\n<h3>Workflow Tip</h3>\n\n<p>Use layout presets for role-based views (programming, calibration, playback), then switch instantly during rehearsal.</p>"
    }
  },
  "12. Troubleshooting": {
    "overview": "<h1>TROUBLESHOOTING</h1>\n\n<p>Solutions to common issues and tips for optimal performance.</p>",
    "sections": {
      "Common Issues": "<h2>Common Issues</h2>\n\n<p>This section covers high-frequency problems seen during setup and rehearsal.</p>\n\n<h3>Producer Opens but Show Actions Fail</h3>\n\n<p>Check:</p>\n\n<ul>\n<li>Director connection state</li>\n<li>Asset Manager connection state</li>\n<li>Whether a different show is currently active on the selected Director</li>\n\n</ul>\n<h3>Cannot Open/Override Show on Director</h3>\n\n<ul>\n<li>Verify you selected the intended host alias.</li>\n<li>Confirm team coordination before overriding a running Director show.</li>\n<li>Resolve unsaved local changes first if prompts are blocking action.</li>\n\n</ul>\n<h3>Menus/Shortcuts Not Acting as Expected</h3>\n\n<ul>\n<li>Confirm the intended window has focus.</li>\n<li>Check selection context (timeline, cue, layer, properties).</li>\n<li>Re-try command from menu to verify availability state.</li>\n\n</ul>\n<h3>Startup Reliability Tips</h3>\n\n<ul>\n<li>Keep node aliases stable.</li>\n<li>Avoid running unrelated heavy software on playback nodes.</li>\n<li>Reboot and validate nodes before show day if system state is uncertain.</li>\n\n</ul>",
      "Performance Tips": "<h2>Performance Tips</h2>\n\n<p>Performance issues are usually a combination of media complexity, output load, and node configuration.</p>\n\n<h3>Media and Rendering</h3>\n\n<ul>\n<li>Prefer playback-friendly codecs and resolutions appropriate for target outputs.</li>\n<li>Limit unnecessary overlapping high-resolution cues.</li>\n<li>Use blur/color-heavy effects carefully in dense sections.</li>\n\n</ul>\n<h3>Node Health</h3>\n\n<ul>\n<li>Keep playback nodes dedicated to WATCHOUT services.</li>\n<li>Watch CPU/GPU/memory indicators in activity views.</li>\n<li>Verify disk throughput for high-bandwidth media.</li>\n\n</ul>\n<h3>Timeline Practices</h3>\n\n<ul>\n<li>Group stable cue clusters to reduce editing overhead.</li>\n<li>Use stage tiers and layer organization to simplify active scenes.</li>\n<li>Avoid last-minute structural changes during live operation.</li>\n\n</ul>\n<h3>Network and Sync</h3>\n\n<ul>\n<li>Keep show traffic on reliable wired networking.</li>\n<li>Verify NTP/time sync behavior on Director/Runner systems.</li>\n<li>Resolve stale/offline node status before technical run-through.</li>\n\n</ul>",
      "Display Problems": "<h2>Display Problems</h2>\n\n<p>When a display misbehaves, diagnose in this order: routing, output mode, geometry, then content.</p>\n\n<h3>No Signal on a Display</h3>\n\n<p>Check:</p>\n\n<ol>\n<li>Display is <strong>enabled</strong> and not locked to wrong settings.</li>\n<li>Correct <strong>host alias</strong> and <strong>output channel</strong>.</li>\n<li>Correct <strong>output type</strong> (GPU/SDI/NDI/Virtual).</li>\n<li>Node services are online.</li>\n\n</ol>\n<h3>Wrong Screen / Wrong Position</h3>\n\n<ul>\n<li>Re-check stage placement and display naming.</li>\n<li>Use <strong>Frame in Stage</strong> and <strong>Frame All Displays</strong>.</li>\n<li>Validate channel mapping in device properties.</li>\n\n</ul>\n<h3>Visible Seams or Warped Content</h3>\n\n<ul>\n<li>Revisit warp geometry and mask edits.</li>\n<li>Verify soft-edge overlap quality.</li>\n<li>Re-run projector calibration where required.</li>\n\n</ul>\n<h3>Interlaced/Color Artifacts</h3>\n\n<ul>\n<li>Confirm interlaced setting is intentional.</li>\n<li>Verify color depth/color space settings per output path.</li>\n<li>Compare with known test pattern media.</li>\n\n</ul>",
      "Network Issues": "<h2>Network Issues</h2>\n\n<p>Most network failures fall into discovery, firewall, or host-alias consistency problems.</p>\n\n<h3>Nodes Not Appearing</h3>\n\n<ul>\n<li>Verify nodes are on reachable network interfaces.</li>\n<li>Check multicast handling (<code>239.2.2.2:3012</code>).</li>\n<li>Confirm firewall allows WATCHOUT services and required UDP ports.</li>\n\n</ul>\n<h3>Node Appears but Goes Stale/Offline</h3>\n\n<ul>\n<li>Check switch stability and cable quality.</li>\n<li>Verify host is not sleeping/power-throttled.</li>\n<li>Confirm process-manager services are still running.</li>\n\n</ul>\n<h3>Director/Runner Mismatch Warnings</h3>\n\n<ul>\n<li>Ensure all nodes are attached to the intended Director.</li>\n<li>Clear stale show state on nodes if needed.</li>\n<li>Re-run a controlled startup sequence before rehearsal.</li>\n\n</ul>\n<h3>NTP/Sync Instability</h3>\n\n<ul>\n<li>Confirm Director and runners use consistent time strategy.</li>\n<li>Check NTP reachability and drift.</li>\n<li>Resolve time sync warnings before running synchronized playback.</li>\n\n</ul>",
      "Media Playback Issues": "<h2>Media Playback Issues</h2>\n\n<p>Playback errors usually come from media format compatibility, missing data, or timing/resource pressure.</p>\n\n<h3>Media Imports but Will Not Play Correctly</h3>\n\n<p>Check:</p>\n\n<ul>\n<li>Asset exists and path/version are valid</li>\n<li>Codec/format is supported for your workflow</li>\n<li>Asset transfer to nodes completed</li>\n\n</ul>\n<h3>Stutter or Frame Drops</h3>\n\n<ul>\n<li>Reduce simultaneous heavy cues.</li>\n<li>Verify storage bandwidth on playback nodes.</li>\n<li>Test with simpler codec/resolution versions of the same content.</li>\n\n</ul>\n<h3>Color or Alpha Looks Wrong</h3>\n\n<ul>\n<li>Verify color space/transfer expectations.</li>\n<li>Confirm key/fill and alpha-capable codec choices.</li>\n<li>Compare against a trusted reference clip.</li>\n\n</ul>\n<h3>NDI/Capture Irregularities</h3>\n\n<ul>\n<li>Verify source stream stability and format.</li>\n<li>Check network bandwidth headroom.</li>\n<li>Confirm capture source dimensions/range settings match source.</li>\n\n</ul>",
      "Feedback Reports": "<h2>Feedback Reports</h2>\n\n<p>A feedback report is a compressed diagnostic archive that bundles logs, system information, and optionally the current show file into a single package. You can send this archive to Dataton support or use it for internal analysis when troubleshooting issues.</p>\n\n<h3>Creating a Report</h3>\n\n<p>The <strong>Create Feedback Report</strong> dialog is accessible from two places:</p>\n\n<ul>\n<li><strong>Help menu</strong> → <strong>Create Feedback Report</strong></li>\n<li><strong>Welcome screen</strong> → <strong>Your Feedback</strong></li>\n\n</ul>\nThe dialog presents the following options:\n\n<p><strong>Director</strong> — Select which Director to fetch logs from. The dropdown lists all discovered Directors on the network by host alias and IP address. If no Director is found, the option defaults to localhost (<code>127.0.0.1</code>). If a show is currently open, the dialog pre-selects the Director associated with that show.</p>\n\n<p><strong>Start Time</strong> — The beginning of the time window for log collection. Use the calendar and clock icons to pick a date and time. The start time must be within the <strong>last 2 weeks</strong> and cannot be in the future. By default, this is set to 8 hours before the current time.</p>\n\n<p><strong>Duration</strong> — How many hours of logs to collect, from <strong>0.1 to 720 hours</strong> (30 days). The default is 8 hours. A shorter duration produces a smaller, more focused report.</p>\n\n<p><strong>Include Show File</strong> — A toggle to attach the current show file to the report. This is enabled by default. Including the show file helps support reproduce issues in context, but you may want to disable it if the show contains sensitive content.</p>\n\n<p>Click <strong>Create</strong> to generate the report.</p>\n\n<h3>What the Report Contains</h3>\n\n<p>The feedback report is saved as a <strong>7z archive</strong> named <code>dataton_feedback.7z</code> in a <code>feedback</code> folder next to the Producer log directory. When the report is created, the folder opens automatically in the file explorer.</p>\n\n<p>The archive contains:</p>\n\n<ul>\n<li><strong>services_log.txt</strong> — Logs from all WATCHOUT services (Director, Runner, Operative, etc.) collected from the centralized logging service for the selected time range. Limited to 500,000 log lines.</li>\n<li><strong>error_log.txt</strong> — A filtered extract of error-level log entries from the past 2 weeks (up to 5,000 entries), providing a quick overview of recent problems.</li>\n<li><strong>producer_log.txt</strong> — The Producer's local log file, trimmed to the last 3 sessions for relevance.</li>\n<li><strong>asset_watcher_log.txt</strong> — The Asset Watcher's log file, if available.</li>\n<li><strong>hosts_info.json</strong> — Information about all discovered nodes on the network.</li>\n<li><strong>show_info.json</strong> — Metadata about the current show.</li>\n<li><strong>show.watch</strong> — The current show file (only if \"Include Show File\" was enabled).</li>\n\n</ul>\n<h3>Size and Data Limits</h3>\n\n<p>The report generation process enforces several safeguards:</p>\n\n<ul>\n<li><strong>Maximum report size: 500 MB</strong> — If the compressed archive exceeds this limit, the report is discarded and an error is shown. Reduce the duration to capture fewer logs.</li>\n<li><strong>Maximum log lines: 500,000</strong> — If the selected time range contains more log lines than this limit, the report is still created but a warning is shown advising you to reduce the time range.</li>\n<li><strong>No data warning</strong> — If the archive is smaller than 1 KB (essentially empty), the report is discarded with a message suggesting you try a different time range or verify that services were running during the selected period.</li>\n\n</ul>\n<h3>The Loki Log Server</h3>\n\n<p>WATCHOUT uses a <strong>Loki-based logging service</strong> for centralized log collection across all services in the system. Every WATCHOUT service (Director, Runner, Operative, Process Manager, etc.) sends its log output to Loki, which runs on the same node as the Process Manager.</p>\n\n<p>The feedback report pulls logs from Loki via its query API, which is why you need to select a Director — the report fetches logs from the Loki instance running on that node.</p>\n\n<div class='warning-box'><p>If Loki fails to start or stops unexpectedly, a message will appear in the log window: \"Logging service (Loki) failed to start\" or \"Logging service (Loki) has stopped unexpectedly and will attempt to restart.\" Without a running Loki instance, feedback reports will not contain service logs for the affected node.\n</p></div>\n\n<h3>When to Create a Report</h3>\n\n<ul>\n<li><strong>After a crash or unexpected behavior</strong> — Capture logs as soon as possible while they are still available.</li>\n<li><strong>Performance issues</strong> — Include a time window that covers the period when the issue occurred.</li>\n<li><strong>When requested by Dataton support</strong> — Support may ask for a feedback report with a specific time range.</li>\n<li><strong>Before making system changes</strong> — A baseline report can be useful for comparison if issues arise later.</li>\n\n</ul>\n<div class='info-box'><p>Create the report promptly after an issue occurs. Loki retains logs for a limited period, and the 2-week start time limit means older logs may no longer be available.\n</p></div>",
      "Getting Help": "<h2>Getting Help</h2>\n\n<p>When escalation is needed, gather diagnostics first so support can reproduce and resolve quickly.</p>\n\n<h3>Built-In Support Tools</h3>\n\n<p>Use the Help menu to:</p>\n\n<ul>\n<li><strong>Create Feedback Report</strong></li>\n<li><strong>Open Log Directory</strong></li>\n<li>Review licensing/version information</li>\n\n</ul>\n<h3>What to Collect</h3>\n\n<p>Before contacting support, capture:</p>\n\n<ul>\n<li>Exact WATCHOUT version/build in use</li>\n<li>Show file name/version</li>\n<li>Steps to reproduce</li>\n<li>Node aliases and roles (Director/Runner/Asset Manager)</li>\n<li>Relevant timestamps and screenshots/video</li>\n\n</ul>\n<h3>Useful Runtime Context</h3>\n\n<p>Include whether the issue occurred:</p>\n\n<ul>\n<li>During local preview or live network playback</li>\n<li>With specific outputs (GPU/SDI/NDI)</li>\n<li>After recent network, driver, or hardware changes</li>\n\n</ul>\n<h3>Team Handoff Tip</h3>\n\n<p>Document temporary workarounds in marker cues or operations notes so the next operator can keep the show stable while root-cause analysis continues.</p>"
    }
  }
};
